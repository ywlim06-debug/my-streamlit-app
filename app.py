# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ (Pebble Decision Coach)
#
# (ì›ì¹™ ìœ ì§€)
# - ì •ë‹µ/ê²°ë¡ /ì¶”ì²œ ì œê³µ ê¸ˆì§€ (ê°•ì œ)
# - í•œ í™”ë©´ì— í•œ ì§ˆë¬¸ì”©
# - ì´ì „ ë‹µë³€ ë°˜ì˜ ë™ì  ì§ˆë¬¸ ìƒì„±
# - ë§ˆì§€ë§‰: ê³ ë¯¼ì˜ í•µì‹¬ / ì„ íƒ ê¸°ì¤€ / ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°, ì¶”ì²œ ê¸ˆì§€)
#
# ì´ë²ˆ ë°˜ì˜(í† í° ë¹„ìš© ê´€ë¦¬):
# âœ… â€œìš”ì•½ ë²„í¼(summary buffer)â€ ë„ì…
# - í”„ë¡¬í”„íŠ¸ì— Q/A ì „ì²´ ëˆ„ì  ê¸ˆì§€
# - ìµœê·¼ 3~4ê°œ Q/Aë§Œ ë³´ë‚´ê³ 
# - ê·¸ ì´ì „ ë‚´ìš©ì€ ì„¸ì…˜ ìš”ì•½(summary_buffer)ë¡œ ì••ì¶•í•´ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
# - ìš”ì•½ì€ 3ê°œ ë©”ì¸ ë‹µë³€ë§ˆë‹¤(ë˜ëŠ” ì„¤ì •ëœ ì£¼ê¸°) ìë™ ì—…ë°ì´íŠ¸
# - OpenAI ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ ìš”ì•½ìœ¼ë¡œ fallback
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import random
import re
import textwrap
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ AI ê²°ì • ì½”ì¹­", page_icon="ğŸª¨", layout="wide")

MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

DECISION_TEMPLATES: Dict[str, str] = {
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] A vs B ì„ íƒ ì •ë¦¬
        1) Aì™€ Bë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í•´ë³´ì„¸ìš”(ë¬´ì—‡ì´ ë‹¤ë¥¸ê°€?)
        2) Aì˜ ì¥ì /ë‹¨ì , Bì˜ ì¥ì /ë‹¨ì  2~3ê°œì”©
        3) 'ë‚´ê²Œ ì¤‘ìš”í•œ ê¸°ì¤€' 3ê°œì™€ ê¸°ì¤€ë³„ A/B ì°¨ì´
        4) ìµœì•…ì˜ ê²½ìš°(ë¦¬ìŠ¤í¬)ì™€ ê°ë‹¹ ê°€ëŠ¥í•œ ì •ë„
        """
    ).strip(),
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì—¬ëŸ¬ ì˜µì…˜ ë¹„êµ
        1) í›„ë³´ ì˜µì…˜ ë‚˜ì—´(ìµœì†Œ 3ê°œ)
        2) ë¹„êµ ê¸°ì¤€ 3~5ê°œ
        3) ì˜µì…˜ë³„ ê¸°ì¤€ì—ì„œì˜ ëŠë‚Œ(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)
        4) â€˜ì§€ê¸ˆì˜ ë‚˜â€™ vs â€˜1ë…„ ë’¤ì˜ ë‚˜â€™ ê¸°ì¤€ êµ¬ë¶„
        """
    ).strip(),
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)
        1) â€˜í•œë‹¤â€™ì˜ ì˜ë¯¸ë¥¼ êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ìˆ˜ì¤€ìœ¼ë¡œ?)
        2) í•œë‹¤ë©´/ì•ˆ í•œë‹¤ë©´ ì–»ëŠ” ê²ƒ/ìƒëŠ” ê²ƒ
        3) ë¯¸ë£¨ëŠ” ë¹„ìš©(ë¶ˆì•ˆ/ê¸°íšŒ/ê´€ê³„ ë“±)
        4) ì§€ê¸ˆ ë‹¹ì¥ í•„ìš”í•œ ì¶”ê°€ ì •ë³´ 1~2ê°œ
        """
    ).strip(),
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì „ëµ/ì‹œì  ê²°ì •
        1) ì„±ê³µì˜ ì •ì˜(ì¸¡ì • ê°€ëŠ¥)
        2) ì‹œë‚˜ë¦¬ì˜¤ 2~3ê°œ(ë¹ ë¥´ê²Œ/ì²œì²œíˆ/ë¶€ë¶„ ì ìš©)
        3) ê° ì‹œë‚˜ë¦¬ì˜¤ ë¦¬ìŠ¤í¬ì™€ ì™„ì¶©ì¥ì¹˜
        4) If(íŠ¸ë¦¬ê±°) â†’ Then(í–‰ë™) ì„¤ê³„
        """
    ).strip(),
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ê°ˆë“±/ëŒ€í™” ë°©í–¥ ì •ë¦¬
        1) ìŸì ì„ â€˜ì‚¬ì‹¤/í•´ì„/ê°ì •/ìš”êµ¬â€™ë¡œ ë¶„ë¦¬
        2) ì›í•˜ëŠ” ë³€í™”(ìš”êµ¬) 1~2ê°œë¥¼ êµ¬ì²´í™”
        3) ìƒëŒ€ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸¸ ê²ƒ(ì¶”ì¸¡)
        4) ëŒ€í™” ì›ì¹™(í†¤/íƒ€ì´ë°/í•œê³„ì„ )
        """
    ).strip(),
}

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” êµ¬ì¡° ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê³ , ê°€ì •ì„ í”ë“œëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì •ë¦¬ë¥¼ ë•ìŠµë‹ˆë‹¤",
        "style": "MECE/ê¸°ì¤€/ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ)",
        "method": [
            "ìƒí™©Â·ì œì•½Â·ì˜µì…˜ì„ ë¶„ë¦¬í•´ì„œ ì ê²Œ í•˜ê¸°",
            "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ì•„ ìš°ì„ ìˆœìœ„ë¥¼ í™•ì¸í•˜ê¸°",
            "â€˜ë‚´ê°€ ë‹¹ì—°í•˜ë‹¤ê³  ë¯¿ëŠ” ê°€ì •â€™ì„ ë°˜ëŒ€ë¡œ ë’¤ì§‘ì–´ ë³´ê¸°",
        ],
        "prompt_hint": "MECE, ê¸°ì¤€ ëª©ë¡, ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°)",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜ ì½”ì¹˜",
        "tagline": "ê°ì •ê³¼ ê°€ì¹˜ë¥¼ ë¶„ë¦¬í•´, í›„íšŒê°€ ì ì€ ê¸°ì¤€ì„ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤",
        "style": "ê°ì • ë¼ë²¨ë§/ê°€ì¹˜ ë¶„ë¦¬/í›„íšŒ ìµœì†Œí™”",
        "method": [
            "ê°ì • ë¼ë²¨ë§(ì§€ê¸ˆ ëŠë¼ëŠ” ê²ƒ) â†’ ì´ìœ ",
            "ê·¸ ê°ì •ì´ â€˜ì¼ì‹œì  í¸ì•ˆí•¨â€™ì¸ì§€ â€˜ì¥ê¸° ê°€ì¹˜â€™ì¸ì§€ ë¶„ë¦¬",
            "ê°€ì¹˜ Top3 ë„ì¶œ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸",
        ],
        "prompt_hint": "ê°ì •-ê°€ì¹˜ ë¶„ë¦¬, ê°€ì¹˜ Top3, ë¯¸ë˜ì˜ ë‚˜ ì§ˆë¬¸",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê³„íšì„ â€˜ì •ë¦¬â€™í•˜ê³ , ì˜¤ëŠ˜ 5ë¶„ Quick Winê¹Œì§€ ìŠ¤ìŠ¤ë¡œ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤(ì¶”ì²œ ê¸ˆì§€)",
        "style": "ìš°ì„ ìˆœìœ„/If-Then/í”„ë¦¬ëª¨í…œ/Quick Win",
        "method": [
            "ìš°ì„ ìˆœìœ„: íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ Top1~3 ì •ë¦¬",
            "ì‹¤í–‰ì„ If-Then íŠ¸ë¦¬ê±°ë¡œ ì„¤ê³„",
            "í”„ë¦¬ëª¨í…œìœ¼ë¡œ ë°©í•´ ìš”ì¸ ë“œëŸ¬ë‚´ê¸°",
            "â€˜ì˜¤ëŠ˜ 5ë¶„â€™ ê°€ì¥ ì‘ì€ í–‰ë™ ë„ì¶œ",
        ],
        "prompt_hint": "ìš°ì„ ìˆœìœ„, If-Then, í”„ë¦¬ëª¨í…œ, Quick Win",
    },
]

MIN_ANSWER_CHARS = 10

CONFUSED_ANSWER_PATTERNS = [
    r"ëª¨ë¥´ê² ",
    r"ì˜\s*ëª¨ë¥´",
    r"ê°ì´\s*ì•ˆ",
    r"ìƒê°ì´\s*ì•ˆ",
    r"ì–´ë µ",
]

SHORT_ANSWER_PATTERNS = [
    r"^ëª¨ë¥´ê² ",
    r"^ì˜\s*ëª¨ë¥´",
    r"^ê·¸ëƒ¥",
    r"^ì—†ì–´",
    r"^ëª¨ë¦„$",
    r"^ã„´ã„´$",
    r"^ëª°ë¼$",
]

# âœ… í† í° ë¹„ìš© ê´€ë¦¬(ìš”ì•½ ë²„í¼) íŒŒë¼ë¯¸í„°
RECENT_QA_WINDOW = 4          # í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  â€œìµœê·¼ Q/Aâ€ ê°œìˆ˜(3~4 ê¶Œì¥)
SUMMARY_UPDATE_EVERY = 3      # ë©”ì¸ ë‹µë³€ Nê°œë§ˆë‹¤ ìš”ì•½ ë²„í¼ ì—…ë°ì´íŠ¸


# =========================
# Pebble SVG
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    return f"""
<svg width="160" height="120" viewBox="0 0 160 120" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="pebble">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="80%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M28 80
           C14 60, 20 30, 50 20
           C66 14, 96 12, 114 24
           C142 44, 150 68, 130 88
           C112 108, 54 110, 28 80 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M54 30 C68 22, 82 22, 94 30"
        fill="none" stroke="{shine}" stroke-width="7" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_svg_b64(progress_0_to_1: float, inactive: bool = False) -> str:
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    if inactive:
        fill, shine = "#2f3136", "#6b6f7a"
    else:
        fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
        shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"
    svg = _pebble_svg(fill=fill, shine=shine)
    return base64.b64encode(svg.encode("utf-8")).decode("ascii")


def render_pebble_bridge(current_idx: int, total: int, labels: List[str]) -> None:
    total = max(2, int(total))
    current_idx = max(0, min(int(current_idx), total - 1))
    left_pct = ((current_idx + 0.5) / total) * 100.0

    pebble_imgs = []
    for i in range(total):
        active = i <= current_idx
        p = (i + 1) / total
        b64 = pebble_svg_b64(p, inactive=not active)
        pebble_imgs.append(b64)

    html = """
<style>
.pebble-bridge-wrap{ position: relative; width: 100%; margin: 6px 0 2px 0; padding: 16px 4px 0 4px;}
.pebble-row{ display:flex; gap:10px; align-items:flex-end; justify-content:space-between;}
.pebble-cell{ flex:1; min-width:0; text-align:center;}
.pebble-img{ width:100%; max-width:120px; height:auto; display:inline-block;}
.pebble-label{ font-size:12px; margin-top:4px; opacity:0.85; white-space:nowrap; overflow:hidden; text-overflow:ellipsis;}
.walker{ position:absolute; top:-10px; left: VAR_LEFT%; transform: translateX(-50%) scaleX(-1); font-size:40px; line-height:1;
  transition:left 520ms cubic-bezier(.2,.9,.2,1); filter: drop-shadow(0px 2px 2px rgba(0,0,0,0.25)); animation:bob 800ms ease-in-out infinite; user-select:none;}
@keyframes bob{0%{ transform: translateX(-50%) translateY(0px) scaleX(-1);} 50%{ transform: translateX(-50%) translateY(-3px) scaleX(-1);} 100%{ transform: translateX(-50%) translateY(0px) scaleX(-1);} }
</style>
<div class="pebble-bridge-wrap">
  <div class="walker">ğŸš¶</div>
  <div class="pebble-row">
    VAR_PEBBLES
  </div>
</div>
""".strip()

    pebble_cells = []
    for i in range(total):
        opacity = "1.0" if i <= current_idx else "0.55"
        cell = f"""
<div class="pebble-cell" style="opacity:{opacity}">
  <img class="pebble-img" src="data:image/svg+xml;base64,{pebble_imgs[i]}" />
  <div class="pebble-label">{labels[i] if i < len(labels) else ""}</div>
</div>
""".strip()
        pebble_cells.append(cell)

    html = html.replace("VAR_LEFT", f"{left_pct:.3f}")
    html = html.replace("VAR_PEBBLES", "\n".join(pebble_cells))
    st.markdown(html, unsafe_allow_html=True)


def render_hero_pebble(progress: float, label: str) -> None:
    b64 = pebble_svg_b64(progress, inactive=False)
    st.markdown(
        f"""
<div style="text-align:center;">
  <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:240px;"/>
  <div style="margin-top:6px; font-size:14px;">{label}</div>
</div>
""",
        unsafe_allow_html=True,
    )


# =========================
# OpenAI
# =========================
def get_api_key() -> str:
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install openai`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.6) -> Tuple[Optional[str], Optional[str], List[str]]:
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. Secretsì— OPENAI_API_KEYë¥¼ ë„£ê±°ë‚˜ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.", debug


# =========================
# State
# =========================
def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def init_state() -> None:
    if "page" not in st.session_state:
        st.session_state.page = "landing"

    if "user_problem" not in st.session_state:
        st.session_state.user_problem = ""

    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]
    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]
    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]
    if "goal" not in st.session_state:
        st.session_state.goal = ""
    if "options" not in st.session_state:
        st.session_state.options = ""
    if "situation" not in st.session_state:
        st.session_state.situation = ""

    if "num_questions" not in st.session_state:
        st.session_state.num_questions = 5

    if "q_index" not in st.session_state:
        st.session_state.q_index = 0
    if "questions" not in st.session_state:
        st.session_state.questions = []
    if "answers" not in st.session_state:
        st.session_state.answers = []

    if "probe_active" not in st.session_state:
        st.session_state.probe_active = False
    if "probe_question" not in st.session_state:
        st.session_state.probe_question = ""
    if "probe_for_index" not in st.session_state:
        st.session_state.probe_for_index = None  # type: ignore
    if "probe_mode" not in st.session_state:
        st.session_state.probe_mode = ""

    if "crosscheck_used_for" not in st.session_state:
        st.session_state.crosscheck_used_for = []  # list[int]

    if "final_report_json" not in st.session_state:
        st.session_state.final_report_json = None
    if "final_report_raw" not in st.session_state:
        st.session_state.final_report_raw = None
    if "report_just_entered" not in st.session_state:
        st.session_state.report_just_entered = False

    if "decision_matrix_df" not in st.session_state:
        st.session_state.decision_matrix_df = None

    if "onboarding_reco" not in st.session_state:
        st.session_state.onboarding_reco = None
    if "onboarding_raw" not in st.session_state:
        st.session_state.onboarding_raw = None
    if "onboarding_applied" not in st.session_state:
        st.session_state.onboarding_applied = False

    if "saved_templates" not in st.session_state:
        st.session_state.saved_templates = []  # list[dict]

    if "emotion_pre" not in st.session_state:
        st.session_state.emotion_pre = None
    if "emotion_post" not in st.session_state:
        st.session_state.emotion_post = None

    if "privacy_mode" not in st.session_state:
        st.session_state.privacy_mode = False
    if "hide_history" not in st.session_state:
        st.session_state.hide_history = False
    if "mask_export" not in st.session_state:
        st.session_state.mask_export = True

    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []
    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""

    # âœ… ìš”ì•½ ë²„í¼ ìƒíƒœ
    if "summary_buffer" not in st.session_state:
        st.session_state.summary_buffer = ""  # str
    if "summarized_main_count" not in st.session_state:
        st.session_state.summarized_main_count = 0  # int (ìš”ì•½ì— í¬í•¨ëœ ë©”ì¸ ë‹µë³€ ê°œìˆ˜)


def reset_flow(to_page: str = "landing", keep_problem: bool = False) -> None:
    st.session_state.page = to_page

    if not keep_problem:
        st.session_state.user_problem = ""

    st.session_state.onboarding_reco = None
    st.session_state.onboarding_raw = None
    st.session_state.onboarding_applied = False

    st.session_state.category = TOPIC_CATEGORIES[0][0]
    st.session_state.decision_type = DECISION_TYPES[0]
    st.session_state.coach_id = COACHES[0]["id"]
    st.session_state.goal = ""
    st.session_state.options = ""
    st.session_state.situation = (st.session_state.user_problem or "").strip()

    st.session_state.num_questions = int(st.session_state.get("num_questions", 5))

    st.session_state.q_index = 0
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.probe_mode = ""
    st.session_state.crosscheck_used_for = []

    st.session_state.final_report_json = None
    st.session_state.final_report_raw = None
    st.session_state.decision_matrix_df = None
    st.session_state.report_just_entered = False

    st.session_state.emotion_pre = None
    st.session_state.emotion_post = None

    st.session_state.debug_log = []

    # âœ… ìš”ì•½ ë²„í¼ ì´ˆê¸°í™”
    st.session_state.summary_buffer = ""
    st.session_state.summarized_main_count = 0


def add_answer(q: str, a: str, kind: str, main_index: int, subkind: str = "") -> None:
    st.session_state.answers.append(
        {
            "q": q,
            "a": a,
            "ts": datetime.now().isoformat(timespec="seconds"),
            "kind": kind,  # "main" | "probe"
            "subkind": subkind,
            "main_index": main_index,
        }
    )


def main_answer_count() -> int:
    return sum(1 for x in st.session_state.answers if x.get("kind") == "main")


# =========================
# Helpers
# =========================
def normalize(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


def token_overlap(a: str, b: str) -> float:
    def toks(s: str) -> set:
        s = re.sub(r"[^\wê°€-í£ ]", " ", s)
        s = re.sub(r"\s+", " ", s).strip().lower()
        return set([t for t in s.split(" ") if len(t) >= 2])

    ta, tb = toks(a), toks(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    denom = max(1, min(len(ta), len(tb)))
    return inter / denom


def is_similar(a: str, b: str) -> bool:
    a0, b0 = normalize(a), normalize(b)
    if not a0 or not b0:
        return False
    if a0 == b0:
        return True
    if a0 in b0 or b0 in a0:
        return True
    return token_overlap(a0, b0) >= 0.75


def is_too_short_answer(ans: str) -> bool:
    a = (ans or "").strip()
    if len(a) < MIN_ANSWER_CHARS:
        return True
    for pat in SHORT_ANSWER_PATTERNS:
        if re.search(pat, a):
            return True
    return False


def _has_meaningful_content(ans: str) -> bool:
    a = normalize(ans)
    if not a:
        return False
    signals = 0
    if re.search(r"\d", a):
        signals += 1
    if re.search(r"(ì´ë²ˆ\s*ì£¼|ë‹¤ìŒ\s*ì£¼|ì´ë²ˆ\s*ë‹¬|ì˜¬í•´|ë‚´ë…„|ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ|ì£¼ë§)", a):
        signals += 1
    if re.search(r"(A|B|C)\s*(ì•ˆ|ì„|ë¥¼)?", a):
        signals += 1
    if len(a) >= 35:
        signals += 1
    if a.count(",") >= 2:
        signals += 1
    return signals >= 2


def is_confused_answer(ans: str) -> bool:
    a = (ans or "").strip()
    if not a:
        return False
    has_confused_kw = any(re.search(pat, a) for pat in CONFUSED_ANSWER_PATTERNS)
    if not has_confused_kw:
        return False
    if is_too_short_answer(a):
        return True
    if not _has_meaningful_content(a):
        return True
    return False


def parse_options() -> List[str]:
    return [o.strip() for o in (st.session_state.options or "").split(",") if o.strip()]


def mask_text_for_privacy(text: str) -> str:
    t = text or ""
    t = re.sub(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", "[ì´ë©”ì¼]", t)
    t = re.sub(r"(https?://\S+)", "[ë§í¬]", t)
    t = re.sub(r"\b\d{6,}\b", "[ìˆ«ì]", t)
    t = re.sub(r"\b\d{4}-\d{2}-\d{2}\b", "[ë‚ ì§œ]", t)
    t = re.sub(r"\b\d{1,2}:\d{2}(:\d{2})?\b", "[ì‹œê°„]", t)
    return t


# =========================
# JSON parsing robustness
# =========================
def extract_json_candidates(text: str) -> List[str]:
    if not text:
        return []
    s = text.strip()
    candidates: List[str] = []
    stack = 0
    start = None
    for i, ch in enumerate(s):
        if ch == "{":
            if stack == 0:
                start = i
            stack += 1
        elif ch == "}":
            if stack > 0:
                stack -= 1
                if stack == 0 and start is not None:
                    block = s[start : i + 1].strip()
                    if len(block) >= 2:
                        candidates.append(block)
                    start = None
    candidates = sorted(set(candidates), key=len, reverse=True)
    return candidates


def safe_json_parse(text: str) -> Optional[Dict[str, Any]]:
    if not text:
        return None
    raw = text.strip()
    try:
        obj = json.loads(raw)
        if isinstance(obj, dict):
            return obj
    except Exception:
        pass
    for cand in extract_json_candidates(raw):
        try:
            obj = json.loads(cand)
            if isinstance(obj, dict):
                return obj
        except Exception:
            continue
    return None


# =========================
# âœ… Summary Buffer (Token Cost Control)
# =========================
def _summarize_fallback_rules(mains: List[Dict[str, Any]], limit_chars: int = 1200) -> str:
    """
    OpenAI í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ ìš”ì•½:
    - ê° ë‹µë³€ì˜ ì²« ë¬¸ì¥/ì•ë¶€ë¶„ë§Œ ì¶”ì¶œ
    - ì¤‘ë³µ ì¤„ì´ê³  ê¸¸ì´ ì œí•œ
    """
    bullets: List[str] = []
    for qa in mains:
        a = normalize(str(qa.get("a", "")))
        if not a:
            continue
        first = re.split(r"[.!?ã€‚\n]", a)[0]
        first = first.strip()
        if len(first) < 6:
            first = a[:60].strip()
        if first:
            bullets.append(f"- {first[:160]}")
    s = "\n".join(bullets)
    s = s[:limit_chars].rstrip()
    return s or ""


def _summary_system_prompt() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ëŒ€í™” ìš”ì•½ê¸°ì…ë‹ˆë‹¤.\n"
        "ëª©í‘œ: ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•´ ì´ì „ ëŒ€í™”ë¥¼ ì§§ê³  ì •ë³´ë°€ë„ ìˆê²Œ ìš”ì•½í•©ë‹ˆë‹¤.\n"
        "ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ: ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ.\n"
        "ì¶œë ¥ í˜•ì‹: í•œêµ­ì–´ ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸ë§Œ. (ë¨¸ë¦¬ë§/ë¶€ì—°ì„¤ëª…/ë²ˆí˜¸ ê¸ˆì§€)\n"
        "ê¸¸ì´ ì œí•œ: 8~12ì¤„, ê° ì¤„ 1ë¬¸ì¥, ìµœëŒ€ 1200ì.\n"
        "í¬í•¨í•˜ë©´ ì¢‹ì€ ê²ƒ: í•µì‹¬ ê³ ë¯¼, ëª©í‘œ, ì œì•½, ì˜µì…˜/ëŒ€ì•ˆ, ê¸°ì¤€/ìš°ì„ ìˆœìœ„, ë¶ˆí™•ì‹¤/ë¦¬ìŠ¤í¬, ê°ì •/ê°€ì¹˜ ì‹ í˜¸.\n"
    )


def _summary_user_prompt(existing_summary: str, new_mains: List[Dict[str, Any]]) -> str:
    qa_text = ""
    for i, qa in enumerate(new_mains, start=1):
        qa_text += f"{i}) Q: {qa.get('q','')}\n   A: {qa.get('a','')}\n"
    return textwrap.dedent(
        f"""
        [ê¸°ì¡´ ìš”ì•½]
        {existing_summary if existing_summary.strip() else "(ì—†ìŒ)"}

        [ìƒˆë¡œ ì¶”ê°€ëœ ë©”ì¸ Q/A]
        {qa_text if qa_text.strip() else "(ì—†ìŒ)"}

        ìœ„ì˜ ìƒˆ Q/Aë¥¼ ê¸°ì¡´ ìš”ì•½ì— ë°˜ì˜í•´ì„œ, ë” ì¢‹ì€ 'í†µí•© ìš”ì•½'ì„ ë¶ˆë¦¿ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
        - ì¶”ì²œ/ê²°ë¡ /ì§€ì‹œ ê¸ˆì§€
        - 8~12ì¤„
        - ìµœëŒ€ 1200ì
        """
    ).strip()


def update_summary_buffer_if_needed() -> None:
    """
    - ë©”ì¸ ë‹µë³€ì´ ëˆ„ì ë˜ë©´, ë„ˆë¬´ ì˜¤ë˜ëœ Q/AëŠ” ìš”ì•½ ë²„í¼ë¡œ ì¶•ì•½í•˜ê³ 
      ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ì—ëŠ” (ìš”ì•½ + ìµœê·¼ Q/A)ë§Œ ë³´ë‚´ë„ë¡ í•œë‹¤.
    - 3ê°œ ë©”ì¸ ë‹µë³€ë§ˆë‹¤(ë˜ëŠ” ì„¤ì •) ìš”ì•½ ë²„í¼ ì—…ë°ì´íŠ¸
    """
    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    mcount = len(mains)
    summarized = int(st.session_state.summarized_main_count or 0)

    # ìš”ì•½í•  ê²Œ ì—†ê±°ë‚˜, ì•„ì§ ì—…ë°ì´íŠ¸ ì£¼ê¸° ë¯¸ë„ë‹¬ì´ë©´ ì¢…ë£Œ
    if mcount < SUMMARY_UPDATE_EVERY:
        return
    if mcount - summarized < SUMMARY_UPDATE_EVERY:
        return

    # âœ… ìµœê·¼ windowëŠ” ìš”ì•½ì—ì„œ ì œì™¸(í•­ìƒ ì›ë¬¸ìœ¼ë¡œ ë³´ë‚´ê¸° ìœ„í•¨)
    keep_recent = RECENT_QA_WINDOW
    cutoff = max(0, mcount - keep_recent)

    # ì´ë¯¸ ìš”ì•½ëœ êµ¬ê°„ ì´í›„ë¶€í„° cutoffê¹Œì§€ê°€ "ìƒˆë¡œ ìš”ì•½í•  ë©”ì¸ Q/A"
    start = summarized
    end = min(cutoff, mcount)

    if end <= start:
        return

    new_chunk = mains[start:end]
    if not new_chunk:
        return

    system = _summary_system_prompt()
    user = _summary_user_prompt(st.session_state.summary_buffer or "", new_chunk)

    txt, err, dbg = call_openai_text(system=system, user=user, temperature=0.2)
    st.session_state.debug_log = dbg

    if txt and txt.strip():
        # ë°©ì–´: ë„ˆë¬´ ê¸¸ë©´ ì»·
        merged = txt.strip()
        merged = merged[:1200].rstrip()
        st.session_state.summary_buffer = merged
    else:
        # fallback: ê¸°ì¡´ ìš”ì•½ + ê·œì¹™ ìš”ì•½ì„ í•©ì³ ê¸¸ì´ ì œí•œ
        merged = (st.session_state.summary_buffer or "").strip()
        add = _summarize_fallback_rules(new_chunk, limit_chars=700)
        merged2 = (merged + ("\n" if merged and add else "") + add).strip()
        st.session_state.summary_buffer = merged2[:1200].rstrip()

    st.session_state.summarized_main_count = end


# =========================
# Context builder (token friendly)
# =========================
def build_context_block() -> str:
    """
    âœ… ë³€ê²½ì :
    - Q/A ì „ì²´ ëˆ„ì  ê¸ˆì§€
    - (ìš”ì•½ ë²„í¼) + (ìµœê·¼ 3~4ê°œ Q/A)ë§Œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
    """
    opts = parse_options()
    opts_txt = "\n".join([f"- {o}" for o in opts]) if opts else "(ë¯¸ì…ë ¥)"

    # ìµœê·¼ Q/A (ë©”ì¸+í”„ë¡œë¸Œ ì„ì´ì§€ ì•Šê²Œ â€œìµœê·¼ answersâ€ ì¤‘ ë§ˆì§€ë§‰ ëª‡ ê°œë§Œ)
    # ì§ˆë¬¸ ìƒì„±ì—ëŠ” "ìµœê·¼ ìƒí˜¸ì‘ìš©"ì´ ë„ì›€ì´ ë˜ë¯€ë¡œ answersì—ì„œ tailì„ ì¡ë˜, ê¸¸ì´ëŠ” ì œí•œ
    tail = st.session_state.answers[-(RECENT_QA_WINDOW * 2) :]  # probe í¬í•¨ ì—¬ì§€ -> ì¡°ê¸ˆ ë„‰ë„‰íˆ
    # ê·¸ëŸ¬ë‚˜ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ ìµœì¢…ì ìœ¼ë¡œ ìµœëŒ€ RECENT_QA_WINDOWê°œ â€œë¸”ë¡â€ë§Œ ë‚¨ê¹€
    # (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ëì—ì„œë¶€í„° RECENT_QA_WINDOWê°œë§Œ ì‚¬ìš©)
    tail = tail[-RECENT_QA_WINDOW:] if len(tail) > RECENT_QA_WINDOW else tail

    hist = ""
    for i, qa in enumerate(tail, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        sub = qa.get("subkind", "")
        tag2 = f"{tag}:{sub}" if sub else tag
        a = str(qa.get("a", ""))
        # ë‹µë³€ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ í† í° í­ì¦ ë°©ì§€
        a_short = a.strip()
        if len(a_short) > 420:
            a_short = a_short[:420].rstrip() + "â€¦"
        hist += f"{i}) ({tag2}) Q: {qa.get('q','')}\n   A: {a_short}\n"

    summary = (st.session_state.summary_buffer or "").strip()
    summary_block = summary if summary else "(ì—†ìŒ)"

    return textwrap.dedent(
        f"""
        [ì„¸ì…˜ ì‹œì‘ ì •ë³´]
        - ì¹´í…Œê³ ë¦¬: {st.session_state.category}
        - ê²°ì • ìœ í˜•: {st.session_state.decision_type}
        - ìƒí™© ì„¤ëª…: {st.session_state.situation or "(ë¯¸ì…ë ¥)"}
        - ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal or "(ë¯¸ì…ë ¥)"}
        - ê³ ë ¤ ì˜µì…˜(ìˆë‹¤ë©´): {opts_txt}

        [ìš”ì•½ ë²„í¼(ì´ì „ ë‚´ìš© ì••ì¶•)]
        {summary_block}

        [ìµœê·¼ Q/A(ì›ë¬¸ ì¼ë¶€)]
        {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
        """
    ).strip()


# =========================
# Onboarding (AI ì¶”ì²œ)
# =========================
def system_prompt_for_onboarding() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì˜¨ë³´ë”© ë¶„ì„ê¸°ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìì˜ ê³ ë¯¼ í…ìŠ¤íŠ¸ë¥¼ ì½ê³ , ì•„ë˜ í•­ëª©ì„ 'ë¶„ë¥˜/ì´ˆì•ˆ ì œì•ˆ' ìˆ˜ì¤€ìœ¼ë¡œë§Œ ì¶”ì²œí•˜ì„¸ìš”.\n"
        "ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.\n"
    )


def user_prompt_for_onboarding(problem_text: str) -> str:
    cats = [c[0] for c in TOPIC_CATEGORIES]
    coaches = [{"id": c["id"], "name": c["name"], "tagline": c["tagline"]} for c in COACHES]
    dtypes = DECISION_TYPES
    return textwrap.dedent(
        f"""
        [ì‚¬ìš©ì ê³ ë¯¼]
        {problem_text}

        [ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬]
        {cats}

        [ê°€ëŠ¥í•œ ê²°ì • ìœ í˜•]
        {dtypes}

        [ê°€ëŠ¥í•œ ì½”ì¹˜]
        {coaches}

        ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì¶œë ¥:
        {{
          "recommended_category": "string",
          "recommended_decision_type": "string",
          "recommended_coach_id": "string (logic|value|action)",
          "coach_reason": "string",
          "goal_draft": "string (ì´ˆì•ˆ, ì§€ì‹œ/ì¶”ì²œ ê¸ˆì§€)",
          "options_hint": "string (ì§ˆë¬¸í˜• íŒíŠ¸, ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)"
        }}
        """
    ).strip()


def onboarding_fallback(problem_text: str) -> Dict[str, Any]:
    txt = normalize(problem_text)
    cat = "ğŸ“¦ ê¸°íƒ€"
    if any(k in txt for k in ["ì·¨ì—…", "ì´ì§", "ì§„ë¡œ", "ì „ê³µ", "í•™ì—…", "ëŒ€í•™ì›"]):
        cat = "ğŸ“ í•™ì—…/ì§„ë¡œ"
    elif any(k in txt for k in ["í”„ë¡œì íŠ¸", "ì—…ë¬´", "íŒ€", "íšŒì‚¬", "ë¦¬ë”", "ì„±ê³¼", "ì»¤ë¦¬ì–´"]):
        cat = "ğŸ’¼ ì»¤ë¦¬ì–´/ì¼"
    elif any(k in txt for k in ["ì—°ì¸", "ì¹œêµ¬", "ê°€ì¡±", "ê°ˆë“±", "ê´€ê³„", "ëŒ€í™”"]):
        cat = "ğŸ’– ê´€ê³„"
    elif any(k in txt for k in ["ëˆ", "ì˜ˆì‚°", "ì†Œë¹„", "ì €ì¶•", "íˆ¬ì", "êµ¬ë§¤"]):
        cat = "ğŸ’° ëˆ/ì†Œë¹„"
    elif any(k in txt for k in ["ë¶ˆì•ˆ", "ë²ˆì•„ì›ƒ", "ìš°ìš¸", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë§ˆìŒ", "ì‚¶"]):
        cat = "ğŸ§  ë§ˆìŒ/ì‚¶"

    dtype = "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)" if any(k in txt for k in ["í• ê¹Œ", "ë§ê¹Œ", "í•´ì•¼", "ê·¸ë§Œ", "ì‹œì‘"]) else "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ"
    coach_id = "logic"
    if any(k in txt for k in ["ë¶ˆì•ˆ", "í›„íšŒ", "ê°ì •", "ë§ˆìŒ", "ê´€ê³„"]):
        coach_id = "value"
    if any(k in txt for k in ["ê³„íš", "ì‹¤í–‰", "ë£¨í‹´", "ìŠµê´€", "ì¼ì •", "ê³µë¶€ë²•"]):
        coach_id = "action"

    return {
        "recommended_category": cat,
        "recommended_decision_type": dtype,
        "recommended_coach_id": coach_id,
        "coach_reason": "ê³ ë¯¼ í…ìŠ¤íŠ¸ì—ì„œ ë‘ë“œëŸ¬ì§€ëŠ” ì •ë¦¬ í¬ì¸íŠ¸ì— ë§ì¶˜ ì´ˆì•ˆì…ë‹ˆë‹¤.",
        "goal_draft": "ì§€ê¸ˆ ê³ ë¯¼ì—ì„œ ë‚´ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê¸°ì¤€ê³¼ ê°ë‹¹ ê°€ëŠ¥í•œ ë¦¬ìŠ¤í¬ë¥¼ ë” ì„ ëª…í•˜ê²Œ ì ì–´ë³´ê³  ì‹¶ë‹¤(ì´ˆì•ˆ).",
        "options_hint": "ì§€ê¸ˆ ë– ì˜¤ë¥´ëŠ” ì„ íƒì§€/ê°€ëŠ¥ì„±(ìˆë‹¤ë©´)ì„ ì‰¼í‘œë¡œ 2~4ê°œë§Œ ì ì–´ë³¼ ìˆ˜ ìˆì„ê¹Œìš”?",
    }


def generate_onboarding_recommendation(problem_text: str) -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    system = system_prompt_for_onboarding()
    user = user_prompt_for_onboarding(problem_text)
    txt, err, dbg = call_openai_text(system=system, user=user, temperature=0.2)
    if not txt:
        fb = onboarding_fallback(problem_text)
        dbg.append("Onboarding fallback used (no model output).")
        return fb, err, dbg, None
    data = safe_json_parse(txt)
    if not data:
        fb = onboarding_fallback(problem_text)
        dbg.append("Onboarding fallback used (JSON parse fail).")
        return fb, "ì˜¨ë³´ë”© ì¶”ì²œ JSON íŒŒì‹± ì‹¤íŒ¨(ëŒ€ì²´ ì´ˆì•ˆì„ í‘œì‹œí•©ë‹ˆë‹¤)", dbg, txt
    return data, None, dbg, txt


# =========================
# Question generation
# =========================
def system_prompt_for_questions(coach: Dict[str, Any]) -> str:
    base = (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì •ë‹µ/í•´ê²°ì±…/ì¶”ì²œì„ ì£¼ì§€ ë§ê³ , ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•˜ë„ë¡ ì§ˆë¬¸ë§Œ ë˜ì§€ì„¸ìš”.\n"
        "ê¸ˆì§€: ê²°ë¡ , ì¶”ì²œ, ì„ íƒ ê°•ìš”, íŒë‹¨ë¬¸, ì§€ì‹œë¬¸(í•´ì•¼ í•œë‹¤/í•˜ì).\n"
        "ì¶œë ¥: ì§ˆë¬¸ 1ê°œë§Œ.\n"
    )
    if coach["id"] == "logic":
        return base + "ìŠ¤íƒ€ì¼: êµ¬ì¡°í™”/ê¸°ì¤€/ì—­ë°œìƒ ì§ˆë¬¸.\n"
    if coach["id"] == "value":
        return base + "ìŠ¤íƒ€ì¼: ê°ì • ë¼ë²¨ë§ + ê°ì •/ê°€ì¹˜ ë¶„ë¦¬ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸.\n"
    return base + "ìŠ¤íƒ€ì¼: If-Then/í”„ë¦¬ëª¨í…œ/ìš°ì„ ìˆœìœ„/Quick Winì„ ì§ˆë¬¸ìœ¼ë¡œë§Œ ìœ ë„.\n"


def probing_instruction(last_q: str, last_a: str) -> str:
    return textwrap.dedent(
        f"""
        ì‚¬ìš©ìì˜ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª¨í˜¸í•©ë‹ˆë‹¤.
        ì§ì „ Q/Aë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´í™”ë¥¼ ë•ëŠ” ì¶”ê°€ ì§ˆë¬¸ 1ê°œ(Probe)ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

        - ì§ì „ ì§ˆë¬¸: {last_q}
        - ì§ì „ ë‹µë³€: {last_a}

        ìš”êµ¬ì‚¬í•­:
        - ì˜ˆì‹œ/ìƒí™©/ê¸°ì¤€/ì´ìœ /ë²”ìœ„/ê¸°ê°„/ìš°ì„ ìˆœìœ„ ì¤‘ í•˜ë‚˜ë¥¼ ë” ë¬»ê¸°
        - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ ê¸ˆì§€
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
        """
    ).strip()


def reframe_instruction(last_q: str, last_a: str) -> str:
    return textwrap.dedent(
        f"""
        ì‚¬ìš©ìê°€ "ì˜ ëª¨ë¥´ê² ì–´ìš”/ê°ì´ ì•ˆ ì™€ìš”/ì–´ë ¤ì›Œìš”" ê°™ì€ ë°˜ì‘ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
        ì§ˆë¬¸ì„ ë” ì‰½ê²Œ í’€ì–´ ì“°ê±°ë‚˜(ì¬í”„ë ˆì´ë°), ë” ë‹µí•˜ê¸° ì‰¬ìš´ ëŒ€ì²´ ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

        [ì‚¬ìš©ì ìƒí™© ì„¤ëª…]
        {st.session_state.situation or "(ë¯¸ì…ë ¥)"}

        [ì§ì „ ì§ˆë¬¸]
        {last_q}

        [ì‚¬ìš©ì ë‹µë³€]
        {last_a}

        ìš”êµ¬ì‚¬í•­:
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
        - ì¶”ì²œ/ì§€ì‹œ/íŒë‹¨ ê¸ˆì§€
        - ë‹µí•˜ê¸° ì‰¬ìš´ í˜•íƒœ(ë²”ìœ„ ì¢íˆê¸°/ë‘˜ ì¤‘ ë¬´ì—‡ì— ê°€ê¹Œìš´ì§€/ì˜ˆì‹œ ìš”êµ¬ ë“±)
        """
    ).strip()


def crosscheck_system_prompt() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ë…¼ë¦¬ ì¶©ëŒ ê°ì§€ê¸°ì…ë‹ˆë‹¤.\n"
        "ì´ì „ ë‹µë³€ë“¤ ì‚¬ì´ì— ê¸°ì¤€/ìš°ì„ ìˆœìœ„/ëª©í‘œì˜ ì¶©ëŒ(ê¸´ì¥)ì´ ìˆëŠ”ì§€ ì ê²€í•˜ì„¸ìš”.\n"
        "ì¤‘ìš”: ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.\n"
    )


def crosscheck_user_prompt(current_main_index: int) -> str:
    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    tail = mains[-6:]  # crosscheckëŠ” ì§§ê²Œ ìœ ì§€(ì´ë¯¸ ë¹„ìš© ê´€ë¦¬ë¨)
    qa = ""
    for i, x in enumerate(tail, start=1):
        qa += f"{i}) Q: {x['q']}\n   A: {x['a']}\n"

    return textwrap.dedent(
        f"""
        ì•„ë˜ ë‹µë³€ë“¤ ì‚¬ì´ì— ê¸°ì¤€/ìš°ì„ ìˆœìœ„ ìƒì¶©ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.
        ì¶©ëŒì´ ìˆë‹¤ë©´, ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì œì•ˆí•˜ì„¸ìš”.
        ì¶©ëŒì´ ì—†ë‹¤ë©´ has_conflict=false.

        [ë‹µë³€ë“¤]
        {qa if qa.strip() else "(ë‹µë³€ ì—†ìŒ)"}

        [ì¶œë ¥ JSON]
        {{
          "has_conflict": true/false,
          "conflict_summary": "string (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
          "question": "string (has_conflict=trueì¼ ë•Œë§Œ, ì§ˆë¬¸ 1ê°œ)"
        }}

        current_main_index={current_main_index}
        """
    ).strip()


def try_logic_crosscheck_question(main_index: int) -> Tuple[Optional[str], List[str]]:
    dbg: List[str] = []
    used_set = set(int(x) for x in (st.session_state.crosscheck_used_for or []))
    if main_index in used_set:
        return None, dbg

    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    if len(mains) < 2:
        return None, dbg

    system = crosscheck_system_prompt()
    user = crosscheck_user_prompt(main_index)
    txt, err, d = call_openai_text(system=system, user=user, temperature=0.2)
    dbg.extend(d)
    if not txt:
        if err:
            dbg.append(f"Crosscheck error: {err}")
        return None, dbg

    data = safe_json_parse(txt)
    if not data:
        dbg.append("Crosscheck JSON parse failed.")
        return None, dbg

    has_conflict = bool(data.get("has_conflict", False))
    q = normalize(str(data.get("question", "") or ""))

    used_set.add(main_index)
    st.session_state.crosscheck_used_for = sorted(list(used_set))

    if has_conflict and q:
        dbg.append("Crosscheck conflict detected -> using conflict question.")
        return q, dbg

    dbg.append("Crosscheck: no conflict (or no question).")
    return None, dbg


def instruction_for_question(i: int, n: int, coach_id: str) -> str:
    if i == 0:
        return "ìƒí™©ì˜ í•µì‹¬ì„ ë” êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
    if i == 1:
        return "ì›í•˜ëŠ” ëª©í‘œë¥¼ ì¸¡ì • ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "action":
        if i == n - 1:
            return "â€˜ì§€ê¸ˆ ì•±ì„ ë„ê³  5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ì„ ìŠ¤ìŠ¤ë¡œ ì ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ í¼ì¹˜ê³  Top1~3 ìš°ì„ ìˆœìœ„ë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸(íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œ)"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return "í”„ë¦¬ëª¨í…œ + If-Then íŠ¸ë¦¬ê±° ì„¤ê³„ ì§ˆë¬¸ 1ê°œ"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "logic":
        if i == 2:
            return "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        return "ì˜µì…˜/ì •ë³´/ì œì•½ì„ ë¶„ë¦¬í•´ ëª…ë£Œí™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "value":
        if i == 2:
            return "ì§€ê¸ˆ ê°ì • 2~3ê°œì™€ ì´ìœ ë¥¼ ë§í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 2:
            return "í›„íšŒ ìµœì†Œí™”(ë¯¸ë˜ ê´€ì ) ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ â€˜ë‚´ ê¸°ì¤€â€™ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        return "ê°€ì¹˜ Top3ë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    return "ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œ"


def fallback_question(coach_id: str, i: int, n: int) -> str:
    if i == 0:
        return "ì§€ê¸ˆ ê³ ë¯¼ì—ì„œ â€˜ê°€ì¥ í•µì‹¬ì ì¸ ìŸì â€™ì€ ë¬´ì—‡ì¸ê°€ìš”? (í•œ ë¬¸ì¥)"
    if i == 1:
        return "ì´ë²ˆ ê²°ì •ìœ¼ë¡œ ì–»ê³  ì‹¶ì€ ëª©í‘œë¥¼ â€˜ì¸¡ì • ê°€ëŠ¥í•˜ê²Œâ€™ ë°”ê¾¸ë©´ ì–´ë–»ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‚˜ìš”? (ì–¸ì œê¹Œì§€/ì–´ëŠ ì •ë„)"
    if coach_id == "action":
        if i == n - 1:
            return "ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” â€˜ê°€ì¥ ì‘ì€ í–‰ë™â€™ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ ì ê³ , íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return "2ì£¼ ë’¤ ì‹¤íŒ¨í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ 3ê°€ì§€ëŠ” ë¬´ì—‡ì´ê³  ê°ê° â€˜ë§Œì•½ ~ì´ë©´ â†’ ~í•œë‹¤â€™ë¡œ ëŒ€ì‘ì„ ì ì–´ë³¼ ìˆ˜ ìˆë‚˜ìš”?"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”í•˜ë©´(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ì¡°ê±´ì—ì„œ) ì–´ë–»ê²Œ ì ì„ ìˆ˜ ìˆë‚˜ìš”?"
    if coach_id == "logic":
        if i == 2:
            return "ì´ ì„ íƒì„ í‰ê°€í•  ê¸°ì¤€ 3~5ê°œë¥¼ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 1:
            return "ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        return "ì˜µì…˜/ì œì•½/ì •ë³´ë¥¼ ë¶„ë¦¬í•´ì„œ ì§€ê¸ˆ ë¶€ì¡±í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ì§€ ì ì–´ë³¼ê¹Œìš”?"
    if i == 2:
        return "ì§€ê¸ˆ ê°ì •ì„ 2~3ê°œ ë‹¨ì–´ë¡œ ì ê³ , ê° ê°ì •ì´ ìƒê¸´ ì´ìœ ë¥¼ í•œ ì¤„ì”© ì¨ë³¼ê¹Œìš”?"
    if i == n - 2:
        return "1ë…„/5ë…„ ë’¤ì˜ ë‚´ê°€ ì§€ê¸ˆì˜ ë‚˜ì—ê²Œ ë­ë¼ê³  ë§í•´ì¤„ ê²ƒ ê°™ë‚˜ìš”?"
    if i == n - 1:
        return "ì´ ê³ ë¯¼ì—ì„œ ë‚´ê°€ ë†“ì¹˜ê³  ì‹¶ì§€ ì•Šì€ ê¸°ì¤€ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì“°ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?"
    return "ì´ ê³ ë¯¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°€ì¹˜ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"


def generate_question(i: int, n: int) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    prev_qs = st.session_state.questions[:]

    cross_q, cross_dbg = try_logic_crosscheck_question(i)
    if cross_q and not any(is_similar(cross_q, pq) for pq in prev_qs):
        return cross_q, None, cross_dbg

    dbg_acc: List[str] = cross_dbg[:]

    def prompt(nonce: int) -> str:
        prev_txt = "\n".join([f"- {q}" for q in prev_qs[-6:]]) if prev_qs else "(ì—†ìŒ)"
        return textwrap.dedent(
            f"""
            [ìµœê·¼ ì§ˆë¬¸ ëª©ë¡]
            {prev_txt}

            {build_context_block()}

            [ì´ë²ˆ ì§ˆë¬¸ ëª©ì ]
            {instruction_for_question(i, n, coach["id"])}

            ê·œì¹™:
            - ê²°ë¡ /ì¶”ì²œ/ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
            - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
            - ì´ì „ ì§ˆë¬¸ê³¼ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ í”¼í•˜ê¸°

            (nonce={nonce})
            """
        ).strip()

    q1, err, dbg = call_openai_text(system=system, user=prompt(random.randint(1000, 9999)), temperature=0.7)
    dbg_acc.extend(dbg)
    if not q1:
        return fallback_question(coach["id"], i, n), err, dbg_acc

    q1 = normalize(q1)
    if not any(is_similar(q1, pq) for pq in prev_qs):
        return q1, None, dbg_acc

    dbg_acc.append("Similar question detected. Regenerating once.")
    q2, err2, dbg2 = call_openai_text(system=system, user=prompt(random.randint(10000, 99999)), temperature=0.85)
    dbg_acc.extend(dbg2)
    if q2:
        q2 = normalize(q2)
        if not any(is_similar(q2, pq) for pq in prev_qs):
            return q2, None, dbg_acc

    dbg_acc.append("Still similar after retry. Using fallback.")
    return fallback_question(coach["id"], i, n), err2, dbg_acc


def ensure_question(index: int, total: int) -> None:
    while len(st.session_state.questions) <= index:
        i = len(st.session_state.questions)
        q, err, dbg = generate_question(i, total)
        st.session_state.debug_log = dbg
        st.session_state.questions.append(q)


def generate_probe_question(last_q: str, last_a: str) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    user = probing_instruction(last_q, last_a)
    q, err, dbg = call_openai_text(system=system, user=user, temperature=0.6)
    if not q:
        return "ë°©ê¸ˆ ë‹µë³€ì—ì„œ â€˜ì˜ˆì‹œ 1ê°œâ€™ë§Œ ë“¤ì–´ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì„¤ëª…í•´ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?", err, dbg
    return normalize(q), None, dbg


def generate_reframe_question(last_q: str, last_a: str) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    user = reframe_instruction(last_q, last_a)
    q, err, dbg = call_openai_text(system=system, user=user, temperature=0.55)
    if not q:
        return "ì´ ì§ˆë¬¸ì´ ì–´ë µë‹¤ë©´, â€˜ì´ë²ˆ ìƒí™©ì—ì„œ ê°€ì¥ ì‹ ê²½ ì“°ì´ëŠ” í•œ ê°€ì§€â€™ë§Œ ê³ ë¥´ë©´ ë¬´ì—‡ì¸ê°€ìš”?", err, dbg
    return normalize(q), None, dbg


# =========================
# Report generation + rendering (ì›ë³¸ ê·¸ëŒ€ë¡œ: ì—¬ê¸°ì„œëŠ” ì§€ë©´ìƒ ìƒëµí•˜ì§€ ì•Šê³  í¬í•¨)
# =========================
FORBIDDEN_RECOMMEND_PATTERNS = [
    r"ì¶”ì²œí•©ë‹ˆë‹¤",
    r"ì¶”ì²œë“œ",
    r"~?í•˜ëŠ” ê²ƒì´ ì¢‹",
    r"~?í•˜ëŠ” ê²Œ ì¢‹",
    r"~?í•˜ì‹œë©´ ì¢‹",
    r"í•´ì•¼ í•©ë‹ˆë‹¤",
    r"í•˜ì‹œê¸¸",
    r"í•˜ëŠ” ê²Œ ë‚«",
    r"ì •ë‹µ(ì€|:)",
    r"ê²°ë¡ (ì€|:)",
    r"\bAë¥¼\s*ì„ íƒ",
    r"\bBë¥¼\s*ì„ íƒ",
]


def contains_forbidden_recommendation(text: str) -> bool:
    t = text or ""
    for pat in FORBIDDEN_RECOMMEND_PATTERNS:
        if re.search(pat, t):
            return True
    return False


def report_schema_hint(coach_id: str) -> str:
    base = """
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”(ì½”ë“œë¸”ë¡/ì„¤ëª… ê¸ˆì§€).
ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.
coaching_messageëŠ” ë°˜ë“œì‹œ "ê±°ìš¸ ë¹„ì¶”ê¸°(Mirroring)" í™”ë²•ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
ê¸ˆì§€ í‘œí˜„: "ì¶”ì²œí•©ë‹ˆë‹¤", "ì¢‹ê² ìŠµë‹ˆë‹¤", "í•´ì•¼ í•©ë‹ˆë‹¤", "í•˜ì", "ì •ë‹µ", "ê²°ë¡ ", "Aë¥¼ ì„ íƒ".
"""
    common_extra = """
ì¶”ê°€ í•„ë“œ:
- "info_check_questions": ["string", ...]  # ì§ˆë¬¸ í˜•íƒœ 1~3ê°œ
"""
    if coach_id == "action":
        return textwrap.dedent(
            base
            + common_extra
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {"core_issue":"string","goal":"string","constraints":["string"],"options_mentioned":["string"]},
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "plan_visualization": {"year":"string","month":"string","week":["string","string","string"]},
  "weekly_table": {"Mon":["string"],"Tue":["string"],"Wed":["string"],"Thu":["string"],"Fri":["string"],"Sat":["string"],"Sun":["string"]},
  "info_check_questions": ["string"],
  "coaching_message": ["string","string"],
  "next_self_question": "string"
}
"""
        ).strip()
    if coach_id == "logic":
        return textwrap.dedent(
            base
            + common_extra
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {"core_issue":"string","goal":"string","constraints":["string"],"options_mentioned":["string"]},
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "key_points": {"uncertainties":["string"],"tradeoffs":["string"]},
  "info_check_questions": ["string"],
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
        ).strip()
    return textwrap.dedent(
        base
        + common_extra
        + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {"core_issue":"string","goal":"string","constraints":["string"],"options_mentioned":["string"]},
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "emotions_values": {"emotions":["string","string"],"top_values":["string","string","string"]},
  "info_check_questions": ["string"],
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
    ).strip()


def system_prompt_for_report() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ìµœì¢… ìš”ì•½ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì˜¤ì§ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬/ê¸°ì¤€/ê¸´ì¥/ë¶ˆí™•ì‹¤ì„±ì„ ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)í•˜ì„¸ìš”.\n"
        "coaching_messageëŠ” ë°˜ë“œì‹œ ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.\n"
    )


def build_qa_text_for_report() -> str:
    qa_text = ""
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        qa_text += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"
    return qa_text


def fallback_report_json() -> Dict[str, Any]:
    coach = coach_by_id(st.session_state.coach_id)
    opts = parse_options()
    base = {
        "summary": {
            "core_issue": normalize(st.session_state.situation)[:180] or "í•µì‹¬ ê³ ë¯¼ì´ ìš”ì•½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "goal": normalize(st.session_state.goal)[:180] or "ëª©í‘œê°€ ëª…í™•íˆ ì íˆì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "constraints": [],
            "options_mentioned": opts or [],
        },
        "criteria": [],
        "info_check_questions": [
            "ì´ ê²°ì •ì„ ë” ê°€ë³ê²Œ ë§Œë“¤ê¸° ìœ„í•´, ì§€ê¸ˆ â€˜í™•ì¸ë˜ì§€ ì•Šì€ ì‚¬ì‹¤/ê°€ì •â€™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ìµœì•…ì˜ ê²½ìš°ë¥¼ ìƒìƒí–ˆì„ ë•Œ, ì‹¤ì œë¡œ ê°ë‹¹ ê°€ëŠ¥í•œ ë¹„ìš©/ì†ì‹¤ì˜ ë²”ìœ„ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
        ],
        "coaching_message": [
            "ì§€ê¸ˆì€ â€˜ì •ë¦¬â€™ê°€ í•„ìš”í•˜ë‹¤ëŠ” ëŠë‚Œê³¼, ë™ì‹œì— â€˜í™•ì‹ ì´ ë¶€ì¡±í•˜ë‹¤â€™ëŠ” ëŠë‚Œì´ í•¨ê»˜ ìˆëŠ” ìƒíƒœì²˜ëŸ¼ ë³´ì…ë‹ˆë‹¤.",
            "ë‹¹ì‹ ì—ê²Œ ì¤‘ìš”í•œ ê¸°ì¤€ì´ ë¬´ì—‡ì¸ì§€ê°€ ì„ ëª…í•´ì§ˆìˆ˜ë¡, ì„ íƒì´ ëœ ë¬´ê²ê²Œ ëŠê»´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”.",
        ],
        "next_self_question": "ë‚´ê°€ ì§€ê¸ˆ ê°€ì¥ ë†“ì¹˜ê¸° ì‹«ì€ ê¸°ì¤€ 1ê°œëŠ” ë¬´ì—‡ì´ê³ , ì™œ ê·¸ê²ƒì´ ì¤‘ìš”í•œê°€ìš”?",
    }
    if coach["id"] == "logic":
        base["key_points"] = {"uncertainties": [], "tradeoffs": []}
    elif coach["id"] == "action":
        base["plan_visualization"] = {"year": "", "month": "", "week": []}
        base["weekly_table"] = {"Mon": [], "Tue": [], "Wed": [], "Thu": [], "Fri": [], "Sat": [], "Sun": []}
    else:
        base["emotions_values"] = {"emotions": [], "top_values": []}
    return base


def generate_final_report_json() -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_report()

    qa_text = build_qa_text_for_report()
    opts = parse_options()

    user = textwrap.dedent(
        f"""
{report_schema_hint(coach["id"])}

[ì„¸ì…˜ ì‹œì‘ ì •ë³´]
- ì¹´í…Œê³ ë¦¬: {st.session_state.category}
- ê²°ì • ìœ í˜•: {st.session_state.decision_type}
- ìƒí™© ì„¤ëª…: {st.session_state.situation}
- ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal}
- ì˜µì…˜(ìˆë‹¤ë©´): {opts if opts else "(ì—†ìŒ)"}

[Q/A]
{qa_text}

ì¤‘ìš”:
- ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
- coaching_messageëŠ” ê±°ìš¸ ë¹„ì¶”ê¸°ë§Œ
- info_check_questionsëŠ” ì§ˆë¬¸ í˜•íƒœë¡œ 1~3ê°œë§Œ
"""
    ).strip()

    text, err, dbg = call_openai_text(system=system, user=user, temperature=0.25)
    if not text:
        fb = fallback_report_json()
        dbg.append("Report fallback used (no model output).")
        return fb, err, dbg, None

    data = safe_json_parse(text)
    if data is None:
        fb = fallback_report_json()
        dbg.append("Report fallback used (JSON parse fail).")
        return fb, "ë¦¬í¬íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨(ëŒ€ì²´ ì •ë¦¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤)", dbg, text

    combined = json.dumps(data, ensure_ascii=False)
    if contains_forbidden_recommendation(combined):
        dbg.append("Forbidden phrasing detected. Regenerating once.")
        stricter_user = user + "\n\n[ê²½ê³ ] ì¶”ì²œ/ì§€ì‹œ í‘œí˜„ ê¸ˆì§€. ê±°ìš¸ ë¹„ì¶”ê¸°ë§Œ."
        text2, err2, dbg2 = call_openai_text(system=system, user=stricter_user, temperature=0.1)
        dbg.extend(dbg2)
        if text2:
            data2 = safe_json_parse(text2)
            if data2 is not None and not contains_forbidden_recommendation(json.dumps(data2, ensure_ascii=False)):
                return data2, None, dbg, text2
        return data, None, dbg, text

    return data, None, dbg, text


# =========================
# UI helpers (ë¦¬í¬íŠ¸ ë Œë”ë§ ë“±) - ì´ì „ ë²„ì „ê³¼ ë™ì¼
# (ê¸¸ì´ ë•Œë¬¸ì— ê¸°ëŠ¥ì„ â€˜ì‚­ì œâ€™í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ í¬í•¨í•©ë‹ˆë‹¤)
# =========================
def render_summary_block(data: Dict[str, Any]) -> None:
    s = data.get("summary", {}) or {}
    st.subheader("ê³ ë¯¼ì˜ í•µì‹¬ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.write(f"**í•µì‹¬ ê³ ë¯¼:** {s.get('core_issue','')}")
        st.write(f"**ëª©í‘œ:** {s.get('goal','')}")
    with c2:
        cons = s.get("constraints", []) or []
        opts = s.get("options_mentioned", []) or []
        st.write("**ì œì•½/ì¡°ê±´:**")
        if cons:
            for x in cons:
                st.write(f"- {x}")
        else:
            st.caption("ì œì•½ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        st.write("**ì–¸ê¸‰ëœ ì˜µì…˜:**")
        if opts:
            for x in opts:
                st.write(f"- {x}")
        else:
            st.caption("ì˜µì…˜ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")


def render_criteria(data: Dict[str, Any]) -> List[str]:
    st.subheader("ì„ íƒ ê¸°ì¤€ ì •ë¦¬(ìš°ì„ ìˆœìœ„ í¬í•¨)")
    crit = data.get("criteria", []) or []
    if not crit:
        st.caption("ì„ íƒ ê¸°ì¤€ì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
        return []
    rows = []
    names: List[str] = []
    for c in crit:
        nm = str(c.get("name", "") or "").strip()
        if nm:
            names.append(nm)
        rows.append({"ê¸°ì¤€": nm, "ìš°ì„ ìˆœìœ„(1~5)": c.get("priority", ""), "ì™œ ì¤‘ìš”í•œê°€": c.get("why", "")})
    st.dataframe(rows, use_container_width=True, hide_index=True)
    return names


def render_action_visualization(data: Dict[str, Any]) -> None:
    st.subheader("ê³„íš ì •ë¦¬(ë…„ â†’ ë‹¬ â†’ ì£¼) â€” ì‚¬ìš©ì ë‹µë³€ ê¸°ë°˜")
    pv = data.get("plan_visualization", {}) or {}
    c1, c2, c3 = st.columns(3)
    c1.metric("ë…„", pv.get("year", "") or "-")
    c2.metric("ë‹¬", pv.get("month", "") or "-")
    c3.metric("ì£¼(í•µì‹¬ 3ê°œ)", " ")
    week = pv.get("week", []) or []
    if week:
        for x in week:
            st.write(f"- {x}")
    else:
        st.caption("ì£¼ ë‹¨ìœ„ ê³„íšì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
    st.subheader("ì£¼ê°„ í…Œì´ë¸”(ì •ë¦¬ìš©)")
    cal = data.get("weekly_table", {}) or {}
    days = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
    table = [{"Day": d, "Tasks": "\n".join(cal.get(d, []) or [])} for d in days]
    st.dataframe(table, use_container_width=True, hide_index=True)


def render_key_points_logic(data: Dict[str, Any]) -> None:
    kp = data.get("key_points", {}) or {}
    st.subheader("ì •ë¦¬ í¬ì¸íŠ¸")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„**")
        for x in kp.get("uncertainties", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**íŠ¸ë ˆì´ë“œì˜¤í”„**")
        for x in kp.get("tradeoffs", []) or []:
            st.write(f"- {x}")


def render_emotions_values(data: Dict[str, Any]) -> None:
    ev = data.get("emotions_values", {}) or {}
    st.subheader("ê°ì •/ê°€ì¹˜ ì •ë¦¬")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ê°ì •**")
        for x in ev.get("emotions", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**ê°€ì¹˜ Top3**")
        for x in ev.get("top_values", []) or []:
            st.write(f"- {x}")


def render_info_check_questions(data: Dict[str, Any]) -> None:
    st.subheader("ì •ë³´ ë¶€ì¡± ì²´í¬ë¦¬ìŠ¤íŠ¸(ì§ˆë¬¸ í˜•íƒœ)")
    qs = data.get("info_check_questions", []) or []
    qs = [str(x).strip() for x in qs if str(x).strip()]
    if not qs:
        st.caption("ì¶”ê°€ë¡œ í™•ì¸í•  ì§ˆë¬¸ì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
        return
    for q in qs[:3]:
        st.write(f"- {q}")


TENSION_AXES = [
    ("ì•ˆì •", "ì„±ì¥"),
    ("ììœ ", "ì•ˆì •"),
    ("ëˆ", "ì‹œê°„"),
    ("ì†ë„", "ì™„ì„±ë„"),
    ("ì„±ê³¼", "ê±´ê°•"),
    ("ê´€ê³„", "ê²½ê³„"),
    ("ë„ì „", "ì•ˆì •"),
    ("ë‹¨ê¸°", "ì¥ê¸°"),
]


def _collect_tension_signals(data: Dict[str, Any]) -> Dict[str, str]:
    s = data.get("summary", {}) or {}
    crit = data.get("criteria", []) or []
    crit_text = " ".join([str(c.get("name", "")) + " " + str(c.get("why", "")) for c in crit if isinstance(c, dict)])
    core = str(s.get("core_issue", "") or "")
    goal = str(s.get("goal", "") or "")
    extras = ""
    if "key_points" in data:
        kp = data.get("key_points", {}) or {}
        extras += " " + " ".join(kp.get("uncertainties", []) or [])
        extras += " " + " ".join(kp.get("tradeoffs", []) or [])
    if "emotions_values" in data:
        ev = data.get("emotions_values", {}) or {}
        extras += " " + " ".join(ev.get("emotions", []) or [])
        extras += " " + " ".join(ev.get("top_values", []) or [])
    blob = normalize(" ".join([core, goal, crit_text, extras]))
    return {"blob": blob}


def render_tension_map(data: Dict[str, Any]) -> None:
    st.subheader("ëª¨ìˆœ/ê¸´ì¥ ì§€ë„(ê´€ì°°ìš©)")
    st.caption("ê²°ë¡ ì„ ë‚´ê¸° ìœ„í•œ ê²Œ ì•„ë‹ˆë¼, â€˜ê¸°ì¤€ë“¤ì´ ì–´ë””ì—ì„œ ì„œë¡œ ë‹¹ê¸°ëŠ”ì§€â€™ë¥¼ ë³´ëŠ” ì§€ë„ì˜ˆìš”.")

    sig = _collect_tension_signals(data)
    blob = sig["blob"]

    found_axes = []
    for a, b in TENSION_AXES:
        if (a in blob) and (b in blob):
            found_axes.append((a, b))

    crit = data.get("criteria", []) or []
    crit_sorted = []
    for c in crit:
        try:
            p = int(c.get("priority", 999))
        except Exception:
            p = 999
        crit_sorted.append((p, str(c.get("name", "") or "").strip()))
    crit_sorted = [x for x in sorted(crit_sorted, key=lambda x: x[0]) if x[1]]
    top3 = [x[1] for x in crit_sorted[:3]]

    uncertainties = []
    if "key_points" in data:
        kp = data.get("key_points", {}) or {}
        uncertainties = [str(x).strip() for x in (kp.get("uncertainties", []) or []) if str(x).strip()]

    emotions = []
    if "emotions_values" in data:
        ev = data.get("emotions_values", {}) or {}
        emotions = [str(x).strip() for x in (ev.get("emotions", []) or []) if str(x).strip()]

    c1, c2, c3 = st.columns(3)
    with c1:
        st.write("**ê¸°ì¤€ Top3**")
        if top3:
            for x in top3:
                st.write(f"- {x}")
        else:
            st.caption("ê¸°ì¤€ Top3ê°€ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
    with c2:
        st.write("**ë¶ˆí™•ì‹¤/ë¦¬ìŠ¤í¬ ì‹ í˜¸**")
        if uncertainties:
            for x in uncertainties[:4]:
                st.write(f"- {x}")
        else:
            st.caption("ë¶ˆí™•ì‹¤ ì‹ í˜¸ê°€ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
    with c3:
        st.write("**ê°ì • ì‹ í˜¸(ë¦¬í¬íŠ¸ ê¸°ë°˜)**")
        if emotions:
            for x in emotions[:4]:
                st.write(f"- {x}")
        else:
            st.caption("ê°ì • ì‹ í˜¸ê°€ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")

    st.write("**ê¸´ì¥ ì¶•(í…ìŠ¤íŠ¸ ë§¤ì¹­ ê¸°ë°˜)**")
    if found_axes:
        for a, b in found_axes:
            st.write(f"- {a} â†” {b}")
    else:
        st.caption("ìë™ìœ¼ë¡œ ì¡íŒ ê¸´ì¥ ì¶•ì´ ì—†ì–´ìš”(í‘œí˜„ì´ ë‹¬ëì„ ìˆ˜ ìˆì–´ìš”).")


def render_coaching_message(data: Dict[str, Any]) -> None:
    st.subheader("ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    msgs = data.get("coaching_message", []) or []
    for m in msgs:
        st.write(f"- {m}")


def render_next_question(data: Dict[str, Any]) -> None:
    st.subheader("ë‹¤ìŒì— ìŠ¤ìŠ¤ë¡œì—ê²Œ ë˜ì§ˆ ì§ˆë¬¸(1ê°œ)")
    st.write(f"**{data.get('next_self_question','')}**")


STOPWORDS = {
    "ê·¸ëƒ¥", "ë„ˆë¬´", "ì§„ì§œ", "ê·¼ë°", "ê·¸ë¦¬ê³ ", "ê·¸ë˜ì„œ", "í•˜ì§€ë§Œ",
    "ì œê°€", "ì €ëŠ”", "ë‚˜ëŠ”", "ë‚´ê°€", "ì´ê²Œ", "ê·¸ê²Œ", "ì €",
    "ê²ƒ", "ìˆ˜", "ì¢€", "ì•½ê°„", "ë•Œë¬¸", "ë•Œë¬¸ì—", "ê°™ì•„ìš”", "ê°™ì€",
    "í•˜ëŠ”", "í•´ì•¼", "í•˜ê³ ", "ìˆëŠ”", "ìˆë‹¤", "ì—†ë‹¤", "ì—†ì–´ìš”",
    "ëª¨ë¥´ê² ", "ëª¨ë¥´ê² ì–´ìš”",
}

EMOTION_WORDS = [
    "ë¶ˆì•ˆ", "ë‘ë ¤ì›€", "ê±±ì •", "ê¸´ì¥", "ë‹µë‹µ", "í›„íšŒ", "ì£„ì±…ê°", "ë¶€ë‹´",
    "ìŠ¤íŠ¸ë ˆìŠ¤", "ìš°ìš¸", "ì§œì¦", "í™”", "ë¶„ë…¸", "ì„¤ë ˜", "ê¸°ëŒ€", "ì•ˆë„",
    "í¸ì•ˆ", "í–‰ë³µ", "ì˜ìš•", "ì§€ì¹¨", "ë²ˆì•„ì›ƒ",
]


def analyze_mirroring_from_answers() -> Tuple[pd.DataFrame, pd.DataFrame]:
    text = " ".join([str(x.get("a", "")) for x in st.session_state.answers if x.get("a")])
    clean = re.sub(r"[^\wê°€-í£ ]", " ", text)
    clean = re.sub(r"\s+", " ", clean).strip().lower()
    toks = [t for t in clean.split(" ") if len(t) >= 2 and t not in STOPWORDS]
    freq: Dict[str, int] = {}
    for t in toks:
        freq[t] = freq.get(t, 0) + 1
    kw = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:10]
    kw_df = pd.DataFrame(kw, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„"])

    emo_freq: Dict[str, int] = {}
    for ew in EMOTION_WORDS:
        c = len(re.findall(re.escape(ew), text))
        if c > 0:
            emo_freq[ew] = c
    emo = sorted(emo_freq.items(), key=lambda x: x[1], reverse=True)[:10]
    emo_df = pd.DataFrame(emo, columns=["ê°ì •ì–´", "ë¹ˆë„"])
    return kw_df, emo_df


def render_mirroring_visual() -> None:
    st.subheader("ë‚´ë©´ì˜ ëª©ì†Œë¦¬(Mirroring) â€” ë‹µë³€ì—ì„œ ë§ì´ ë“±ì¥í•œ í‘œí˜„")
    kw_df, emo_df = analyze_mirroring_from_answers()
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ìì£¼ ë“±ì¥í•œ í‚¤ì›Œë“œ(Top 10)**")
        if len(kw_df) == 0:
            st.caption("í‚¤ì›Œë“œê°€ ì¶©ë¶„íˆ ì¡íˆì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(kw_df, use_container_width=True, hide_index=True)
            st.bar_chart(kw_df.set_index("í‚¤ì›Œë“œ")["ë¹ˆë„"])
    with c2:
        st.write("**ê°ì •ì–´(Top 10)**")
        if len(emo_df) == 0:
            st.caption("ê°ì •ì–´ê°€ ë§ì´ ë“±ì¥í•˜ì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(emo_df, use_container_width=True, hide_index=True)
            st.bar_chart(emo_df.set_index("ê°ì •ì–´")["ë¹ˆë„"])
    st.caption("ì´ ê²°ê³¼ëŠ” â€˜ì •ë‹µâ€™ì´ ì•„ë‹ˆë¼, ë‹µë³€ì— ë‚˜íƒ€ë‚œ ë°˜ë³µ í‘œí˜„ì„ ìš”ì•½í•œ ê±°ìš¸ì…ë‹ˆë‹¤.")


def build_decision_matrix(options: List[str], criteria_names: List[str]) -> pd.DataFrame:
    if not options:
        options = ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]
    if not criteria_names:
        criteria_names = ["ê¸°ì¤€ 1", "ê¸°ì¤€ 2", "ê¸°ì¤€ 3"]
    cols = ["ì˜µì…˜"] + criteria_names + ["ë©”ëª¨"]
    rows = []
    for opt in options:
        r = {"ì˜µì…˜": opt, "ë©”ëª¨": ""}
        for c in criteria_names:
            r[c] = 3
        rows.append(r)
    return pd.DataFrame(rows, columns=cols)


def render_decision_matrix(criteria_names: List[str], data: Dict[str, Any]) -> None:
    st.subheader("ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(ì§ì ‘ ì ìˆ˜ ë§¤ê¸°ê¸°)")
    st.caption("ê° ì˜µì…˜ì´ â€˜ë‚´ ê¸°ì¤€â€™ì—ì„œ ì–´ëŠ ì •ë„ì¸ì§€ 1~5ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”. ì ìˆ˜ëŠ” ê²°ë¡ ì´ ì•„ë‹ˆë¼ ìƒê°ì„ êº¼ë‚´ëŠ” ë„êµ¬ì˜ˆìš”.")

    user_opts = parse_options()
    report_opts = (data.get("summary", {}) or {}).get("options_mentioned", []) or []
    opts = user_opts or [str(x) for x in report_opts if str(x).strip()] or ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]

    if st.session_state.decision_matrix_df is None:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)

    df: pd.DataFrame = st.session_state.decision_matrix_df

    existing_opts = [str(x) for x in df["ì˜µì…˜"].tolist()] if "ì˜µì…˜" in df.columns else []
    if set(existing_opts) != set(opts):
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    desired_cols = ["ì˜µì…˜"] + (criteria_names or []) + ["ë©”ëª¨"]
    if list(df.columns) != desired_cols:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    col_cfg: Dict[str, Any] = {}
    for c in criteria_names:
        col_cfg[c] = st.column_config.NumberColumn(c, min_value=1, max_value=5, step=1, format="%d")

    edited = st.data_editor(
        df,
        use_container_width=True,
        hide_index=True,
        column_config=col_cfg,
        num_rows="fixed",
    )
    st.session_state.decision_matrix_df = edited

    if criteria_names:
        try:
            totals = edited[criteria_names].sum(axis=1)
            show = edited.copy()
            show["ì´ì (ì°¸ê³ )"] = totals
            st.write("**ì´ì (ì°¸ê³ ìš©)**")
            st.dataframe(show[["ì˜µì…˜", "ì´ì (ì°¸ê³ )"]], use_container_width=True, hide_index=True)
            st.caption("ì´ì ì€ ê²°ë¡ ì´ ì•„ë‹ˆë¼, ê¸°ì¤€ë³„ ê°•/ì•½ì ì„ ë‹¤ì‹œ ë³´ê²Œ í•˜ëŠ” ì°¸ê³ ì¹˜ì˜ˆìš”.")
        except Exception:
            pass


def render_copy_to_clipboard_button(text: str, button_label: str = "í´ë¦½ë³´ë“œì— ë³µì‚¬") -> None:
    safe = text.replace("\\", "\\\\").replace("`", "\\`").replace("${", "\\${")
    html = f"""
    <div style="display:flex; gap:8px; align-items:center;">
      <button
        onclick="navigator.clipboard.writeText(`{safe}`).then(()=>{{const el=document.getElementById('cpmsg'); el.innerText='ë³µì‚¬ë¨'; setTimeout(()=>el.innerText='',1200);}});"
        style="padding:8px 12px; border-radius:10px; border:1px solid #444; background:#111; color:#fff; cursor:pointer;">
        {button_label}
      </button>
      <span id="cpmsg" style="font-size:12px; opacity:0.8;"></span>
    </div>
    """
    st.components.v1.html(html, height=55)


def build_report_text_for_export(data: Dict[str, Any]) -> str:
    lines: List[str] = []
    lines.append("ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ â€” ìµœì¢… ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    lines.append(f"- ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("[ì„¸ì…˜ ì •ë³´]")
    lines.append(f"- ì¹´í…Œê³ ë¦¬: {st.session_state.category}")
    lines.append(f"- ê²°ì • ìœ í˜•: {st.session_state.decision_type}")
    lines.append(f"- ìƒí™© ì„¤ëª…: {st.session_state.situation}")
    lines.append(f"- ëª©í‘œ: {st.session_state.goal}")
    lines.append(f"- ì˜µì…˜: {st.session_state.options or '(ì—†ìŒ)'}")
    if st.session_state.emotion_pre is not None or st.session_state.emotion_post is not None:
        lines.append(f"- ê°ì • ê°•ë„(ì‹œì‘/ë): {st.session_state.emotion_pre} â†’ {st.session_state.emotion_post}")
    lines.append("")
    lines.append("[ë¦¬í¬íŠ¸ JSON]")
    lines.append(json.dumps(data, ensure_ascii=False, indent=2))
    lines.append("")
    lines.append("[Q/A]")
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        lines.append(f"{i}. ({tag}) Q: {qa['q']}")
        lines.append(f"   A: {qa['a']}")
        lines.append(f"   ts: {qa['ts']}")
        lines.append("")
    return "\n".join(lines).strip()


# =========================
# Back
# =========================
def handle_back() -> None:
    if not st.session_state.answers:
        st.session_state.q_index = max(0, int(st.session_state.q_index) - 1)
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        st.session_state.probe_mode = ""
        return

    last = st.session_state.answers.pop()

    if last.get("kind") == "probe":
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        st.session_state.probe_mode = ""
        st.session_state.q_index = int(last.get("main_index", st.session_state.q_index))
        return

    mi = int(last.get("main_index", 0))
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.probe_mode = ""
    st.session_state.q_index = max(0, mi)


# =========================
# Sidebar
# =========================
init_state()

with st.sidebar:
    st.header("ë³´ì¡° ë©”ë‰´")
    st.text_input("OpenAI API Key (Secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()
    st.subheader("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ")
    st.toggle("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ", key="privacy_mode")
    if st.session_state.privacy_mode:
        st.toggle("ë‹µë³€ ê¸°ë¡ ìˆ¨ê¸°ê¸°", key="hide_history")
        st.toggle("ë‚´ë³´ë‚´ê¸° ë§ˆìŠ¤í‚¹(ê¶Œì¥)", key="mask_export")
        st.caption("í‘œì‹œ/ê³µìœ  ìœ„í—˜ì„ ë‚®ì¶”ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤(ì™„ì „ ìµëª…í™”ëŠ” ì•„ë‹˜).")
    else:
        st.session_state.hide_history = False

    st.divider()
    st.subheader("ì„¸ì…˜ í…œí”Œë¦¿(í”„ë¦¬ì…‹)")
    with st.expander("í”„ë¦¬ì…‹ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°"):
        tpl_name = st.text_input("í”„ë¦¬ì…‹ ì´ë¦„", placeholder="ì˜ˆ: ì»¤ë¦¬ì–´ ê²°ì •(êµ¬ì¡° ì½”ì¹˜)")
        colx, coly = st.columns(2)
        with colx:
            if st.button("í˜„ì¬ ì„¤ì • ì €ì¥", use_container_width=True):
                if tpl_name.strip():
                    st.session_state.saved_templates.append(
                        {
                            "name": tpl_name.strip(),
                            "category": st.session_state.category,
                            "decision_type": st.session_state.decision_type,
                            "coach_id": st.session_state.coach_id,
                            "num_questions": int(st.session_state.num_questions),
                            "saved_at": datetime.now().isoformat(timespec="seconds"),
                        }
                    )
                    st.success("ì €ì¥í–ˆì–´ìš”.")
                else:
                    st.warning("í”„ë¦¬ì…‹ ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        with coly:
            st.download_button(
                "í”„ë¦¬ì…‹ JSON ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(st.session_state.saved_templates, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name="pebble_templates.json",
                mime="application/json",
                use_container_width=True,
            )

        if st.session_state.saved_templates:
            names = [t["name"] for t in st.session_state.saved_templates]
            picked = st.selectbox("ë¶ˆëŸ¬ì˜¬ í”„ë¦¬ì…‹", names, index=0)
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ë¶ˆëŸ¬ì˜¤ê¸°(í˜„ì¬ ì„¤ì •ì— ì ìš©)", use_container_width=True):
                    t = next((x for x in st.session_state.saved_templates if x["name"] == picked), None)
                    if t:
                        st.session_state.category = t["category"]
                        st.session_state.decision_type = t["decision_type"]
                        st.session_state.coach_id = t["coach_id"]
                        st.session_state.num_questions = int(t["num_questions"])
                        st.success("ì ìš©í–ˆì–´ìš”.")
            with col2:
                if st.button("ì‚­ì œ", use_container_width=True):
                    st.session_state.saved_templates = [x for x in st.session_state.saved_templates if x["name"] != picked]
                    st.success("ì‚­ì œí–ˆì–´ìš”.")
                    st.rerun()

            up = st.file_uploader("í”„ë¦¬ì…‹ JSON ë¶ˆëŸ¬ì˜¤ê¸°", type=["json"])
            if up is not None:
                try:
                    loaded = json.loads(up.read().decode("utf-8"))
                    if isinstance(loaded, list):
                        for item in loaded:
                            if isinstance(item, dict) and "name" in item:
                                st.session_state.saved_templates.append(item)
                        st.success("ë¶ˆëŸ¬ì™”ì–´ìš”.")
                        st.rerun()
                    else:
                        st.warning("í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤(ë¦¬ìŠ¤íŠ¸ JSONì´ì–´ì•¼ í•´ìš”).")
                except Exception:
                    st.warning("JSONì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”.")
        else:
            st.caption("ì €ì¥ëœ í”„ë¦¬ì…‹ì´ ì•„ì§ ì—†ì–´ìš”.")

    st.divider()
    st.subheader("ìš”ì•½ ë²„í¼(í† í° ë¹„ìš© ê´€ë¦¬)")
    st.caption("í”„ë¡¬í”„íŠ¸ì—ëŠ” â€˜ìš”ì•½ + ìµœê·¼ Q/Aâ€™ë§Œ í¬í•¨ë©ë‹ˆë‹¤.")
    st.write(f"- ìµœê·¼ Q/A í¬í•¨: {RECENT_QA_WINDOW}ê°œ")
    st.write(f"- ìš”ì•½ ì—…ë°ì´íŠ¸: ë©”ì¸ {SUMMARY_UPDATE_EVERY}ê°œë§ˆë‹¤")
    with st.expander("í˜„ì¬ ìš”ì•½ ë²„í¼ ë³´ê¸°"):
        st.code(st.session_state.summary_buffer or "(ë¹„ì–´ ìˆìŒ)", language="text")
    if st.button("ìš”ì•½ ë²„í¼ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.summary_buffer = ""
        st.session_state.summarized_main_count = 0
        st.success("ì´ˆê¸°í™”í–ˆì–´ìš”.")

    st.divider()
    if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸°", use_container_width=True):
        reset_flow("landing", keep_problem=False)
        st.rerun()

    if st.session_state.page in ("setup_details", "questions", "report"):
        if st.button("ê³ ë¯¼ë§Œ ìœ ì§€í•˜ê³  ë‹¤ì‹œ ì„¤ì •", use_container_width=True):
            reset_flow("landing", keep_problem=True)
            st.rerun()

    st.divider()
    with st.expander("ë””ë²„ê·¸ ë¡œê·¸"):
        st.write(st.session_state.debug_log)


# =========================
# Progress
# =========================
nq = int(st.session_state.num_questions)
labels = ["ê³ ë¯¼", "ì„¤ì •"] + [f"Q{i}" for i in range(1, nq + 1)] + ["ìš”ì•½"]

if st.session_state.page == "landing":
    idx = 0
elif st.session_state.page == "setup_details":
    idx = 1
elif st.session_state.page == "questions":
    idx = 2 + int(st.session_state.q_index)
else:
    idx = 2 + nq

render_pebble_bridge(idx, len(labels), labels)
progress = idx / max(1, (len(labels) - 1))
with st.columns([1, 2, 1])[1]:
    render_hero_pebble(progress, f"ì§„í–‰ë„: {int(progress * 100)}%")

st.divider()


# =========================
# Pages
# =========================
def render_landing() -> None:
    st.title("ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­")
    st.caption("ì •ë‹µì„ ì£¼ê¸°ë³´ë‹¤, ì§ˆë¬¸ìœ¼ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.")

    cols = st.columns([1, 3, 1])
    with cols[1]:
        st.subheader("1ë‹¨ê³„ Â· ê³ ë¯¼ ì‘ì„±")
        st.caption("ì§€ê¸ˆ ê³ ë¯¼ ì¤‘ì¸ ìƒí™©ì„ ììœ ë¡­ê²Œ ì ì–´ì£¼ì„¸ìš”.")

        with st.container(border=True):
            if st.session_state.privacy_mode:
                st.caption("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ: í™”ë©´ ê³µìœ  ì‹œ ë¯¼ê° í‘œì‹œë¥¼ ì¤„ì…ë‹ˆë‹¤.")
            st.text_area(
                "ê³ ë¯¼ ë‚´ìš©",
                key="user_problem",
                height=220,
                placeholder="ì˜ˆ: ì´ì§ ì œì•ˆì„ ë°›ì•˜ëŠ”ë° ì•ˆì •ì„±ê³¼ ì„±ì¥ ì‚¬ì´ì—ì„œ ê³ ë¯¼ë¼ìš”â€¦",
                label_visibility="collapsed",
            )

        c1, c2 = st.columns([2, 1])
        with c1:
            st.session_state.num_questions = st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions))
        with c2:
            if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ", type="primary", use_container_width=True):
                txt = (st.session_state.user_problem or "").strip()
                if not txt:
                    st.warning("ê³ ë¯¼ ë‚´ìš©ì„ ë¨¼ì € í•œ ì¤„ì´ë¼ë„ ì ì–´ì£¼ì„¸ìš”.")
                else:
                    if not (st.session_state.situation or "").strip():
                        st.session_state.situation = txt
                    st.session_state.page = "setup_details"
                    st.rerun()


def render_setup_details() -> None:
    st.title("2ë‹¨ê³„ Â· AI ë¶„ì„ ë° ì¶”ì²œ")
    st.caption("ì•„ë˜ ê°’ë“¤ì€ â€˜ì¶”ì²œ/ì´ˆì•ˆâ€™ì…ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ì§ì ‘ ë°”ê¿”ë„ ê´œì°®ì•„ìš”.")

    problem_text = (st.session_state.user_problem or "").strip()

    auto_generate = st.session_state.onboarding_reco is None and bool(problem_text)
    if auto_generate:
        with st.spinner("AIê°€ ê³ ë¯¼ì„ ì½ê³  ì¶”ì²œì„ ë§Œë“œëŠ” ì¤‘..."):
            reco, err, dbg, raw = generate_onboarding_recommendation(problem_text)
            st.session_state.debug_log = dbg
            st.session_state.onboarding_reco = reco
            st.session_state.onboarding_raw = raw
            if err:
                st.warning(err)

    top = st.columns([2, 1])
    with top[0]:
        st.subheader("ë‚´ê°€ ì ì€ ê³ ë¯¼")
    with top[1]:
        if st.button("ì¶”ì²œ ë‹¤ì‹œ ìƒì„±", use_container_width=True):
            with st.spinner("ì¶”ì²œì„ ë‹¤ì‹œ ìƒì„±í•˜ëŠ” ì¤‘..."):
                reco, err, dbg, raw = generate_onboarding_recommendation(problem_text)
                st.session_state.debug_log = dbg
                st.session_state.onboarding_reco = reco
                st.session_state.onboarding_raw = raw
                st.session_state.onboarding_applied = False
                if err:
                    st.warning(err)
            st.rerun()

    with st.container(border=True):
        if st.session_state.privacy_mode:
            st.write("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ: (í‘œì‹œ ìˆ¨ê¹€) â€” ì´ ì˜ì—­ì€ í™”ë©´ ê³µìœ  ì‹œ ë¯¼ê°í•  ìˆ˜ ìˆì–´ìš”.")
        else:
            st.write(problem_text)

    reco = st.session_state.onboarding_reco or {}
    if reco and not st.session_state.onboarding_applied:
        rec_cat = reco.get("recommended_category", "")
        if rec_cat in [c[0] for c in TOPIC_CATEGORIES]:
            st.session_state.category = rec_cat
        rec_dt = reco.get("recommended_decision_type", "")
        if rec_dt in DECISION_TYPES:
            st.session_state.decision_type = rec_dt
        rec_coach = reco.get("recommended_coach_id", "")
        if rec_coach in [c["id"] for c in COACHES]:
            st.session_state.coach_id = rec_coach
        goal_draft = str(reco.get("goal_draft", "") or "").strip()
        if goal_draft and not (st.session_state.goal or "").strip():
            st.session_state.goal = goal_draft
        if not (st.session_state.situation or "").strip():
            st.session_state.situation = problem_text
        st.session_state.onboarding_applied = True

    st.divider()
    st.subheader("ì¶”ì²œê°’ í™•ì¸/ìˆ˜ì •")

    c1, c2 = st.columns(2)
    with c1:
        st.selectbox("ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")
        st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type")
        st.text_input("ì›í•˜ëŠ” ëª©í‘œ(ì´ˆì•ˆ)", key="goal", placeholder="ì˜ˆ: ë‚´ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê¸°ì¤€ì„ ì„ ëª…í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ë‹¤")
        st.text_input("ì˜µì…˜(ì‰¼í‘œë¡œ êµ¬ë¶„, ì„ íƒ)", key="options", placeholder="ì˜ˆ: A, B, C")
        st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions), key="num_questions")
    with c2:
        coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
        cur = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
        picked = st.radio("ì½”ì¹˜ ì„ íƒ", coach_labels, index=cur)
        st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]
        coach = coach_by_id(st.session_state.coach_id)

        reason = str(reco.get("coach_reason", "") or "").strip()
        if reason:
            st.info(f"**AIê°€ ì´ ì½”ì¹˜ë¥¼ ì¶”ì²œí•œ ì´ìœ (ì°¸ê³ ):** {reason}")

        with st.expander("ì½”ì¹˜ ì§„í–‰ ë°©ì‹"):
            st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
            for m in coach["method"]:
                st.write(f"- {m}")
            st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.subheader("ìƒí™© ì„¤ëª…(í¸ì§‘ ê°€ëŠ¥)")
    st.text_area("ìƒí™© ì„¤ëª…", key="situation", height=180)

    with st.expander("ê²°ì • ìœ í˜• ê°€ì´ë“œ(í…œí”Œë¦¿)"):
        st.caption("í•„ìš”í•˜ë©´ ì•„ë˜ ê°€ì´ë“œë¥¼ ìƒí™© ì„¤ëª…ì— ì‚½ì…í•  ìˆ˜ ìˆì–´ìš”.")
        tmpl = DECISION_TEMPLATES.get(st.session_state.decision_type, "")
        if tmpl:
            st.code(tmpl, language="text")
            if st.button("ê°€ì´ë“œ ì‚½ì…(ìƒí™© ì„¤ëª…ì— ì¶”ê°€)", use_container_width=True):
                cur_txt = (st.session_state.situation or "").strip()
                st.session_state.situation = (cur_txt + "\n\n" + tmpl).strip() if cur_txt else tmpl
                st.rerun()

    st.divider()
    b1, b2, b3 = st.columns([1, 1, 1])
    with b1:
        if st.button("â¬…ï¸ ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.page = "landing"
            st.rerun()
    with b2:
        if st.button("ì¶”ì²œ ì›ë¬¸(JSON) ë³´ê¸°", use_container_width=True):
            if st.session_state.onboarding_raw:
                st.code(st.session_state.onboarding_raw, language="json")
            else:
                st.caption("ì¶”ì²œ ì›ë¬¸ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
    with b3:
        if st.button("ì½”ì¹­ ì‹œì‘í•˜ê¸°(ì‹¤í–‰í•˜ê¸°)", type="primary", use_container_width=True):
            st.session_state.q_index = 0
            st.session_state.questions = []
            st.session_state.answers = []
            st.session_state.probe_active = False
            st.session_state.probe_question = ""
            st.session_state.probe_for_index = None
            st.session_state.probe_mode = ""
            st.session_state.crosscheck_used_for = []
            st.session_state.final_report_json = None
            st.session_state.final_report_raw = None
            st.session_state.decision_matrix_df = None
            st.session_state.page = "questions"
            # âœ… ìš”ì•½ ë²„í¼ ì´ˆê¸°í™”
            st.session_state.summary_buffer = ""
            st.session_state.summarized_main_count = 0
            st.rerun()


def render_questions() -> None:
    st.title("ì§ˆë¬¸")
    st.caption("í”„ë¡¬í”„íŠ¸ ë¹„ìš© ê´€ë¦¬ë¥¼ ìœ„í•´: â€˜ìš”ì•½ ë²„í¼ + ìµœê·¼ Q/Aâ€™ë§Œ ëª¨ë¸ì— ë³´ëƒ…ë‹ˆë‹¤.")

    nq = int(st.session_state.num_questions)
    q_idx = int(st.session_state.q_index)
    q_idx = max(0, min(q_idx, nq - 1))

    # ê°ì • íŠ¸ë˜í‚¹: ì‹œì‘ ì „ 1íšŒ
    if q_idx == 0 and st.session_state.emotion_pre is None:
        st.subheader("ì‹œì‘ ì „ ì…€í”„ ì²´í¬(1ì´ˆ)")
        st.caption("ì§€ê¸ˆ ë§ˆìŒì˜ ë¬´ê²Œ/ê¸´ì¥ ì •ë„ë¥¼ 1~5ë¡œ ì°ì–´ì£¼ì„¸ìš”.")
        st.session_state.emotion_pre = st.slider("í˜„ì¬ ê°ì • ê°•ë„", 1, 5, 3, key="emotion_pre_slider")
        st.divider()

    ensure_question(q_idx, nq)
    main_q = st.session_state.questions[q_idx]

    if st.session_state.probe_active and st.session_state.probe_for_index == q_idx:
        show_q = st.session_state.probe_question
        kind = "probe"
        badge = "ë„ì›€ ì§ˆë¬¸(ì¬í”„ë ˆì´ë°)" if st.session_state.probe_mode == "reframe" else "ì¶”ê°€ ì§ˆë¬¸(êµ¬ì²´í™”)"
    else:
        show_q = main_q
        kind = "main"
        badge = "ë©”ì¸ ì§ˆë¬¸"

    top_c1, top_c2, top_c3 = st.columns([1, 2, 1])
    with top_c1:
        if st.button("â¬…ï¸ ì´ì „ìœ¼ë¡œ", use_container_width=True, disabled=(q_idx == 0 and not st.session_state.answers)):
            handle_back()
            st.rerun()
    with top_c3:
        st.caption(f"ë©”ì¸ ë‹µë³€: {main_answer_count()} / {nq}")

    st.subheader(f"Q{q_idx + 1} / {nq}  Â·  {badge}")
    with st.container(border=True):
        st.markdown(f"**{show_q}**")

    with st.form(f"answer_form_{q_idx}_{kind}", clear_on_submit=True):
        ans = st.text_area("ë‹µë³€", placeholder="ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", height=150)
        submitted = st.form_submit_button("ë‹µë³€ ì €ì¥", use_container_width=True)

    if submitted:
        a = (ans or "").strip()
        if not a:
            st.warning("ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í•œ ì¤„ë§Œ ì…ë ¥í•´ë„ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            if kind == "probe":
                add_answer(show_q, a, kind="probe", main_index=q_idx, subkind=st.session_state.probe_mode or "")
                st.session_state.probe_active = False
                st.session_state.probe_question = ""
                st.session_state.probe_for_index = None
                st.session_state.probe_mode = ""
                st.session_state.q_index = min(q_idx + 1, nq - 1)
                st.rerun()

            # main answer ì €ì¥
            add_answer(show_q, a, kind="main", main_index=q_idx, subkind="")

            # âœ… ë©”ì¸ ë‹µë³€ ì¶”ê°€ í›„ ìš”ì•½ ë²„í¼ ì—…ë°ì´íŠ¸(í•„ìš” ì‹œ)
            update_summary_buffer_if_needed()

            # ë‚œê° â†’ ì¬í”„ë ˆì´ë°
            if is_confused_answer(a):
                rq, err, dbg = generate_reframe_question(show_q, a)
                st.session_state.debug_log = dbg
                st.session_state.probe_active = True
                st.session_state.probe_question = rq
                st.session_state.probe_for_index = q_idx
                st.session_state.probe_mode = "reframe"
                st.rerun()

            # ì§§ìŒ â†’ probing
            if is_too_short_answer(a):
                pq, err, dbg = generate_probe_question(show_q, a)
                st.session_state.debug_log = dbg
                st.session_state.probe_active = True
                st.session_state.probe_question = pq
                st.session_state.probe_for_index = q_idx
                st.session_state.probe_mode = "short"
                st.rerun()

            if main_answer_count() >= nq:
                st.session_state.page = "report"
                st.session_state.report_just_entered = True
                st.session_state.q_index = nq - 1
            else:
                st.session_state.q_index = min(q_idx + 1, nq - 1)
            st.rerun()

    if not (st.session_state.privacy_mode and st.session_state.hide_history):
        with st.expander("ë‹µë³€ ê¸°ë¡"):
            grouped: Dict[int, List[Dict[str, Any]]] = {}
            for qa in st.session_state.answers:
                grouped.setdefault(int(qa.get("main_index", 0)), []).append(qa)
            for mi in sorted(grouped.keys()):
                st.markdown(f"### Q{mi + 1}")
                for qa in grouped[mi]:
                    tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
                    sub = qa.get("subkind", "")
                    tag2 = f"{tag}:{sub}" if sub else tag
                    st.markdown(f"**({tag2}) {qa['q']}**")
                    st.write(qa["a"])
                    st.caption(qa["ts"])
                    st.divider()
    else:
        st.caption("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ: ë‹µë³€ ê¸°ë¡ì´ ìˆ¨ê¹€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")


def render_emotion_delta_block() -> None:
    st.subheader("ê°ì • ë³€í™”(ì…€í”„ ì²´í¬)")
    pre = st.session_state.emotion_pre
    post = st.session_state.emotion_post
    if pre is None:
        st.caption("ì‹œì‘ ì „ ê°ì • ê°•ë„ê°€ ê¸°ë¡ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        return
    if post is None:
        st.caption("ëë‚œ ë’¤ ê°ì • ê°•ë„ê°€ ì•„ì§ ê¸°ë¡ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        return
    delta = int(post) - int(pre)
    c1, c2, c3 = st.columns(3)
    c1.metric("ì‹œì‘", str(pre))
    c2.metric("ë", str(post))
    c3.metric("ë³€í™”(ë-ì‹œì‘)", f"{delta:+d}")
    st.caption("ì¢‹ê³  ë‚˜ì¨ì´ ì•„ë‹ˆë¼, ì •ë¦¬ ì „/í›„ ì²´ê° ë³€í™”ë¥¼ ê´€ì°°í•˜ê¸° ìœ„í•œ ê¸°ë¡ì´ì—ìš”.")


def render_report() -> None:
    coach = coach_by_id(st.session_state.coach_id)
    nq = int(st.session_state.num_questions)

    st.title("ìµœì¢… ì •ë¦¬")
    st.caption("ì¶”ì²œ/ì •ë‹µ ì—†ì´, ê³ ë¯¼ì˜ í•µì‹¬ê³¼ ê¸°ì¤€ì„ â€˜ê±°ìš¸ ë¹„ì¶”ê¸°â€™ ë°©ì‹ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.")

    if st.session_state.report_just_entered:
        st.balloons()
        st.session_state.report_just_entered = False

    st.subheader("ëë‚œ ë’¤ ì…€í”„ ì²´í¬(1ì´ˆ)")
    st.caption("ì •ë¦¬ë¥¼ ë§ˆì¹œ ì§€ê¸ˆì˜ ê°ì • ê°•ë„ë¥¼ 1~5ë¡œ ì°ì–´ì£¼ì„¸ìš”.")
    st.session_state.emotion_post = st.slider("í˜„ì¬ ê°ì • ê°•ë„", 1, 5, 3, key="emotion_post_slider")
    st.divider()

    if main_answer_count() < nq:
        st.warning("ì•„ì§ ëª¨ë“  ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ ì´ë™", type="primary"):
            st.session_state.page = "questions"
            st.rerun()
        st.stop()

    colA, colB = st.columns([1, 1])
    with colA:
        gen = st.button("ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨", type="primary", use_container_width=True)
    with colB:
        if st.button("ìƒˆ ì„¸ì…˜ ì‹œì‘", use_container_width=True):
            reset_flow("landing", keep_problem=False)
            st.rerun()

    if gen or (st.session_state.final_report_json is None and st.session_state.final_report_raw is None):
        with st.spinner("ìµœì¢… ì •ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            data, err, dbg, raw = generate_final_report_json()
            st.session_state.debug_log = dbg
            if data is not None:
                st.session_state.final_report_json = data
                st.session_state.final_report_raw = raw
            else:
                st.session_state.final_report_json = None
                st.session_state.final_report_raw = raw
                st.error(err or "ì •ë¦¬ ìƒì„± ì‹¤íŒ¨")

    data = st.session_state.final_report_json
    if data:
        st.success("ìµœì¢… ì •ë¦¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        render_emotion_delta_block()
        render_summary_block(data)
        criteria_names = render_criteria(data)
        render_decision_matrix(criteria_names, data)

        if coach["id"] == "action":
            render_action_visualization(data)
        elif coach["id"] == "logic":
            render_key_points_logic(data)
        else:
            render_emotions_values(data)

        render_tension_map(data)
        render_info_check_questions(data)
        render_mirroring_visual()
        render_coaching_message(data)
        render_next_question(data)

        st.subheader("ë‹¤ìŒ ì„¸ì…˜ìœ¼ë¡œ ì—°ê²°í•˜ê¸°")
        st.caption("ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•œ ë‚´ìš©ì„ â€˜ë‹¤ìŒ ì„¸ì…˜ì˜ ì‹œì‘ ê³ ë¯¼â€™ìœ¼ë¡œ ì‚¼ì„ ìˆ˜ ìˆì–´ìš”.")
        nsq = str(data.get("next_self_question", "") or "").strip()
        if nsq:
            st.write(f"**ì§ˆë¬¸:** {nsq}")
        next_seed = st.text_area("ë‚´ ë‹µë³€(ë‹¤ìŒ ì„¸ì…˜ ì‹œì‘ìš©)", height=120, placeholder="ì˜ˆ: ë‚´ê°€ ë†“ì¹˜ê¸° ì‹«ì€ ê¸°ì¤€ì€ â€¦")
        colx, coly = st.columns([1, 1])
        with colx:
            if st.button("ì´ ë‹µë³€ìœ¼ë¡œ ìƒˆ ì„¸ì…˜ ì‹œì‘", use_container_width=True):
                if next_seed.strip():
                    st.session_state.user_problem = next_seed.strip()
                    reset_flow("setup_details", keep_problem=True)
                    st.session_state.page = "setup_details"
                    st.rerun()
                else:
                    st.warning("ë‹µë³€ì„ í•œ ì¤„ì´ë¼ë„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        with coly:
            if st.button("ê·¸ëƒ¥ ëœë”©ìœ¼ë¡œ", use_container_width=True):
                reset_flow("landing", keep_problem=False)
                st.rerun()

        st.subheader("ê³µìœ /ì €ì¥")
        export_text = build_report_text_for_export(data)
        if st.session_state.privacy_mode and st.session_state.mask_export:
            export_text = mask_text_for_privacy(export_text)

        render_copy_to_clipboard_button(export_text, "ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ ë³µì‚¬")
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.download_button(
            "ë¦¬í¬íŠ¸ .txt ë‹¤ìš´ë¡œë“œ",
            data=export_text.encode("utf-8"),
            file_name=f"pebble_decision_report_{ts}.txt",
            mime="text/plain",
            use_container_width=True,
        )

        st.subheader("ê³µìœ ìš©(JSON)")
        json_text = json.dumps(data, ensure_ascii=False, indent=2)
        if st.session_state.privacy_mode and st.session_state.mask_export:
            json_text = mask_text_for_privacy(json_text)
        st.code(json_text, language="json")

        valid_until = (datetime.now().date() + timedelta(days=7)).strftime("%Y-%m-%d")
        st.divider()
        st.caption(f"ì´ ì •ë¦¬ëŠ” **{valid_until}**ê¹Œì§€ ìœ íš¨í•©ë‹ˆë‹¤.")
    elif st.session_state.final_report_raw:
        st.warning("JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë¬¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.code(st.session_state.final_report_raw, language="text")


# =========================
# Router
# =========================
if st.session_state.page == "landing":
    render_landing()
elif st.session_state.page == "setup_details":
    render_setup_details()
elif st.session_state.page == "questions":
    render_questions()
else:
    render_report()

st.divider()
with st.expander("ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Streamlit Cloud)"):
    st.markdown(
        """
- Secrets ì„¤ì •: Settings â†’ Secretsì— `OPENAI_API_KEY = "sk-..."` ì¶”ê°€
- requirements.txt:
  - streamlit
  - openai
  - pandas
"""
    )

