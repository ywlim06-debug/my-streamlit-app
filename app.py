# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ (Pebble Decision Coach)
#
# PRD/ê³„íšì„œ ì¤€ìˆ˜:
# - ì •ë‹µ/ê²°ë¡ /ì¶”ì²œ ì œê³µ ê¸ˆì§€ (ê°•ì œ)
# - í•œ í™”ë©´ì— í•œ ì§ˆë¬¸ì”©
# - ì´ì „ ë‹µë³€ ë°˜ì˜ ë™ì  ì§ˆë¬¸ ìƒì„±
# - ë§ˆì§€ë§‰: ê³ ë¯¼ì˜ í•µì‹¬ / ì„ íƒ ê¸°ì¤€ / ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°, ì¶”ì²œ ê¸ˆì§€)
#
# ë°˜ì˜ëœ ê°œì„ ì‚¬í•­:
# 1) êµ¬ì¡° ì½”ì¹˜: "ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ/ë°˜ëŒ€ ê°€ì •)" ê³ ì • ì§ˆë¬¸ í¬í•¨
# 2) ê°€ì¹˜ ì½”ì¹˜: "ê°ì • vs ê°€ì¹˜ ë¶„ë¦¬" ê³ ì • ì§ˆë¬¸ í¬í•¨
# 3) ì‹¤í–‰ ì½”ì¹˜: ë§ˆì§€ë§‰ì— "ì˜¤ëŠ˜ 5ë¶„ Quick Win" ê³ ì • ì§ˆë¬¸ í¬í•¨
# 4) Dynamic Depth: ë‹µë³€ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ Probe ì§ˆë¬¸ 1íšŒ ì¶”ê°€(ë‹¤ìŒ ë‹¨ê³„ë¡œ ì•ˆ ë„˜ì–´ê°)
# 5) ë¦¬í¬íŠ¸: ì¶”ì²œ/ì§€ì‹œ í‘œí˜„ ë°©ì§€ ê°•í™” + ìœ„ë°˜ ì‹œ ìë™ ì¬ìƒì„± 1íšŒ
#
# UI:
# - ëŒë‹¤ë¦¬ ì§„í–‰ UI + ì‚¬ëŒ(ğŸš¶) ì•„ì´ì½˜ í¬ê²Œ(40px) + ë°©í–¥ ë°˜ëŒ€
# - PIL ë¯¸ì‚¬ìš© (SVG base64 HTML ë Œë”)
#
# í•„ìš”:
#   pip install streamlit openai
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import random
import re
import textwrap
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ AI ê²°ì • ì½”ì¹­", page_icon="ğŸª¨", layout="wide")

MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” êµ¬ì¡° ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê³ , ê°€ì •ì„ í”ë“œëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì •ë¦¬ë¥¼ ë•ìŠµë‹ˆë‹¤",
        "style": "MECE/ê¸°ì¤€/ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ)",
        "method": [
            "ìƒí™©Â·ì œì•½Â·ì˜µì…˜ì„ ë¶„ë¦¬í•´ì„œ ì ê²Œ í•˜ê¸°",
            "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ì•„ ìš°ì„ ìˆœìœ„ë¥¼ í™•ì¸í•˜ê¸°",
            "â€˜ë‚´ê°€ ë‹¹ì—°í•˜ë‹¤ê³  ë¯¿ëŠ” ê°€ì •â€™ì„ ë°˜ëŒ€ë¡œ ë’¤ì§‘ì–´ ë³´ê¸°",
        ],
        "prompt_hint": "MECE, ê¸°ì¤€ ëª©ë¡, ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°)",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜ ì½”ì¹˜",
        "tagline": "ê°ì •ê³¼ ê°€ì¹˜ë¥¼ ë¶„ë¦¬í•´, í›„íšŒê°€ ì ì€ ê¸°ì¤€ì„ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤",
        "style": "ê°ì • ë¼ë²¨ë§/ê°€ì¹˜ ë¶„ë¦¬/í›„íšŒ ìµœì†Œí™”",
        "method": [
            "ê°ì • ë¼ë²¨ë§(ì§€ê¸ˆ ëŠë¼ëŠ” ê²ƒ) â†’ ì´ìœ ",
            "ê·¸ ê°ì •ì´ â€˜ì¼ì‹œì  í¸ì•ˆí•¨â€™ì¸ì§€ â€˜ì¥ê¸° ê°€ì¹˜â€™ì¸ì§€ ë¶„ë¦¬",
            "ê°€ì¹˜ Top3 ë„ì¶œ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸",
        ],
        "prompt_hint": "ê°ì •-ê°€ì¹˜ ë¶„ë¦¬, ê°€ì¹˜ Top3, ë¯¸ë˜ì˜ ë‚˜ ì§ˆë¬¸",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê³„íšì„ â€˜ì •ë¦¬â€™í•˜ê³ , ì˜¤ëŠ˜ 5ë¶„ Quick Winê¹Œì§€ ìŠ¤ìŠ¤ë¡œ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤(ì¶”ì²œ ê¸ˆì§€)",
        "style": "ìš°ì„ ìˆœìœ„/ë…„â†’ë‹¬â†’ì£¼/ì¥ì• ë¬¼/Quick Win",
        "method": [
            "ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°: íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ Top1~3 ì •ë¦¬",
            "ëª©í‘œë¥¼ ë…„â†’ë‹¬â†’ì£¼ë¡œ ìª¼ê°œ â€˜ì‚¬ìš©ìê°€ ë§í•œ ê³„íšâ€™ì„ êµ¬ì¡°í™”",
            "ë§ˆì§€ë§‰ì— â€˜ì˜¤ëŠ˜ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ ë„ì¶œ",
        ],
        "prompt_hint": "ìš°ì„ ìˆœìœ„, ë¡œë“œë§µ(ë…„â†’ë‹¬â†’ì£¼), If-Then, Quick Win",
    },
]

# ë‹µë³€ì´ ì§§ë‹¤ê³  íŒë‹¨í•˜ëŠ” ê¸°ì¤€
MIN_ANSWER_CHARS = 18
SHORT_ANSWER_PATTERNS = [
    r"^ëª¨ë¥´ê² ",
    r"^ì˜\s*ëª¨ë¥´",
    r"^ê·¸ëƒ¥",
    r"^ì—†ì–´",
    r"^ëª¨ë¦„$",
    r"^ã„´ã„´$",
    r"^ëª°ë¼$",
]


# =========================
# Pebble SVG (no PIL)
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    return f"""
<svg width="160" height="120" viewBox="0 0 160 120" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="pebble">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="80%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M28 80
           C14 60, 20 30, 50 20
           C66 14, 96 12, 114 24
           C142 44, 150 68, 130 88
           C112 108, 54 110, 28 80 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M54 30 C68 22, 82 22, 94 30"
        fill="none" stroke="{shine}" stroke-width="7" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_svg_b64(progress_0_to_1: float, inactive: bool = False) -> str:
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    if inactive:
        fill, shine = "#2f3136", "#6b6f7a"
    else:
        fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
        shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"
    svg = _pebble_svg(fill=fill, shine=shine)
    return base64.b64encode(svg.encode("utf-8")).decode("ascii")


def render_pebble_bridge(current_idx: int, total: int, labels: List[str]) -> None:
    total = max(2, int(total))
    current_idx = max(0, min(int(current_idx), total - 1))

    left_pct = ((current_idx + 0.5) / total) * 100.0

    pebble_imgs = []
    for i in range(total):
        active = i <= current_idx
        p = (i + 1) / total
        b64 = pebble_svg_b64(p, inactive=not active)
        pebble_imgs.append(b64)

    html = """
<style>
.pebble-bridge-wrap{
  position: relative;
  width: 100%;
  margin: 6px 0 2px 0;
  padding: 16px 4px 0 4px;
}
.pebble-row{
  display: flex;
  gap: 10px;
  align-items: flex-end;
  justify-content: space-between;
}
.pebble-cell{
  flex: 1;
  min-width: 0;
  text-align: center;
}
.pebble-img{
  width: 100%;
  max-width: 120px;
  height: auto;
  display: inline-block;
}
.pebble-label{
  font-size: 12px;
  margin-top: 4px;
  opacity: 0.85;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

/* ì‚¬ëŒ(ğŸš¶) í¬ê²Œ + ë°©í–¥ ë°˜ëŒ€ë¡œ */
.walker{
  position: absolute;
  top: -10px;
  left: VAR_LEFT%;
  transform: translateX(-50%) scaleX(-1);
  font-size: 40px;
  line-height: 1;
  transition: left 520ms cubic-bezier(.2,.9,.2,1);
  filter: drop-shadow(0px 2px 2px rgba(0,0,0,0.25));
  animation: bob 800ms ease-in-out infinite;
  user-select: none;
}
@keyframes bob{
  0%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
  50%{ transform: translateX(-50%) translateY(-3px) scaleX(-1); }
  100%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
}
</style>
<div class="pebble-bridge-wrap">
  <div class="walker">ğŸš¶</div>
  <div class="pebble-row">
    VAR_PEBBLES
  </div>
</div>
""".strip()

    pebble_cells = []
    for i in range(total):
        opacity = "1.0" if i <= current_idx else "0.55"
        cell = f"""
<div class="pebble-cell" style="opacity:{opacity}">
  <img class="pebble-img" src="data:image/svg+xml;base64,{pebble_imgs[i]}" />
  <div class="pebble-label">{labels[i] if i < len(labels) else ""}</div>
</div>
""".strip()
        pebble_cells.append(cell)

    html = html.replace("VAR_LEFT", f"{left_pct:.3f}")
    html = html.replace("VAR_PEBBLES", "\n".join(pebble_cells))
    st.markdown(html, unsafe_allow_html=True)


def render_hero_pebble(progress: float, label: str) -> None:
    b64 = pebble_svg_b64(progress, inactive=False)
    st.markdown(
        f"""
<div style="text-align:center;">
  <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:240px;"/>
  <div style="margin-top:6px; font-size:14px;">{label}</div>
</div>
""",
        unsafe_allow_html=True,
    )


# =========================
# OpenAI
# =========================
def get_api_key() -> str:
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install openai`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.6) -> Tuple[Optional[str], Optional[str], List[str]]:
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. Secretsì— OPENAI_API_KEYë¥¼ ë„£ê±°ë‚˜ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.", debug


# =========================
# State + routing
# =========================
def init_state() -> None:
    if "page" not in st.session_state:
        st.session_state.page = "setup"  # setup | questions | report

    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]
    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]
    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]

    if "situation" not in st.session_state:
        st.session_state.situation = ""
    if "goal" not in st.session_state:
        st.session_state.goal = ""
    if "options" not in st.session_state:
        st.session_state.options = ""

    if "num_questions" not in st.session_state:
        st.session_state.num_questions = 5

    # main question index (0..n-1)
    if "q_index" not in st.session_state:
        st.session_state.q_index = 0

    # ì§ˆë¬¸ ëª©ë¡ì€ "main ì§ˆë¬¸"ë§Œ ì €ì¥
    if "questions" not in st.session_state:
        st.session_state.questions = []

    # answers: {"q":..., "a":..., "ts":..., "kind":"main"|"probe", "main_index":int}
    if "answers" not in st.session_state:
        st.session_state.answers = []

    # probe ëª¨ë“œ
    if "probe_active" not in st.session_state:
        st.session_state.probe_active = False
    if "probe_question" not in st.session_state:
        st.session_state.probe_question = ""
    if "probe_for_index" not in st.session_state:
        st.session_state.probe_for_index = None  # type: ignore

    if "final_report_json" not in st.session_state:
        st.session_state.final_report_json = None
    if "final_report_raw" not in st.session_state:
        st.session_state.final_report_raw = None

    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []
    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""


def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def reset_flow(to_page: str = "setup") -> None:
    st.session_state.page = to_page
    st.session_state.q_index = 0
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.final_report_json = None
    st.session_state.final_report_raw = None
    st.session_state.debug_log = []


def add_answer(q: str, a: str, kind: str, main_index: int) -> None:
    st.session_state.answers.append(
        {"q": q, "a": a, "ts": datetime.now().isoformat(timespec="seconds"), "kind": kind, "main_index": main_index}
    )


def main_answer_count() -> int:
    return sum(1 for x in st.session_state.answers if x.get("kind") == "main")


# =========================
# Helpers
# =========================
def normalize(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


def token_overlap(a: str, b: str) -> float:
    def toks(s: str) -> set:
        s = re.sub(r"[^\wê°€-í£ ]", " ", s)
        s = re.sub(r"\s+", " ", s).strip().lower()
        return set([t for t in s.split(" ") if len(t) >= 2])

    ta, tb = toks(a), toks(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    denom = max(1, min(len(ta), len(tb)))
    return inter / denom


def is_similar(a: str, b: str) -> bool:
    a0, b0 = normalize(a), normalize(b)
    if not a0 or not b0:
        return False
    if a0 == b0:
        return True
    if a0 in b0 or b0 in a0:
        return True
    return token_overlap(a0, b0) >= 0.75


def is_too_short_answer(ans: str) -> bool:
    a = (ans or "").strip()
    if len(a) < MIN_ANSWER_CHARS:
        return True
    for pat in SHORT_ANSWER_PATTERNS:
        if re.search(pat, a):
            return True
    return False


# =========================
# Question generation
# =========================
def system_prompt_for_questions(coach: Dict[str, Any]) -> str:
    base = (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì •ë‹µ/í•´ê²°ì±…/ì¶”ì²œì„ ì£¼ì§€ ë§ê³ , ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ì§ˆë¬¸ë§Œ ë˜ì§€ì„¸ìš”.\n"
        "ê¸ˆì§€: ê²°ë¡ , ì¶”ì²œ, ì„ íƒ ê°•ìš”, íŒë‹¨ë¬¸(ì˜ˆ: Aê°€ ë‚«ë‹¤), ì§€ì‹œë¬¸(í•´ì•¼ í•œë‹¤/í•˜ì).\n"
        "ì¶œë ¥: ì§ˆë¬¸ 1ê°œë§Œ. (ì„¤ëª…/ë²ˆí˜¸/ë¨¸ë¦¬ë§ ê¸ˆì§€)\n"
    )
    if coach["id"] == "logic":
        return base + "ìŠ¤íƒ€ì¼: êµ¬ì¡°í™”/ê¸°ì¤€/ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°) ì§ˆë¬¸.\n"
    if coach["id"] == "value":
        return base + "ìŠ¤íƒ€ì¼: ê°ì • ë¼ë²¨ë§ + ê°ì •/ê°€ì¹˜ ë¶„ë¦¬ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸.\n"
    return base + "ìŠ¤íƒ€ì¼: ìš°ì„ ìˆœìœ„/ê³„íš(ë…„â†’ë‹¬â†’ì£¼)/ì¥ì• ë¬¼/Quick Winì„ ëª¨ë‘ ì§ˆë¬¸ìœ¼ë¡œë§Œ ìœ ë„.\n"


def build_context_block() -> str:
    # ìµœê·¼ main/probe í¬í•¨ ìµœëŒ€ 6ê°œ
    hist = ""
    tail = st.session_state.answers[-6:]
    for i, qa in enumerate(tail, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        hist += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"

    opts = [o.strip() for o in (st.session_state.options or "").split(",") if o.strip()]
    opts_txt = "\n".join([f"- {o}" for o in opts]) if opts else "(ë¯¸ì…ë ¥)"

    return textwrap.dedent(f"""
    [ì„¸ì…˜ ì‹œì‘ ì •ë³´]
    - ì¹´í…Œê³ ë¦¬: {st.session_state.category}
    - ê²°ì • ìœ í˜•: {st.session_state.decision_type}
    - ìƒí™© ì„¤ëª…: {st.session_state.situation or "(ë¯¸ì…ë ¥)"}
    - ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal or "(ë¯¸ì…ë ¥)"}
    - ê³ ë ¤ ì˜µì…˜(ìˆë‹¤ë©´): {opts_txt}

    [ìµœê·¼ Q/A]
    {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
    """).strip()


def probing_instruction(last_q: str, last_a: str) -> str:
    # ì§§ì€ ë‹µë³€ì„ êµ¬ì²´í™”í•˜ëŠ” â€œì‹¬ì¸µ ì§ˆë¬¸â€ ëª©ì 
    return textwrap.dedent(f"""
    ì‚¬ìš©ìì˜ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª¨í˜¸í•©ë‹ˆë‹¤.
    ì•„ë˜ì˜ ì§ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ êµ¬ì²´í™”í•  ìˆ˜ ìˆë„ë¡ ë”± 1ê°œì˜ ì¶”ê°€ ì§ˆë¬¸(Probe)ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

    - ì§ì „ ì§ˆë¬¸: {last_q}
    - ì§ì „ ë‹µë³€: {last_a}

    ìš”êµ¬ì‚¬í•­:
    - 'êµ¬ì²´í™”'ë¥¼ ë•ëŠ” ì§ˆë¬¸(ì˜ˆ: ì˜ˆì‹œ/ìƒí™©/ê¸°ì¤€/ì´ìœ /ë²”ìœ„/ê¸°ê°„/ìš°ì„ ìˆœìœ„ ì¤‘ í•˜ë‚˜ë¥¼ ë” ë¬»ê¸°)
    - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ ê¸ˆì§€
    - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
    """).strip()


def instruction_for_question(i: int, n: int, coach_id: str) -> str:
    """
    (ê°œì„  ë°˜ì˜)
    - logic: ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ) ì§ˆë¬¸ì„ íŠ¹ì • ë‹¨ê³„ì— ê³ ì •
    - value: ê°ì • í›„ 'ê°ì • vs ê°€ì¹˜ ë¶„ë¦¬' ê³ ì •
    - action: ë§ˆì§€ë§‰ì— 5ë¶„ Quick Win ê³ ì •
    """
    # ê³µí†µ ì´ˆë°˜
    if i == 0:
        return "ìƒí™©ì˜ í•µì‹¬ì„ ë” êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
    if i == 1:
        return "ì›í•˜ëŠ” ëª©í‘œë¥¼ ì¸¡ì • ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    # ì‹¤í–‰ ì½”ì¹˜
    if coach_id == "action":
        # ë§ˆì§€ë§‰ì€ Quick Win ê³ ì •
        if i == n - 1:
            return (
                "â€˜ì´ë²ˆ ì£¼ ê³„íšì„ ìœ„í•´, ì§€ê¸ˆ ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ "
                "ì„ ìŠ¤ìŠ¤ë¡œ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ(Quick Win)"
            )
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ í¼ì¹˜ê³  Top1~3 ìš°ì„ ìˆœìœ„ë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸(íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ì„ ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œ)"
        if i == 3 and n >= 5:
            return "Top1ì„ â€˜1ë…„â†’ì´ë²ˆ ë‹¬â†’ì´ë²ˆ ì£¼â€™ë¡œ ìª¼ê°œ ì‚¬ìš©ìê°€ ê³„íšì„ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 2:
            return "ì´ë²ˆ ì£¼ ê³„íšì„ ë°©í•´í•  ì¥ì• ë¬¼ê³¼ If-Then ëŒ€ì‘ì„ ìŠ¤ìŠ¤ë¡œ ì“°ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        return "ì´ë²ˆ ì£¼ ê³„íšì„ ë” êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–¸ì œ)í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    # êµ¬ì¡° ì½”ì¹˜
    if coach_id == "logic":
        # ê°€ì • ê¹¨ê¸° ì§ˆë¬¸ì„ ê°€ëŠ¥í•œ ì¤‘í›„ë°˜ì— ê³ ì •
        if n >= 5 and i == n - 2:
            return (
                "ì—­ë°œìƒ/ë°˜ëŒ€ ìƒí™© ê°€ì • ì§ˆë¬¸ 1ê°œ. "
                "ì˜ˆ: â€˜ë§Œì•½ ë‹¹ì‹ ì´ ì„¸ìš´ ê¸°ì¤€ì´ ì™„ì „íˆ í‹€ë ¸ë‹¤ë©´ ì–´ë–¤ ìƒí™©ì´ ë²Œì–´ì§ˆê¹Œìš”?â€™ "
                "ë˜ëŠ” â€˜ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë‚®ë‹¤ê³  ìƒê°í•˜ëŠ” ì˜µì…˜ì´ ì •ë‹µì´ ë  ìˆ˜ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ëŠ”?â€™"
            )
        if i == 2:
            return "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        if i == n - 2 and n < 5:
            return "ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì¶”ê°€ë¡œ í™•ì¸í•  ì •ë³´ 1~2ê°œë¥¼ ë“œëŸ¬ë‚´ëŠ” ì§ˆë¬¸ 1ê°œ"
        return "ì˜µì…˜/ì •ë³´/ì œì•½ì„ ë” ë¶„ë¦¬í•´ ëª…ë£Œí™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    # ê°€ì¹˜ ì½”ì¹˜
    if coach_id == "value":
        if i == 2:
            return "ì§€ê¸ˆ ê°ì •(2~3ê°œ)ê³¼ ê·¸ ê°ì •ì˜ ì´ìœ ë¥¼ ë§í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        # ê°ì • í›„ì— 'ê°ì • vs ê°€ì¹˜ ë¶„ë¦¬' ê³ ì •
        if i == 3 and n >= 5:
            return (
                "ê°ì •ê³¼ ê°€ì¹˜ì˜ ë¶„ë¦¬ ì§ˆë¬¸ 1ê°œ. "
                "ì˜ˆ: â€˜ì§€ê¸ˆì˜ ë¶ˆì•ˆì´ í•µì‹¬ ê°€ì¹˜ë¥¼ ì¹¨í•´í•´ì„œ ìƒê¸´ ê±´ê°€ìš”, ì•„ë‹ˆë©´ ë‚¯ì„  ë³€í™”ì— ëŒ€í•œ ë³¸ëŠ¥ì  ê±°ë¶€ê°ì¸ê°€ìš”?â€™"
            )
        if i == n - 2:
            return "í›„íšŒ ìµœì†Œí™” ê´€ì (1ë…„/5ë…„ í›„)ì„ ì ê²€í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ â€˜ë‚´ ê¸°ì¤€â€™ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        return "ê°€ì¹˜ Top3(ë‚´ê²Œ ì¤‘ìš”í•œ ê²ƒ)ì™€ ë‚´ë ¤ë†“ì„ ê²ƒ 1ê°œë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"


def fallback_question(coach_id: str, i: int, n: int) -> str:
    if i == 0:
        return "ì§€ê¸ˆ ê³ ë¯¼ì—ì„œ â€˜ê°€ì¥ í•µì‹¬ì ì¸ ìŸì â€™ì€ ë¬´ì—‡ì¸ê°€ìš”? (í•œ ë¬¸ì¥)"
    if i == 1:
        return "ì´ë²ˆ ê²°ì •ìœ¼ë¡œ ì–»ê³  ì‹¶ì€ ëª©í‘œë¥¼ â€˜ì¸¡ì • ê°€ëŠ¥í•˜ê²Œâ€™ ë°”ê¾¸ë©´ ì–´ë–»ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‚˜ìš”? (ì–¸ì œê¹Œì§€/ì–´ëŠ ì •ë„)"

    if coach_id == "action":
        if i == n - 1:
            return "ì´ë²ˆ ì£¼ ê³„íšì„ ìœ„í•´, ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” â€˜ê°€ì¥ ì‘ì€ í–‰ë™â€™ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ ì ê³ , íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        if i == 3 and n >= 5:
            return "Top1ì„ ê¸°ì¤€ìœ¼ë¡œ â€˜1ë…„ ëª©í‘œ â†’ ì´ë²ˆ ë‹¬ ëª©í‘œ â†’ ì´ë²ˆ ì£¼ ê³„íš(3ê°œ)â€™ì„ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 2:
            return "ì´ë²ˆ ì£¼ ê³„íšì„ ë°©í•´í•  ì¥ì• ë¬¼ 3ê°€ì§€ë¥¼ ì ê³ , ê°ê° â€˜ë§Œì•½ ~ì´ë©´ â†’ ~í•œë‹¤â€™ë¡œ ëŒ€ì‘ì„ ì¨ë³¼ê¹Œìš”?"
        return "ì´ë²ˆ ì£¼ ê³„íšì„ ë” êµ¬ì²´í™”í•˜ë©´(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–¸ì œ) ì–´ë–»ê²Œ ì ì„ ìˆ˜ ìˆë‚˜ìš”?"

    if coach_id == "logic":
        if n >= 5 and i == n - 2:
            return "ë§Œì•½ ë‹¹ì‹ ì´ ì„¸ìš´ ê¸°ì¤€ì´ ì™„ì „íˆ í‹€ë ¸ë‹¤ë©´ ì–´ë–¤ ìƒí™©ì´ ë²Œì–´ì§ˆê¹Œìš”?"
        if i == 2:
            return "ì´ ì„ íƒì„ í‰ê°€í•  ê¸°ì¤€ 3~5ê°œë¥¼ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 1:
            return "ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 2 and n < 5:
            return "ì§€ê¸ˆ ê²°ì •ì„ ì–´ë µê²Œ ë§Œë“œëŠ” â€˜ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì •ë³´â€™ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        return "ì˜µì…˜/ì œì•½/ì •ë³´ë¥¼ ë¶„ë¦¬í•´ì„œ ì§€ê¸ˆ ë¶€ì¡±í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ì§€ ì ì–´ë³¼ê¹Œìš”?"

    # value
    if i == 2:
        return "ì§€ê¸ˆ ê°ì •ì„ 2~3ê°œ ë‹¨ì–´ë¡œ ì ê³ , ê° ê°ì •ì´ ìƒê¸´ ì´ìœ ë¥¼ í•œ ì¤„ì”© ì¨ë³¼ê¹Œìš”?"
    if i == 3 and n >= 5:
        return "ê·¸ ê°ì •ì€ â€˜ì§€ê¸ˆ ë‹¹ì¥ì˜ í¸ì•ˆí•¨â€™ ë•Œë¬¸ì¸ê°€ìš”, â€˜ë¯¸ë˜ì˜ ë‚˜ë¥¼ ìœ„í•œ ê°€ì¹˜â€™ ë•Œë¬¸ì¸ê°€ìš”?"
    if i == n - 2:
        return "1ë…„/5ë…„ ë’¤ì˜ ë‚´ê°€ ì§€ê¸ˆì˜ ë‚˜ì—ê²Œ ë­ë¼ê³  ë§í•´ì¤„ ê²ƒ ê°™ë‚˜ìš”?"
    return "ì´ ê³ ë¯¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°€ì¹˜ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"


def generate_question(i: int, n: int) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    prev_qs = st.session_state.questions[:]

    def prompt(nonce: int) -> str:
        prev_txt = "\n".join([f"- {q}" for q in prev_qs]) if prev_qs else "(ì—†ìŒ)"
        return textwrap.dedent(f"""
        [ì´ì „ ì§ˆë¬¸ ëª©ë¡]
        {prev_txt}

        {build_context_block()}

        [ì´ë²ˆ ì§ˆë¬¸ ëª©ì ]
        {instruction_for_question(i, n, coach["id"])}

        ê·œì¹™:
        - ê²°ë¡ /ì¶”ì²œ/ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
        - ì´ì „ ì§ˆë¬¸ê³¼ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ í”¼í•˜ê¸°

        (nonce={nonce})
        """).strip()

    q1, err, dbg = call_openai_text(system=system, user=prompt(random.randint(1000, 9999)), temperature=0.7)
    if not q1:
        return fallback_question(coach["id"], i, n), err, dbg

    q1 = normalize(q1)
    if not any(is_similar(q1, pq) for pq in prev_qs):
        return q1, None, dbg

    dbg.append("Similar question detected. Regenerating once.")
    q2, err2, dbg2 = call_openai_text(system=system, user=prompt(random.randint(10000, 99999)), temperature=0.85)
    dbg.extend(dbg2)
    if q2:
        q2 = normalize(q2)
        if not any(is_similar(q2, pq) for pq in prev_qs):
            return q2, None, dbg

    dbg.append("Still similar after retry. Using fallback.")
    return fallback_question(coach["id"], i, n), None, dbg


def ensure_question(index: int, total: int) -> None:
    while len(st.session_state.questions) <= index:
        i = len(st.session_state.questions)
        q, err, dbg = generate_question(i, total)
        st.session_state.debug_log = dbg
        st.session_state.questions.append(q)


def generate_probe_question(last_q: str, last_a: str) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    user = probing_instruction(last_q, last_a)
    q, err, dbg = call_openai_text(system=system, user=user, temperature=0.6)
    if not q:
        # fallback probe
        return "ë°©ê¸ˆ ë‹µë³€ì—ì„œ â€˜ì˜ˆì‹œ 1ê°œâ€™ë§Œ ë“¤ì–´ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì„¤ëª…í•´ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?", err, dbg
    return normalize(q), None, dbg


# =========================
# Final report (Mirroring only)
# =========================
FORBIDDEN_RECOMMEND_PATTERNS = [
    r"ì¶”ì²œ",
    r"~?í•˜ëŠ” ê²ƒì´ ì¢‹",
    r"í•´ì•¼ í•©ë‹ˆë‹¤",
    r"í•˜ì‹œê¸¸",
    r"í•˜ëŠ” ê²Œ ë‚«",
    r"Aë¥¼ ì„ íƒ",
    r"Bë¥¼ ì„ íƒ",
    r"ì •ë‹µ",
    r"ê²°ë¡ ",
]


def contains_forbidden_recommendation(text: str) -> bool:
    t = text or ""
    for pat in FORBIDDEN_RECOMMEND_PATTERNS:
        if re.search(pat, t):
            return True
    return False


def report_schema_hint(coach_id: str) -> str:
    base = """
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”(ì½”ë“œë¸”ë¡/ì„¤ëª… ê¸ˆì§€).
ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.
coaching_messageëŠ” ë°˜ë“œì‹œ "ê±°ìš¸ ë¹„ì¶”ê¸°(Mirroring)" í™”ë²•ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- ì˜ˆ: "ë‹¹ì‹ ì€ ___ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤"
- ì˜ˆ: "ë‹¹ì‹ ì˜ ë‹µë³€ì—ì„œ ___ì™€ ___ ì‚¬ì´ì˜ ê¸´ì¥ì´ ë“œëŸ¬ë‚©ë‹ˆë‹¤"
ê¸ˆì§€ í‘œí˜„: "ì¶”ì²œ", "ì¢‹ê² ìŠµë‹ˆë‹¤", "í•´ì•¼ í•©ë‹ˆë‹¤", "í•˜ì", "ì •ë‹µ", "ê²°ë¡ ", "Aë¥¼ ì„ íƒ".
"""
    if coach_id == "action":
        return textwrap.dedent(
            base
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue": "string",
    "goal": "string",
    "constraints": ["string"],
    "options_mentioned": ["string"]
  },
  "criteria": [
    {"name":"string","priority":1-5,"why":"string"}
  ],
  "plan_visualization": {
    "year": "string",
    "month": "string",
    "week": ["string","string","string"]
  },
  "weekly_table": {
    "Mon": ["string"], "Tue": ["string"], "Wed": ["string"], "Thu": ["string"],
    "Fri": ["string"], "Sat": ["string"], "Sun": ["string"]
  },
  "coaching_message": ["string","string"],
  "next_self_question": "string"
}
"""
        ).strip()

    if coach_id == "logic":
        return textwrap.dedent(
            base
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "key_points": {"uncertainties":["string"], "tradeoffs":["string"]},
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
        ).strip()

    return textwrap.dedent(
        base
        + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "emotions_values": {"emotions":["string","string"], "top_values":["string","string","string"]},
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
    ).strip()


def safe_json_parse(text: str) -> Optional[Dict[str, Any]]:
    if not text:
        return None
    t = text.strip()
    if not t.startswith("{"):
        m = re.search(r"\{.*\}", t, flags=re.S)
        if m:
            t = m.group(0).strip()
    try:
        return json.loads(t)
    except Exception:
        return None


def system_prompt_for_report() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ìµœì¢… ìš”ì•½ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì˜¤ì§ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬/ê¸°ì¤€/ê¸´ì¥/ë¶ˆí™•ì‹¤ì„±ì„ ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)í•˜ì„¸ìš”.\n"
        "coaching_messageëŠ” ë°˜ë“œì‹œ ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ(â€˜ë‹¹ì‹ ì€ ~ë¡œ ë³´ì…ë‹ˆë‹¤â€™).\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.\n"
    )


def build_qa_text_for_report() -> str:
    qa_text = ""
    # main/probe ëª¨ë‘ í¬í•¨í•˜ë˜ ìˆœì„œëŒ€ë¡œ
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        qa_text += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"
    return qa_text


def generate_final_report_json() -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_report()

    qa_text = build_qa_text_for_report()
    opts = [o.strip() for o in (st.session_state.options or "").split(",") if o.strip()]

    user = textwrap.dedent(f"""
{report_schema_hint(coach["id"])}

[ì„¸ì…˜ ì‹œì‘ ì •ë³´]
- ì¹´í…Œê³ ë¦¬: {st.session_state.category}
- ê²°ì • ìœ í˜•: {st.session_state.decision_type}
- ìƒí™© ì„¤ëª…: {st.session_state.situation}
- ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal}
- ì˜µì…˜(ìˆë‹¤ë©´): {opts if opts else "(ì—†ìŒ)"}

[Q/A]
{qa_text}

ì¤‘ìš”:
- ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
- coaching_messageëŠ” ê±°ìš¸ ë¹„ì¶”ê¸°ë§Œ
- ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ê³„íšì„ â€˜ì§€ì–´ë‚´ì§€â€™ ë§ˆì„¸ìš”
""").strip()

    text, err, dbg = call_openai_text(system=system, user=user, temperature=0.25)
    if not text:
        return None, err, dbg, None

    # 1ì°¨ íŒŒì‹±
    data = safe_json_parse(text)
    if data is None:
        return None, "ë¦¬í¬íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨(ëª¨ë¸ì´ JSONë§Œ ì¶œë ¥í•˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ)", dbg, text

    # ì¶”ì²œ/ì§€ì‹œ ë¬¸êµ¬ ë°©ì§€: coaching_message / ì „ì²´ ë¬¸ìì—´ ê²€ì‚¬
    combined = json.dumps(data, ensure_ascii=False)
    if contains_forbidden_recommendation(combined):
        dbg.append("Forbidden recommendation-like phrasing detected. Regenerating once with stricter warning.")
        stricter_user = user + "\n\n[ê²½ê³ ] ì´ì „ ì¶œë ¥ì— ì¶”ì²œ/ì§€ì‹œ í‘œí˜„ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ê³  ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
        text2, err2, dbg2 = call_openai_text(system=system, user=stricter_user, temperature=0.1)
        dbg.extend(dbg2)
        if text2:
            data2 = safe_json_parse(text2)
            if data2 is not None and not contains_forbidden_recommendation(json.dumps(data2, ensure_ascii=False)):
                return data2, None, dbg, text2
        # ì¬ìƒì„± ì‹¤íŒ¨ ì‹œì—ë„ ë°˜í™˜ì€ í•˜ë˜, ì‚¬ìš©ìì—ê²Œ ê²½ê³  í‘œì‹œ ê°€ëŠ¥
        dbg.append("Regeneration did not fully remove forbidden phrasing.")
        return data, None, dbg, text

    return data, None, dbg, text


# =========================
# Report rendering
# =========================
def render_summary_block(data: Dict[str, Any]) -> None:
    s = data.get("summary", {}) or {}
    st.subheader("ê³ ë¯¼ì˜ í•µì‹¬ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.write(f"**í•µì‹¬ ê³ ë¯¼:** {s.get('core_issue','')}")
        st.write(f"**ëª©í‘œ:** {s.get('goal','')}")
    with c2:
        cons = s.get("constraints", []) or []
        opts = s.get("options_mentioned", []) or []
        st.write("**ì œì•½/ì¡°ê±´:**")
        if cons:
            for x in cons:
                st.write(f"- {x}")
        else:
            st.caption("ì œì•½ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        st.write("**ì–¸ê¸‰ëœ ì˜µì…˜:**")
        if opts:
            for x in opts:
                st.write(f"- {x}")
        else:
            st.caption("ì˜µì…˜ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")


def render_criteria(data: Dict[str, Any]) -> None:
    st.subheader("ì„ íƒ ê¸°ì¤€ ì •ë¦¬(ìš°ì„ ìˆœìœ„ í¬í•¨)")
    crit = data.get("criteria", []) or []
    if not crit:
        st.caption("ì„ íƒ ê¸°ì¤€ì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
        return
    rows = []
    for c in crit:
        rows.append({"ê¸°ì¤€": c.get("name", ""), "ìš°ì„ ìˆœìœ„(1~5)": c.get("priority", ""), "ì™œ ì¤‘ìš”í•œê°€": c.get("why", "")})
    st.dataframe(rows, use_container_width=True, hide_index=True)


def render_action_visualization(data: Dict[str, Any]) -> None:
    st.subheader("ê³„íš ì •ë¦¬(ë…„ â†’ ë‹¬ â†’ ì£¼) â€” ì‚¬ìš©ì ë‹µë³€ ê¸°ë°˜")
    pv = data.get("plan_visualization", {}) or {}
    c1, c2, c3 = st.columns(3)
    c1.metric("ë…„", pv.get("year", "") or "-")
    c2.metric("ë‹¬", pv.get("month", "") or "-")
    c3.metric("ì£¼(í•µì‹¬ 3ê°œ)", " ")

    week = pv.get("week", []) or []
    if week:
        for x in week:
            st.write(f"- {x}")
    else:
        st.caption("ì‚¬ìš©ì ë‹µë³€ì—ì„œ ì£¼ ë‹¨ìœ„ ê³„íšì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")

    st.subheader("ì£¼ê°„ í…Œì´ë¸”(ì •ë¦¬ìš©)")
    cal = data.get("weekly_table", {}) or {}
    days = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
    table = [{"Day": d, "Tasks": "\n".join(cal.get(d, []) or [])} for d in days]
    st.dataframe(table, use_container_width=True, hide_index=True)


def render_key_points_logic(data: Dict[str, Any]) -> None:
    kp = data.get("key_points", {}) or {}
    st.subheader("ì •ë¦¬ í¬ì¸íŠ¸")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„(ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ê²ƒ)**")
        for x in kp.get("uncertainties", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**íŠ¸ë ˆì´ë“œì˜¤í”„(ì–»ëŠ” ê²ƒ vs ìƒëŠ” ê²ƒ)**")
        for x in kp.get("tradeoffs", []) or []:
            st.write(f"- {x}")


def render_emotions_values(data: Dict[str, Any]) -> None:
    ev = data.get("emotions_values", {}) or {}
    st.subheader("ê°ì •/ê°€ì¹˜ ì •ë¦¬")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ê°ì •**")
        for x in ev.get("emotions", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**ê°€ì¹˜ Top3**")
        for x in ev.get("top_values", []) or []:
            st.write(f"- {x}")


def render_coaching_message(data: Dict[str, Any]) -> None:
    st.subheader("ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    msgs = data.get("coaching_message", []) or []
    for m in msgs:
        st.write(f"- {m}")


def render_next_question(data: Dict[str, Any]) -> None:
    st.subheader("ë‹¤ìŒì— ìŠ¤ìŠ¤ë¡œì—ê²Œ ë˜ì§ˆ ì§ˆë¬¸(1ê°œ)")
    st.write(f"**{data.get('next_self_question','')}**")


# =========================
# App UI
# =========================
init_state()

with st.sidebar:
    st.header("ì„¤ì •")
    st.text_input("OpenAI API Key (Secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()
    st.subheader("ìƒí™© ì„¤ì •(ì„¸ì…˜ ì‹œì‘)")
    st.selectbox("ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")
    st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type")
    st.text_area("ìƒí™© ì„¤ëª…", key="situation", height=90, placeholder="ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆê³  ë¬´ì—‡ì„ ê²°ì •í•´ì•¼ í•˜ë‚˜ìš”?")
    st.text_input("ì›í•˜ëŠ” ëª©í‘œ", key="goal", placeholder="ì´ ê²°ì •ì—ì„œ ì–»ê³  ì‹¶ì€ ê²°ê³¼(ê°€ëŠ¥í•˜ë©´ ì¸¡ì • ê°€ëŠ¥í•˜ê²Œ)")
    st.text_input("ì˜µì…˜(ì‰¼í‘œë¡œ êµ¬ë¶„, ì„ íƒ)", key="options", placeholder="ì˜ˆ: A, B, C")

    st.divider()
    st.subheader("ì½”ì¹˜ ì„ íƒ")
    coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
    cur = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
    picked = st.radio("ì½”ì¹˜", coach_labels, index=cur)
    st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]
    coach = coach_by_id(st.session_state.coach_id)
    with st.expander("ì½”ì¹˜ ì§„í–‰ ë°©ì‹"):
        st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
        for m in coach["method"]:
            st.write(f"- {m}")
        st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.divider()
    st.subheader("ì§ˆë¬¸ ê°œìˆ˜")
    st.session_state.num_questions = st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions))

    st.divider()
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ì²˜ìŒë¶€í„°", use_container_width=True):
            reset_flow("setup")
            st.rerun()
    with c2:
        if st.session_state.page == "setup":
            if st.button("ì§ˆë¬¸ ì‹œì‘", type="primary", use_container_width=True):
                reset_flow("questions")
                st.rerun()
        elif st.session_state.page == "questions":
            done = main_answer_count() >= int(st.session_state.num_questions)
            if st.button("ìµœì¢… ê²°ê³¼ë¡œ", use_container_width=True, disabled=not done):
                st.session_state.page = "report"
                st.rerun()
        else:
            if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ", use_container_width=True):
                st.session_state.page = "questions"
                st.rerun()

# Progress (ëŒë‹¤ë¦¬ + ì‚¬ëŒ)
nq = int(st.session_state.num_questions)
labels = ["ì„¤ì •"] + [f"Q{i}" for i in range(1, nq + 1)] + ["ìš”ì•½"]

if st.session_state.page == "setup":
    idx = 0
elif st.session_state.page == "questions":
    # probe ì¤‘ì´ë©´ ê°™ì€ ëŒì— ë¨¸ë¬´ë¥´ëŠ” ëŠë‚Œ(í˜„ì¬ ì§ˆë¬¸ ì¸ë±ìŠ¤ ìœ ì§€)
    idx = 1 + int(st.session_state.q_index)
else:
    idx = 1 + nq

render_pebble_bridge(idx, len(labels), labels)

progress = idx / max(1, (len(labels) - 1))
with st.columns([1, 2, 1])[1]:
    render_hero_pebble(progress, f"ì§„í–‰ë„: {int(progress * 100)}%")

st.divider()

coach = coach_by_id(st.session_state.coach_id)

if st.session_state.page == "setup":
    st.title("ğŸª¨ AI ê²°ì • ì½”ì¹­")
    st.caption("ì •ë‹µì„ ì£¼ê¸°ë³´ë‹¤, ì§ˆë¬¸ìœ¼ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤. í•œ í™”ë©´ì— í•œ ì§ˆë¬¸ì”© ì§„í–‰ë©ë‹ˆë‹¤.")
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ìƒí™©ì„ ì…ë ¥í•˜ê³  â€˜ì§ˆë¬¸ ì‹œì‘â€™ì„ ëˆ„ë¥´ì„¸ìš”.")

    with st.container(border=True):
        st.subheader("í˜„ì¬ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°")
        st.write(f"- ì¹´í…Œê³ ë¦¬: {st.session_state.category}")
        st.write(f"- ê²°ì • ìœ í˜•: {st.session_state.decision_type}")
        st.write(f"- ì½”ì¹˜: {coach['name']}")
        st.write(f"- ì§ˆë¬¸ ê°œìˆ˜: {nq}")
        st.write(f"- ìƒí™© ì„¤ëª…: {st.session_state.situation or '(ë¯¸ì…ë ¥)'}")
        st.write(f"- ëª©í‘œ: {st.session_state.goal or '(ë¯¸ì…ë ¥)'}")
        st.write(f"- ì˜µì…˜: {st.session_state.options or '(ë¯¸ì…ë ¥)'}")

elif st.session_state.page == "questions":
    st.title("ì§ˆë¬¸")
    st.caption("í•œ í™”ë©´ì— í•œ ì§ˆë¬¸. ë‹µë³€ì„ ì €ì¥í•˜ë©´ ë‹¤ìŒìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. (ë‹µë³€ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ í•œ ë²ˆ ë” êµ¬ì²´í™” ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤)")

    q_idx = int(st.session_state.q_index)
    q_idx = max(0, min(q_idx, nq - 1))

    # ë©”ì¸ ì§ˆë¬¸ ì¤€ë¹„
    ensure_question(q_idx, nq)
    main_q = st.session_state.questions[q_idx]

    # í˜„ì¬ í‘œì‹œí•  ì§ˆë¬¸: probeê°€ í™œì„±í™”ë©´ probe, ì•„ë‹ˆë©´ main
    if st.session_state.probe_active and st.session_state.probe_for_index == q_idx:
        show_q = st.session_state.probe_question
        kind = "probe"
        badge = "ì¶”ê°€ ì§ˆë¬¸(êµ¬ì²´í™”)"
    else:
        show_q = main_q
        kind = "main"
        badge = "ë©”ì¸ ì§ˆë¬¸"

    st.subheader(f"Q{q_idx + 1} / {nq}  Â·  {badge}")
    with st.container(border=True):
        st.markdown(f"**{show_q}**")

    with st.form(f"answer_form_{q_idx}_{kind}", clear_on_submit=True):
        hint = ""
        if st.session_state.answers:
            last_a = st.session_state.answers[-1]["a"]
            hint = f"ì´ì „ ë‹µ ìš”ì•½: {last_a[:90]}{'â€¦' if len(last_a) > 90 else ''}"
        ans = st.text_area("ë‹µë³€", placeholder=hint or "ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", height=150)
        submitted = st.form_submit_button("ë‹µë³€ ì €ì¥", use_container_width=True)

    if submitted:
        a = (ans or "").strip()
        if not a:
            st.warning("ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í•œ ì¤„ë§Œ ì…ë ¥í•´ë„ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            # ì €ì¥
            add_answer(show_q, a, kind=kind, main_index=q_idx)

            if kind == "probe":
                # probeë¥¼ ëë‚´ê³  ë‹¤ìŒ main ì§ˆë¬¸ìœ¼ë¡œ ì§„í–‰
                st.session_state.probe_active = False
                st.session_state.probe_question = ""
                st.session_state.probe_for_index = None
                st.session_state.q_index = min(q_idx + 1, nq - 1)

            else:
                # main ë‹µë³€ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ probe ìƒì„±í•˜ê³  ê°™ì€ ë‹¨ê³„ ìœ ì§€
                if is_too_short_answer(a):
                    pq, err, dbg = generate_probe_question(show_q, a)
                    st.session_state.debug_log = dbg
                    st.session_state.probe_active = True
                    st.session_state.probe_question = pq
                    st.session_state.probe_for_index = q_idx
                    # q_indexëŠ” ê·¸ëŒ€ë¡œ

                else:
                    # ì •ìƒ ì§„í–‰
                    if main_answer_count() >= nq:
                        st.session_state.page = "report"
                        st.session_state.q_index = nq - 1
                    else:
                        st.session_state.q_index = min(q_idx + 1, nq - 1)

            st.rerun()

    with st.expander("ë‹µë³€ ê¸°ë¡"):
        # main/probe ë‹¤ ë³´ì—¬ì£¼ë˜, main_index ê¸°ì¤€ìœ¼ë¡œ ë¬¶ì–´ì„œ ë³´ê¸° ì¢‹ê²Œ
        grouped: Dict[int, List[Dict[str, Any]]] = {}
        for qa in st.session_state.answers:
            grouped.setdefault(int(qa.get("main_index", 0)), []).append(qa)

        for mi in sorted(grouped.keys()):
            st.markdown(f"### Q{mi + 1}")
            for qa in grouped[mi]:
                tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
                st.markdown(f"**({tag}) {qa['q']}**")
                st.write(qa["a"])
                st.caption(qa["ts"])
                st.divider()

    with st.expander("ë””ë²„ê·¸ ë¡œê·¸"):
        st.write(st.session_state.debug_log)

else:
    st.title("ìµœì¢… ì •ë¦¬")
    st.caption("ì¶”ì²œ/ì •ë‹µ ì—†ì´, ê³ ë¯¼ì˜ í•µì‹¬ê³¼ ê¸°ì¤€ì„ â€˜ê±°ìš¸ ë¹„ì¶”ê¸°â€™ ë°©ì‹ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.")

    if main_answer_count() < nq:
        st.warning("ì•„ì§ ëª¨ë“  ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì§ˆë¬¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ ë‹µë³€ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ ì´ë™", type="primary"):
            st.session_state.page = "questions"
            st.rerun()
        st.stop()

    colA, colB = st.columns([1, 1])
    with colA:
        gen = st.button("ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨", type="primary", use_container_width=True)
    with colB:
        if st.button("ìƒˆ ì„¸ì…˜ ì‹œì‘", use_container_width=True):
            reset_flow("setup")
            st.rerun()

    if gen or (st.session_state.final_report_json is None and st.session_state.final_report_raw is None):
        with st.spinner("ìµœì¢… ì •ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            data, err, dbg, raw = generate_final_report_json()
            st.session_state.debug_log = dbg
            if data is not None:
                st.session_state.final_report_json = data
                st.session_state.final_report_raw = raw
            else:
                st.session_state.final_report_json = None
                st.session_state.final_report_raw = raw
                st.error(err or "ì •ë¦¬ ìƒì„± ì‹¤íŒ¨")

    data = st.session_state.final_report_json
    if data:
        st.success("ìµœì¢… ì •ë¦¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

        render_summary_block(data)
        render_criteria(data)

        if coach["id"] == "action":
            render_action_visualization(data)
        elif coach["id"] == "logic":
            render_key_points_logic(data)
        else:
            render_emotions_values(data)

        render_coaching_message(data)
        render_next_question(data)

        st.subheader("ê³µìœ ìš©(JSON)")
        st.code(json.dumps(data, ensure_ascii=False, indent=2), language="json")

        # í˜¹ì‹œë¼ë„ ê¸ˆì§€ í‘œí˜„ì´ ë‚¨ì•„ìˆì„ ë•Œ ì‚¬ìš©ìì—ê²Œë§Œ ê²½ê³ (ë‚´ìš©ì€ ê·¸ëŒ€ë¡œ)
        if contains_forbidden_recommendation(json.dumps(data, ensure_ascii=False)):
            st.warning("ë¦¬í¬íŠ¸ì— ì¶”ì²œ/ì§€ì‹œì²˜ëŸ¼ ë³´ì´ëŠ” í‘œí˜„ì´ ì„ì˜€ì„ ìˆ˜ ìˆì–´ìš”. í•„ìš”í•˜ë©´ â€˜ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨â€™ì„ í•œ ë²ˆ ë” ëˆŒëŸ¬ ë³´ì„¸ìš”.")

    elif st.session_state.final_report_raw:
        st.warning("JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë¬¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.code(st.session_state.final_report_raw, language="text")

    with st.expander("Q/A ì „ì²´ ë³´ê¸°"):
        for i, qa in enumerate(st.session_state.answers, start=1):
            tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
            st.markdown(f"**{i}. ({tag}) {qa['q']}**")
            st.write(qa["a"])
            st.caption(qa["ts"])
            st.divider()

    with st.expander("ë””ë²„ê·¸ ë¡œê·¸"):
        st.write(st.session_state.debug_log)

st.divider()
with st.expander("ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Streamlit Cloud)"):
    st.markdown(
        """
- Secrets ì„¤ì •: Settings â†’ Secretsì— `OPENAI_API_KEY = "sk-..."` ì¶”ê°€
- requirements.txt:
  - streamlit
  - openai
"""
    )
