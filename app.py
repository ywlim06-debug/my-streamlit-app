# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëŒë©©ì´ ê²°ì • ì½”ì¹˜ (Pebble Decision Coach)
# - "ì§ˆë¬¸ì„ í†µí•´ ìƒê°ì„ ì •ë¦¬í•´ì£¼ëŠ”" ì»¨ì…‰
# - ì½”ì¹˜ë³„ ì»¨ì…‰ì„ ê°•í•˜ê²Œ êµ¬ë¶„ (ë…¼ë¦¬/ê°ì •ê°€ì¹˜/ì‹¤í–‰)
# - ì§ˆë¬¸ ë‹¨ê³„ë¶€í„° ëŒë©©ì´(í˜ë¸”) UI ì ê·¹ í™œìš© (ì§„í–‰ ë‹¨ê³„, ë°˜ì§/ê´‘íƒ)
# - ì´ì „ ë‹µë³€ì„ ê¸°ì–µí•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ì— ë°˜ì˜
# - Streamlit Cloud ë°°í¬ìš©: st.secrets["OPENAI_API_KEY"]
#
# í•„ìš” íŒ¨í‚¤ì§€:
#   pip install streamlit openai
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import textwrap
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Page Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ ê²°ì • ì½”ì¹˜", page_icon="ğŸª¨", layout="wide")


# =========================
# Constants
# =========================
MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” ë…¼ë¦¬ ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•´ì„œ ê²°ì •ì„ 'ëª…ë£Œ'í•˜ê²Œ ë§Œë“œëŠ” ì½”ì¹˜í•‘",
        "style": "ë…¼ë¦¬ì /ê°„ê²°/í”„ë ˆì„ì›Œí¬ ì¤‘ì‹¬",
        "method": [
            "í•µì‹¬ ìŸì Â·ì œì•½ì¡°ê±´ ì •ì˜",
            "ì˜µì…˜/ê¸°ì¤€/ê°€ì¤‘ì¹˜ ì •ë¦¬",
            "ì¥ë‹¨ì Â·ë¦¬ìŠ¤í¬Â·ëŒ€ì•ˆ ë¹„êµ",
            "ê²°ë¡  + ì„ íƒ ê·¼ê±°",
        ],
        "prompt_hint": "MECE, ì˜ì‚¬ê²°ì • ê¸°ì¤€í‘œ, ë¦¬ìŠ¤í¬/ê°€ì • ê²€ì¦ ì§ˆë¬¸ì„ ì˜ ì”€",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜/ê°ì • ì½”ì¹˜",
        "tagline": "ë‚´ê°€ 'ì™œ í”ë“¤ë¦¬ëŠ”ì§€'ë¥¼ ì°¾ì•„ ê¸°ì¤€ì„ ì„¸ì›Œì£¼ëŠ” ì½”ì¹˜í•‘",
        "style": "ê³µê°/ê°€ì¹˜ê´€/ê°ì • ëª…ë£Œí™”",
        "method": [
            "ê°ì •/ë‘ë ¤ì›€/ê¸°ëŒ€ ë¶„í•´",
            "ì§„ì§œ ì›í•˜ëŠ” ê²ƒ(ê°€ì¹˜) ë°œêµ´",
            "í›„íšŒ ìµœì†Œí™” ê´€ì (ë¯¸ë˜ì˜ ë‚˜) ì§ˆë¬¸",
            "ë‚˜ë‹µê²Œ ì„ íƒí•˜ëŠ” ë¬¸ì¥ ë§Œë“¤ê¸°",
        ],
        "prompt_hint": "ê°ì • ë¼ë²¨ë§, ê°€ì¹˜ ìš°ì„ ìˆœìœ„, í›„íšŒ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì„ ì˜ ì”€",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê²°ì •ì„ 'í–‰ë™'ìœ¼ë¡œ ë°”ê¾¸ëŠ” ì½”ì¹˜í•‘ (ì‹¤í—˜Â·ë‹¤ìŒ ìŠ¤í…)",
        "style": "êµ¬ì²´ì /ì‹¤í–‰/ì‘ì€ ì‹¤í—˜",
        "method": [
            "ì˜¤ëŠ˜~7ì¼ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ì‹¤í—˜ ì„¤ê³„",
            "ìµœì†Œ í–‰ë™(15ë¶„) + ì²´í¬ë¦¬ìŠ¤íŠ¸",
            "ì¥ì• ë¬¼/ëŒ€ì‘ê³„íš(If-Then)",
            "ì‹¤í–‰ í›„ ë¦¬ë·° ì§ˆë¬¸",
        ],
        "prompt_hint": "ì‘ì€ ì‹¤í—˜, ì¼ì •/ë£¨í‹´, ì¥ì• ë¬¼ ëŒ€ì‘ì„ ë§¤ìš° êµ¬ì²´í™”",
    },
]

STEPS = [
    "ì£¼ì œ ì„ íƒ",
    "ê³ ë¯¼ ì •ë¦¬(1)",
    "ê³ ë¯¼ ì •ë¦¬(2)",
    "ê¸°ì¤€Â·ì˜µì…˜",
    "ìµœì¢… ì •ë¦¬",
]


# =========================
# Pebble (Rock) UI Helpers
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    # ë‹¨ìˆœ ëŒë©©ì´ SVG (ì €ì‘ê¶Œ ì´ìŠˆ ì—†ëŠ” ì˜¤ë¦¬ì§€ë„ ë„í˜•)
    return f"""
<svg width="140" height="100" viewBox="0 0 140 100" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="75%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M24 68
           C12 52, 18 26, 44 18
           C58 12, 84 10, 100 20
           C124 36, 132 58, 116 74
           C102 90, 50 92, 24 68 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M46 28 C58 20, 70 20, 80 26"
        fill="none" stroke="{shine}" stroke-width="6" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_image_bytes(progress_0_to_1: float) -> bytes:
    # progressê°€ ë†’ì„ìˆ˜ë¡ ë°˜ì§(ê´‘íƒ) ê°•í•´ì§€ê²Œ
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    # ìƒ‰ìƒ: ì–´ë‘ìš´ íšŒìƒ‰ -> ë°ì€ ëŒìƒ‰
    fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
    shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"
    svg = _pebble_svg(fill=fill, shine=shine)
    return svg.encode("utf-8")


def step_pebbles_bar(step_idx: int, total: int) -> None:
    cols = st.columns(total)
    for i in range(total):
        p = (i + 1) / total
        active = i <= step_idx
        img = pebble_image_bytes(p if active else 0.08)
        cols[i].image(img, use_container_width=True)
        cols[i].caption(STEPS[i])


# =========================
# OpenAI Helpers (robust + debug)
# =========================
def get_api_key() -> str:
    # Streamlit Cloud: secrets ìš°ì„ 
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    # ë¡œì»¬: ì…ë ¥ê°’
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ìš”. `pip install openai` í•´ì£¼ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.7) -> Tuple[Optional[str], Optional[str], List[str]]:
    """
    Returns: (text_or_none, err_or_none, debug_log)
    - Responses API -> Chat Completions fallback
    - Model fallback (primary -> fallback)
    """
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•´ìš”. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•˜ê±°ë‚˜ secretsì— ë„£ì–´ì£¼ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    # 1) Responses API
    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                # robust extraction
                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    # 2) Chat Completions fallback
    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆì–´ìš”. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.", debug


# =========================
# State
# =========================
def init_state() -> None:
    if "step" not in st.session_state:
        st.session_state.step = 0

    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]

    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]

    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]

    if "answers" not in st.session_state:
        # Q/A íˆìŠ¤í† ë¦¬ (ì§ˆë¬¸ ê¸°ë°˜ ì‚¬ê³  ì •ë¦¬)
        st.session_state.answers = []  # list[dict]: {"q":..., "a":..., "ts":...}

    if "generated_questions" not in st.session_state:
        # ê° stepë§ˆë‹¤ ìƒì„±ëœ ì§ˆë¬¸ ìºì‹œ
        st.session_state.generated_questions = {}  # step -> question

    if "final_report" not in st.session_state:
        st.session_state.final_report = None

    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []

    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""


def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def add_answer(q: str, a: str) -> None:
    st.session_state.answers.append({"q": q, "a": a, "ts": datetime.now().isoformat(timespec="seconds")})


def reset_flow() -> None:
    st.session_state.step = 0
    st.session_state.answers = []
    st.session_state.generated_questions = {}
    st.session_state.final_report = None
    st.session_state.debug_log = []


# =========================
# Prompting (Coach differentiation)
# =========================
def system_prompt_for(coach: Dict[str, Any]) -> str:
    # ì½”ì¹˜ë³„ë¡œ "ì§ˆë¬¸ ìŠ¤íƒ€ì¼"ê³¼ "ìµœì¢… ë¦¬í¬íŠ¸ ìŠ¤íƒ€ì¼"ì„ í™•ì‹¤íˆ ë¶„ë¦¬
    if coach["id"] == "logic":
        return (
            "ë„ˆëŠ” 'ë…¼ë¦¬ ì½”ì¹˜'ì•¼. ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ ì˜ì‚¬ê²°ì • ë¬¸ì œë¡œ êµ¬ì¡°í™”í•˜ëŠ” ê²ƒ.\n"
            "- ë°˜ë“œì‹œ: ìŸì /ì˜µì…˜/ê¸°ì¤€/ì œì•½/ê°€ì •/ë¦¬ìŠ¤í¬ë¥¼ ë¶„ë¦¬í•´ì„œ ë‹¤ë£¨ê¸°\n"
            "- ì§ˆë¬¸ì€ ì§§ê³ , ë‹µë³€ì„ í‘œ/ëª©ë¡ìœ¼ë¡œ ë§Œë“¤ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë¬»ê¸°\n"
            "- ê°ì • ê³µê°ì€ ì§§ê²Œë§Œ í•˜ê³ , êµ¬ì¡°í™”ê°€ ìµœìš°ì„ \n"
            "- ë§íˆ¬ëŠ” ê¹”ë”í•˜ê³  ë‹¨í˜¸í•˜ì§€ë§Œ ê³µê²©ì ì´ì§€ ì•Šê²Œ\n"
        )
    if coach["id"] == "value":
        return (
            "ë„ˆëŠ” 'ê°€ì¹˜/ê°ì • ì½”ì¹˜'ì•¼. ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ê°ì •ê³¼ ê°€ì¹˜ê´€ì„ ëª…ë£Œí™”í•´ì„œ 'ë‚˜ë‹¤ìš´ ì„ íƒ'ì„ ë•ëŠ” ê²ƒ.\n"
            "- ë°˜ë“œì‹œ: ê°ì • ë¼ë²¨ë§(ì§€ê¸ˆ ëŠë¼ëŠ” ê°ì •) + ê·¸ ê°ì •ì˜ ê·¼ì›(ìš•êµ¬/ë‘ë ¤ì›€)ì„ íƒìƒ‰\n"
            "- ê°€ì¹˜(ì¤‘ìš”í•œ ê²ƒ)ë¥¼ 3ê°œë¡œ ì¢íˆê³ , í›„íšŒ ìµœì†Œí™” ê´€ì  ì§ˆë¬¸ í¬í•¨\n"
            "- ë§íˆ¬ëŠ” ë”°ëœ»í•˜ê³  ê³µê°ì . ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ë§ë¡œ ì •ë¦¬í•˜ê²Œ ìœ ë„\n"
        )
    # action
    return (
        "ë„ˆëŠ” 'ì‹¤í–‰ ì½”ì¹˜'ì•¼. ëª©í‘œëŠ” ê²°ì •ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‹¤í—˜ê³¼ ë‹¤ìŒ í–‰ë™ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê²ƒ.\n"
        "- ë°˜ë“œì‹œ: 7ì¼ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ì‘ì€ ì‹¤í—˜ 1~2ê°œë¡œ ì„¤ê³„\n"
        "- ì¥ì• ë¬¼(ì‹œê°„/ëˆ/ì‹¬ë¦¬)ê³¼ If-Then ëŒ€ì‘ì„ ë¬»ê¸°\n"
        "- ë§íˆ¬ëŠ” ì—ë„ˆì§€ ìˆê³  êµ¬ì²´ì . ì²´í¬ë¦¬ìŠ¤íŠ¸/ì¼ì • í‘œí˜„ì„ ì˜ ì“°ê¸°\n"
    )


def build_context_block() -> str:
    cat = st.session_state.category
    dtype = st.session_state.decision_type
    answers = st.session_state.answers

    hist = ""
    for i, qa in enumerate(answers[-6:], start=1):
        hist += f"{i}) Q: {qa['q']}\n   A: {qa['a']}\n"

    return textwrap.dedent(f"""
    [ê³ ë¯¼ ì¹´í…Œê³ ë¦¬]
    {cat}

    [ê²°ì • ìœ í˜•]
    {dtype}

    [ì§€ê¸ˆê¹Œì§€ì˜ Q/A (ìµœê·¼ 6ê°œ)]
    {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
    """).strip()


def question_instruction(step_idx: int, coach: Dict[str, Any]) -> str:
    # ë‹¨ê³„ë³„ ì§ˆë¬¸ ëª©ì ì„ ë‹¤ë¥´ê²Œ
    if step_idx == 1:
        return "ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ 'ìƒí™©' ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ê²Œ ë§Œë“œëŠ” 1ê°œì˜ ì§ˆë¬¸ì„ ë§Œë“¤ì–´."
    if step_idx == 2:
        return "ì‚¬ìš©ìì˜ 'ì§„ì§œ ì›í•˜ëŠ” ê²°ê³¼/ë‘ë ¤ìš´ ê²°ê³¼/ê°€ì¥ ì¤‘ìš”í•œ ì œì•½'ì„ ë“œëŸ¬ë‚´ëŠ” 1ê°œì˜ ì§ˆë¬¸ì„ ë§Œë“¤ì–´."
    if step_idx == 3:
        # ì½”ì¹˜ë³„ ì§ˆë¬¸ í˜•íƒœë¥¼ ê°•í•˜ê²Œ êµ¬ë¶„
        if coach["id"] == "logic":
            return "ì˜µì…˜ì„ 2~4ê°œë¡œ ë‚˜ëˆ„ê³ , í‰ê°€ ê¸°ì¤€ 3ê°œë¥¼ ë½‘ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´. ë‹µì€ í‘œë¡œ ë§Œë“¤ê¸° ì¢‹ê²Œ."
        if coach["id"] == "value":
            return "ê°€ì¹˜ ìš°ì„ ìˆœìœ„(ìƒìœ„ 3ê°œ)ì™€ í›„íšŒ í…ŒìŠ¤íŠ¸(1ë…„ ë’¤/5ë…„ ë’¤)ë¥¼ í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´."
        return "ì´ë²ˆ ì£¼ì— í•  ìˆ˜ ìˆëŠ” 'ì‘ì€ ì‹¤í—˜'ì„ ê³ ë¥´ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´. (ì˜ˆ: 15ë¶„ í–‰ë™/í•˜ë£¨ ì²´í¬)"
    # step 4: ìµœì¢… ì •ë¦¬ìš©
    if coach["id"] == "logic":
        return "ê²°ì •ì„ ë‚´ë¦¬ê¸° ì „ ë§ˆì§€ë§‰ í™•ì¸ ì§ˆë¬¸ 1ê°œ(ê°€ì • ê²€ì¦/ë¦¬ìŠ¤í¬ ëŒ€ë¹„)ë¥¼ ë§Œë“¤ì–´."
    if coach["id"] == "value":
        return "ê²°ì • ë¬¸ì¥ì„ í•œ ì¤„ë¡œ ë§Œë“¤ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(â€˜ë‚˜ëŠ” ___ë¥¼ ìœ„í•´ ___ì„ ì„ íƒí•œë‹¤â€™)ë¥¼ ë§Œë“¤ì–´."
    return "ì‹¤í–‰ ì•½ì†ì„ êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì–¸ì œ/ì–´ë””ì„œ/ë¬´ì—‡ì„/ë§‰íˆë©´ ì–´ë–»ê²Œ)ë¥¼ ë§Œë“¤ì–´."


def generate_next_question(step_idx: int) -> Tuple[Optional[str], Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for(coach)

    user = textwrap.dedent(f"""
    ë„ˆëŠ” ì‚¬ìš©ìì˜ ìƒê°ì„ ì •ë¦¬í•˜ê¸° ìœ„í•œ 'ë‹¨ í•˜ë‚˜ì˜ ì§ˆë¬¸'ì„ ë§Œë“ ë‹¤.

    ê·œì¹™:
    - ì§ˆë¬¸ì€ 1ê°œë§Œ ì¶œë ¥ (ì„¤ëª… ê¸ˆì§€)
    - ì§ˆë¬¸ì€ í•œêµ­ì–´
    - ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ì§€ ì•Šê²Œ, ì§€ê¸ˆ ë‹¨ê³„ì˜ ëª©ì ì— ë§ê²Œ êµ¬ì²´ì ìœ¼ë¡œ
    - ì‚¬ìš©ìê°€ ë‹µí•˜ê¸° ì‰½ê²Œ ì˜ˆì‹œ(ê´„í˜¸ 1ì¤„)ëŠ” í—ˆìš©

    {build_context_block()}

    [ì´ë²ˆ ë‹¨ê³„ ëª©ì ]
    {question_instruction(step_idx, coach)}

    ì´ì œ ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥í•´.
    """).strip()

    return call_openai_text(system=system, user=user, temperature=0.7)


def generate_final_report() -> Tuple[Optional[str], Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for(coach)

    # ìµœì¢… ì‚°ì¶œë¬¼ë„ ì½”ì¹˜ë³„ë¡œ 'í˜•ì‹'ì„ í™• ë‹¤ë¥´ê²Œ
    if coach["id"] == "logic":
        format_spec = """
        ì¶œë ¥ í˜•ì‹:
        ## í•œ ì¤„ ê²°ë¡ 
        - ê²°ë¡ : ...

        ## ì˜ì‚¬ê²°ì • êµ¬ì¡°
        - ìŸì :
        - ì˜µì…˜(2~4):
        - í‰ê°€ ê¸°ì¤€(3~5):
        - ì œì•½/ê°€ì •:
        - ë¦¬ìŠ¤í¬/ëŒ€ì‘:

        ## ì¶”ì²œì•ˆ (ê·¼ê±°)
        - ì¶”ì²œ: ...
        - ì´ìœ (3ì¤„):
        - ë³´ì™„ì±…(ë¦¬ìŠ¤í¬ ì¤„ì´ê¸°):

        ## ë‹¤ìŒ í–‰ë™(24ì‹œê°„ ë‚´)
        - ...
        """
    elif coach["id"] == "value":
        format_spec = """
        ì¶œë ¥ í˜•ì‹:
        ## ì§€ê¸ˆì˜ ë§ˆìŒ ìš”ì•½
        - ê°ì •(3ê°œ): ...
        - ì§„ì§œ ìš•êµ¬/ë‘ë ¤ì›€: ...

        ## ë‚˜ì˜ ê¸°ì¤€(ê°€ì¹˜)
        - ìƒìœ„ 3ê°€ì§€: ...
        - ë²„ë¦´ ìˆ˜ ìˆëŠ” ê²ƒ 1ê°€ì§€: ...

        ## ë‚˜ë‹¤ìš´ ì„ íƒ ë¬¸ì¥
        - â€œë‚˜ëŠ” ___ë¥¼ ìœ„í•´ ___ì„ ì„ íƒí•œë‹¤.â€

        ## í›„íšŒ ìµœì†Œí™” ì²´í¬
        - 1ë…„ ë’¤ì˜ ë‚˜: ...
        - 5ë…„ ë’¤ì˜ ë‚˜: ...

        ## ë‚´ì¼ì˜ ì‘ì€ ì•½ì†
        - ...
        """
    else:
        format_spec = """
        ì¶œë ¥ í˜•ì‹:
        ## ê²°ì •ì„ í–‰ë™ìœ¼ë¡œ ë°”ê¾¸ê¸°
        - ì´ë²ˆ ì£¼ í•µì‹¬ ëª©í‘œ(1ê°œ): ...

        ## 7ì¼ ì‹¤í—˜(1~2ê°œ)
        - ì‹¤í—˜1: (15ë¶„ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ)
        - ì‹¤í—˜2(ì„ íƒ): ...

        ## If-Then ëŒ€ì‘í‘œ
        - ë§Œì•½ ___ì´ë©´ â†’ ___í•œë‹¤ (3ê°œ)

        ## ì˜¤ëŠ˜(24ì‹œê°„ ë‚´) ì²´í¬ë¦¬ìŠ¤íŠ¸
        - [ ] ...
        - [ ] ...
        - [ ] ...

        ## ë¦¬ë·° ì§ˆë¬¸(ì‹¤í—˜ í›„)
        - ...
        """

    user = textwrap.dedent(f"""
    ì•„ë˜ Q/Aë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì½”ì¹˜ ì—­í• ì— ë§ëŠ” 'ìµœì¢… ì •ë¦¬ ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•´.

    ê·œì¹™:
    - í•œêµ­ì–´
    - ì‚¬ìš©ìì—ê²Œ ì„ íƒì„ ê°•ìš”í•˜ì§€ ë§ê³ , ê²°ì •ì˜ ê·¼ê±°ì™€ ë‹¤ìŒ ìŠ¤í…ì„ ëª…í™•íˆ
    - ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ 'ì¶”ê°€ í™•ì¸ ì§ˆë¬¸' 1ê°œë¥¼ ë§ˆì§€ë§‰ì— ì œì•ˆ
    - ê¸¸ì´ëŠ” 500~900ì ì •ë„

    {build_context_block()}

    {format_spec}

    ë§ˆì§€ë§‰ ì¤„ì—:
    - ì¶”ê°€ í™•ì¸ ì§ˆë¬¸: ...
    """).strip()

    return call_openai_text(system=system, user=user, temperature=0.65)


# =========================
# UI
# =========================
init_state()

# Sidebar
with st.sidebar:
    st.header("ğŸª¨ ëŒë©©ì´ ì„¤ì •")
    # secretsê°€ ì—†ì„ ë•Œë§Œ ì…ë ¥ì´ ì˜ë¯¸ìˆê²Œ
    st.text_input("OpenAI API Key (secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()
    st.subheader("ğŸ§­ ê³ ë¯¼ ë²”ìœ„ ì¢íˆê¸°")
    st.selectbox("ê³ ë¯¼ ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")
    st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type")

    st.divider()
    st.subheader("ğŸ§‘â€ğŸ« ê²°ì • ì½”ì¹˜ ì„ íƒ")
    coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
    coach_idx = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
    picked = st.radio("ì½”ì¹˜", coach_labels, index=coach_idx)
    st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]

    coach = coach_by_id(st.session_state.coach_id)
    with st.expander("ì½”ì¹˜ê°€ ì–´ë–»ê²Œ ë„ì™€ì£¼í•‘?"):
        st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
        st.markdown("**ì§„í–‰ ë°©ì‹**")
        for m in coach["method"]:
            st.write(f"- {m}")
        st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.divider()
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ”„ ìƒˆ ê³ ë¯¼ ì‹œì‘", use_container_width=True):
            reset_flow()
            st.rerun()
    with c2:
        if st.button("ğŸª¨ ë‹¤ìŒ ë‹¨ê³„ë¡œ", use_container_width=True, disabled=(st.session_state.step >= len(STEPS) - 1)):
            st.session_state.step += 1
            st.rerun()


# Main
st.title("ğŸª¨ ëŒë©©ì´ ê²°ì • ì½”ì¹˜")
st.caption("ì§ˆë¬¸ì„ ë”°ë¼ê°€ë‹¤ ë³´ë©´, ê³ ë¯¼ì´ ì •ë¦¬ë˜ê³  ê²°ë¡ ì´ ë˜ë ·í•´ì ¸ìš”. (ëŒë©©ì´ê°€ ë°˜ì§ì¼ìˆ˜ë¡ ì •ë¦¬ê°€ ì§„í–‰ ì¤‘!)")

# Pebble progress bar
step_pebbles_bar(st.session_state.step, len(STEPS))

# Hero pebble
progress = (st.session_state.step) / (len(STEPS) - 1)
hero_cols = st.columns([1, 2, 1])
with hero_cols[1]:
    st.image(pebble_image_bytes(progress), use_container_width=True)
    st.caption(f"í˜„ì¬ ë‹¨ê³„: **{STEPS[st.session_state.step]}**  Â·  ì •ë¦¬ ì§„í–‰ë„: **{int(progress*100)}%**")

st.divider()

# Step content
coach = coach_by_id(st.session_state.coach_id)

# Step 0: Topic selection summary
if st.session_state.step == 0:
    st.subheader("ğŸ§­ ë¨¼ì € ê³ ë¯¼ì„ 'ì‘ê²Œ' ë§Œë“¤ê¸°")
    cat_desc = next((d for n, d in TOPIC_CATEGORIES if n == st.session_state.category), "")
    st.info(f"**ì¹´í…Œê³ ë¦¬:** {st.session_state.category}\n\n{cat_desc}")

    st.success("ì¢‹ì•„ìš”! ì´ì œ ì§ˆë¬¸ì„ í†µí•´ ê³ ë¯¼ì„ í•œ ì¸µì”© ë‹¤ë“¬ì–´ë³¼ê²Œìš”. ì‚¬ì´ë“œë°”ì—ì„œ **â€˜ë‹¤ìŒ ë‹¨ê³„â€™**ë¥¼ ëˆŒëŸ¬ ì‹œì‘í•´ìš”.")

# Steps 1~4: Question & Answer flow
else:
    step_idx = st.session_state.step

    # Generate or reuse question
    if step_idx not in st.session_state.generated_questions:
        q, err, dbg = generate_next_question(step_idx)
        st.session_state.debug_log = dbg
        if q:
            st.session_state.generated_questions[step_idx] = q
        else:
            st.error(err or "ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
            with st.expander("ğŸ”§ ë””ë²„ê·¸ ë¡œê·¸"):
                st.write(dbg)
            st.stop()

    question = st.session_state.generated_questions[step_idx]

    # Question UI with pebble emphasis
    q_box = st.container(border=True)
    with q_box:
        st.markdown(f"### ğŸª¨ ì§ˆë¬¸ {step_idx} (ì½”ì¹˜: {coach['name']})")
        st.markdown(f"**Q. {question}**")
        st.caption("íŒ: ì§§ì•„ë„ ê´œì°®ì•„ìš”. í•µì‹¬ë§Œ ì ì–´ë„ â€˜ëŒë©©ì´â€™ê°€ ì¶©ë¶„íˆ ë‹¤ë“¬ì–´ì ¸ìš”.")

    # Answer input (clear-on-submit behavior)
    with st.form(f"answer_form_{step_idx}", clear_on_submit=True):
        default_hint = ""
        if st.session_state.answers:
            last_a = st.session_state.answers[-1]["a"]
            default_hint = f"ì´ì „ ë‹µ ì°¸ê³ : {last_a[:80]}{'â€¦' if len(last_a) > 80 else ''}"

        answer = st.text_area(
            "ğŸ“ ë‚´ ë‹µë³€(ì—¬ê¸°ì— ì ì–´ì¤˜ìš”)",
            placeholder=f"ì˜ˆ) {default_hint}" if default_hint else "ì˜ˆ) ìƒí™©/ì›í•˜ëŠ” ê²°ê³¼/ì œì•½ì„ ì ì–´ì¤˜ìš”",
            height=140,
        )
        submitted = st.form_submit_button("âœ… ë‹µë³€ ì €ì¥í•˜ê³  ë°˜ì§ì´ê¸°")

    if submitted:
        if not answer.strip():
            st.warning("ë‹µë³€ì´ ë¹„ì–´ìˆì–´ìš”. í•œ ì¤„ë§Œ ì ì–´ë„ ê´œì°®ì•„ìš”í•‘!")
        else:
            add_answer(question, answer.strip())
            st.success("ì €ì¥ ì™„ë£Œ! ëŒë©©ì´ê°€ í•œ ë²ˆ ë” ë°˜ì§ì˜€ì–´ìš” âœ¨")
            # ë‹¤ìŒ ë‹¨ê³„ ìë™ ì´ë™(ì‚¬ìš©ì ê²½í—˜ ê°•í™”)
            if st.session_state.step < len(STEPS) - 1:
                st.session_state.step += 1
            st.rerun()

    # Show history
    st.subheader("ğŸ“š ì§€ê¸ˆê¹Œì§€ì˜ ë‹µë³€(ê¸°ì–µí•˜ê³  ìˆì–´ìš”)")
    if not st.session_state.answers:
        st.caption("ì•„ì§ ë‹µë³€ì´ ì—†ì–´ìš”.")
    else:
        for i, qa in enumerate(st.session_state.answers, start=1):
            with st.expander(f"ğŸª¨ Q{i}. {qa['q']}"):
                st.write(qa["a"])
                st.caption(qa["ts"])

    # Final step: Generate report button
    if st.session_state.step == len(STEPS) - 1:
        st.divider()
        st.subheader("ğŸ§¾ ìµœì¢… ì •ë¦¬ ë¦¬í¬íŠ¸(ëŒë©©ì´ ìœ¤ë‚´ê¸°)")

        left, right = st.columns([1, 1])
        with left:
            st.write("ì´ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´, ì§€ê¸ˆê¹Œì§€ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ì½”ì¹˜ê°€ ìµœì¢… ì •ë¦¬ë¥¼ í•´ì¤˜ìš”.")
            st.caption("ì½”ì¹˜ê°€ ë‹¤ë¥´ë©´ ë¦¬í¬íŠ¸ì˜ í˜•íƒœ/ê²°ë¡  ë„ì¶œ ë°©ì‹ë„ í™• ë‹¬ë¼ì ¸ìš”.")
        with right:
            gen = st.button("âœ¨ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±", type="primary", use_container_width=True)

        if gen:
            with st.spinner("ëŒë©©ì´ì— ìœ¤ì„ ë‚´ëŠ” ì¤‘â€¦(ë¦¬í¬íŠ¸ ìƒì„±)"):
                report, err, dbg = generate_final_report()
                st.session_state.debug_log = dbg
                if report:
                    st.session_state.final_report = report
                else:
                    st.session_state.final_report = None
                    st.error(err or "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")
                    with st.expander("ğŸ”§ ë””ë²„ê·¸ ë¡œê·¸"):
                        st.write(dbg)

        if st.session_state.final_report:
            st.success("ì™„ë£Œ! ëŒë©©ì´ê°€ ë°˜ì§ë°˜ì§ ìœ¤ì´ ë‚¬ì–´ìš” âœ¨")
            st.markdown(st.session_state.final_report)

            st.markdown("### ğŸ“Œ ê³µìœ ìš© ìš”ì•½(JSON)")
            share = {
                "category": st.session_state.category,
                "decision_type": st.session_state.decision_type,
                "coach": coach["name"],
                "answers": st.session_state.answers,
                "final_report": st.session_state.final_report,
            }
            st.code(json.dumps(share, ensure_ascii=False, indent=2), language="json")

        with st.expander("ğŸ”§ ë””ë²„ê·¸ ë¡œê·¸ (ë¬¸ì œ ìƒê¸°ë©´ ì—¬ê¸° ë³µì‚¬í•´ì„œ ë³´ë‚´ì¤˜ìš”)"):
            st.write(st.session_state.debug_log)

# Footer: Streamlit Cloud checklist
st.divider()
with st.expander("âœ… Streamlit Cloud ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì§§ê²Œ)"):
    st.markdown(
        """
- **Secrets ì„¤ì •**: `OPENAI_API_KEY` ë¥¼ Streamlit Cloud â†’ Settings â†’ Secretsì— ì¶”ê°€  
- **requirements.txt** ì˜ˆì‹œ:
  - `streamlit`
  - `openai`
- **ëª¨ë¸ ê¶Œí•œ ì´ìŠˆ**ê°€ ìˆìœ¼ë©´:
  - ì•±ì´ ìë™ìœ¼ë¡œ `gpt-4o-mini`ë¡œ ì¬ì‹œë„í•´ìš”
  - ê·¸ë˜ë„ ì‹¤íŒ¨ ì‹œ, í™”ë©´ì˜ **ë””ë²„ê·¸ ë¡œê·¸**ë¥¼ ë³µì‚¬í•´ì„œ í™•ì¸
"""
    )
