# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ (Pebble Decision Coach)
#
# ì›ì¹™(ìœ ì§€):
# - ì •ë‹µ/ê²°ë¡ /ì¶”ì²œ ì œê³µ ê¸ˆì§€ (ê°•ì œ)
# - í•œ í™”ë©´ì— í•œ ì§ˆë¬¸ì”©
# - ì´ì „ ë‹µë³€ ë°˜ì˜ ë™ì  ì§ˆë¬¸ ìƒì„±
# - ë§ˆì§€ë§‰: ê³ ë¯¼ì˜ í•µì‹¬ / ì„ íƒ ê¸°ì¤€ / ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°, ì¶”ì²œ ê¸ˆì§€)
#
# ìœ ì§€ ê¸°ëŠ¥:
# - Logic Cross-Check(ë‹µë³€ ê°„ ì¶©ëŒ ê°ì§€ â†’ ì¶©ëŒì„ ì§šëŠ” ì§ˆë¬¸ ìš°ì„  ìƒì„±)
# - Probing(ë‹µë³€ 10ì ë¯¸ë§Œì´ë©´ 1íšŒ êµ¬ì²´í™” ì§ˆë¬¸)
# - "ì˜ ëª¨ë¥´ê² ì–´ìš”" ë“± ë‚œê° ë‹µë³€ ì‹œ: ì§ˆë¬¸ ì¬í”„ë ˆì´ë°/ëŒ€ì²´ ì§ˆë¬¸ 1íšŒ ìƒì„±(ìƒí™© ë°˜ì˜)
# - Action Coach ê°•í™”: If-Then íŠ¸ë¦¬ê±° + Pre-mortem ì§ˆë¬¸ í¬í•¨
# - Back ë²„íŠ¼
# - ê²°ì • ìœ í˜•ë³„ í…œí”Œë¦¿(2ë‹¨ê³„ì—ì„œ ìƒí™©ì„¤ëª… ê°€ì´ë“œ ì‚½ì… ë²„íŠ¼)
# - ë¦¬í¬íŠ¸: ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(st.data_editor), Mirroring ì‹œê°í™”, ë³µì‚¬/ë‹¤ìš´ë¡œë“œ, ìœ íš¨ê¸°ê°„, balloons
#
# ì´ë²ˆ ë°˜ì˜(ì¶”ê°€ ê¸°ëŠ¥ + ê°œì„ ):
# 1) â€œëª¨ìˆœ/ê¸´ì¥ ì§€ë„â€ ì‹œê°í™”(ë¦¬í¬íŠ¸)
# 2) â€œì •ë³´ ë¶€ì¡± ì²´í¬ë¦¬ìŠ¤íŠ¸â€(ì§ˆë¬¸ í˜•íƒœ 1~3ê°œ, ë¦¬í¬íŠ¸)
# 3) â€œì„¸ì…˜ í…œí”Œë¦¿ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°â€(í”„ë¦¬ì…‹)
# 4) â€œê°ì • ë³€í™” íŠ¸ë˜í‚¹(ì…€í”„ ì²´í¬)â€ (ì§ˆë¬¸ ì‹œì‘ ì „/ë¦¬í¬íŠ¸ì—ì„œ)
# 5) â€œë‹¤ìŒ ì„¸ì…˜ ì—°ê²° ì§ˆë¬¸â€(ë¦¬í¬íŠ¸ next_self_question ë‹µë³€ â†’ ìƒˆ ì„¸ì…˜ ì‹œì‘)
# 6) â€œí”„ë¼ì´ë²„ì‹œ ëª¨ë“œâ€(ë‹µë³€ ê¸°ë¡ ìˆ¨ê¸°ê¸° + ë‚´ë³´ë‚´ê¸° ë§ˆìŠ¤í‚¹ + ì¼ë¶€ í™”ë©´ ê°€ë¦¼)
# 7) crosscheck_used_for: set() â†’ list ì €ì¥(ì„¸ì…˜ ì§ë ¬í™” ì•ˆì •)
# 8) ë‚œê° ë‹µë³€ íŠ¸ë¦¬ê±° ì •êµí™”(â€œë‚œê° í‚¤ì›Œë“œ + ì •ë³´ ë¶€ì¡±â€ì¼ ë•Œë§Œ)
# 9) JSON íŒŒì‹± robustness ê°•í™”(í›„ë³´ ì—¬ëŸ¬ ê°œ ì¶”ì¶œ í›„ ì²« ì„±ê³µ)
# 10) ê¸ˆì¹™ì–´ íƒì§€ ì •ë°€ë„ ê°œì„ (â€œì¶”ì²œâ€ ë‹¨ë… ì œê±°, ë¬¸ì¥ íŒ¨í„´ ì¤‘ì‹¬)
# 11) ì˜¨ë³´ë”©/ë¦¬í¬íŠ¸: LLM ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ fallback JSON ìƒì„±(UX ì•ˆì •)
#
# í•„ìš”:
#   pip install streamlit openai pandas
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import random
import re
import textwrap
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ AI ê²°ì • ì½”ì¹­", page_icon="ğŸª¨", layout="wide")

MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

DECISION_TEMPLATES: Dict[str, str] = {
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] A vs B ì„ íƒ ì •ë¦¬
        1) Aì™€ Bë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í•´ë³´ì„¸ìš”(ë¬´ì—‡ì´ ë‹¤ë¥¸ê°€?)
        2) Aì˜ ì¥ì /ë‹¨ì , Bì˜ ì¥ì /ë‹¨ì ì„ ê°ê° 2~3ê°œì”© ì ì–´ë³´ì„¸ìš”
        3) 'ë‚´ê²Œ ì¤‘ìš”í•œ ê¸°ì¤€' 3ê°œë¥¼ ì ê³ , ê° ê¸°ì¤€ì—ì„œ A/Bê°€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì¨ë³´ì„¸ìš”
        4) ìµœì•…ì˜ ê²½ìš°(ë¦¬ìŠ¤í¬)ì™€ ê°ë‹¹ ê°€ëŠ¥í•œ ì •ë„ë¥¼ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì—¬ëŸ¬ ì˜µì…˜ ë¹„êµ
        1) í›„ë³´ ì˜µì…˜ì„ ëª¨ë‘ ë‚˜ì—´í•´ë³´ì„¸ìš”(ìµœì†Œ 3ê°œ)
        2) ë¹„êµ ê¸°ì¤€ 3~5ê°œ(ë¹„ìš©/ì‹œê°„/ì„±ì¥/ìŠ¤íŠ¸ë ˆìŠ¤/ê´€ê³„ ë“±)ë¥¼ ì ì–´ë³´ì„¸ìš”
        3) ê° ì˜µì…˜ì´ ê¸°ì¤€ë³„ë¡œ ì–´ë–¤ ëŠë‚Œì¸ì§€(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)ë¶€í„° ëŒ€ëµ ì ì–´ë³´ì„¸ìš”
        4) 'ì§€ê¸ˆì˜ ë‚˜'ì—ê²Œ ì¤‘ìš”í•œ ê²ƒê³¼ '1ë…„ ë’¤ì˜ ë‚˜'ì—ê²Œ ì¤‘ìš”í•œ ê²ƒì„ êµ¬ë¶„í•´ë³´ì„¸ìš”
        """
    ).strip(),
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)
        1) 'í•œë‹¤'ì˜ ì˜ë¯¸ë¥¼ êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ìˆ˜ì¤€ìœ¼ë¡œ?)
        2) í•œë‹¤ë©´ ì–»ëŠ” ê²ƒ/ìƒëŠ” ê²ƒ, ì•ˆ í•œë‹¤ë©´ ì–»ëŠ” ê²ƒ/ìƒëŠ” ê²ƒì„ ê°ê° ì ì–´ë³´ì„¸ìš”
        3) ê²°ì •ì´ ë¯¸ë¤„ì§ˆ ë•Œ ìƒê¸°ëŠ” ë¹„ìš©(ë¶ˆì•ˆ/ê¸°íšŒ/ê´€ê³„ ë“±)ì„ ì ì–´ë³´ì„¸ìš”
        4) ì§€ê¸ˆ ë‹¹ì¥ í•„ìš”í•œ ì¶”ê°€ ì •ë³´ 1~2ê°œê°€ ë¬´ì—‡ì¸ì§€ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì „ëµ/ì‹œì  ê²°ì •
        1) ì„±ê³µì˜ ì •ì˜ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ(ì¸¡ì • ê°€ëŠ¥í•˜ê²Œ)
        2) ì„ íƒ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ 2~3ê°œ(ë¹ ë¥´ê²Œ/ì²œì²œíˆ/ë¶€ë¶„ ì ìš© ë“±) ë‚˜ì—´
        3) ê° ì‹œë‚˜ë¦¬ì˜¤ì˜ ë¦¬ìŠ¤í¬ì™€ ì™„ì¶©ì¥ì¹˜(ë³´í—˜)ë¥¼ ì ì–´ë³´ì„¸ìš”
        4) 'ì‹œì‘ íŠ¸ë¦¬ê±°(If) â†’ í–‰ë™(Then)' í˜•íƒœë¡œ ì‹¤í–‰ ì¡°ê±´ì„ ì„¤ê³„í•´ë³´ì„¸ìš”
        """
    ).strip(),
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ê°ˆë“±/ëŒ€í™” ë°©í–¥ ì •ë¦¬
        1) ì§€ê¸ˆ ê°ˆë“±ì˜ ìŸì ì„ 'ì‚¬ì‹¤/í•´ì„/ê°ì •/ìš”êµ¬'ë¡œ ë‚˜ëˆ  ì ì–´ë³´ì„¸ìš”
        2) ë‚´ê°€ ì›í•˜ëŠ” ë³€í™”(ìš”êµ¬) 1~2ê°œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”
        3) ìƒëŒ€ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸¸ ë§Œí•œ ê²ƒì„ ì¶”ì¸¡í•´ ì ì–´ë³´ì„¸ìš”(í™•ì • ì•„ë‹˜)
        4) ëŒ€í™”ì—ì„œ ì§€í‚¤ê³  ì‹¶ì€ ì›ì¹™(í†¤/íƒ€ì´ë°/í•œê³„ì„ )ì„ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
}

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” êµ¬ì¡° ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê³ , ê°€ì •ì„ í”ë“œëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì •ë¦¬ë¥¼ ë•ìŠµë‹ˆë‹¤",
        "style": "MECE/ê¸°ì¤€/ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ)",
        "method": [
            "ìƒí™©Â·ì œì•½Â·ì˜µì…˜ì„ ë¶„ë¦¬í•´ì„œ ì ê²Œ í•˜ê¸°",
            "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ì•„ ìš°ì„ ìˆœìœ„ë¥¼ í™•ì¸í•˜ê¸°",
            "â€˜ë‚´ê°€ ë‹¹ì—°í•˜ë‹¤ê³  ë¯¿ëŠ” ê°€ì •â€™ì„ ë°˜ëŒ€ë¡œ ë’¤ì§‘ì–´ ë³´ê¸°",
        ],
        "prompt_hint": "MECE, ê¸°ì¤€ ëª©ë¡, ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°)",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜ ì½”ì¹˜",
        "tagline": "ê°ì •ê³¼ ê°€ì¹˜ë¥¼ ë¶„ë¦¬í•´, í›„íšŒê°€ ì ì€ ê¸°ì¤€ì„ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤",
        "style": "ê°ì • ë¼ë²¨ë§/ê°€ì¹˜ ë¶„ë¦¬/í›„íšŒ ìµœì†Œí™”",
        "method": [
            "ê°ì • ë¼ë²¨ë§(ì§€ê¸ˆ ëŠë¼ëŠ” ê²ƒ) â†’ ì´ìœ ",
            "ê·¸ ê°ì •ì´ â€˜ì¼ì‹œì  í¸ì•ˆí•¨â€™ì¸ì§€ â€˜ì¥ê¸° ê°€ì¹˜â€™ì¸ì§€ ë¶„ë¦¬",
            "ê°€ì¹˜ Top3 ë„ì¶œ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸",
        ],
        "prompt_hint": "ê°ì •-ê°€ì¹˜ ë¶„ë¦¬, ê°€ì¹˜ Top3, ë¯¸ë˜ì˜ ë‚˜ ì§ˆë¬¸",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê³„íšì„ â€˜ì •ë¦¬â€™í•˜ê³ , ì˜¤ëŠ˜ 5ë¶„ Quick Winê¹Œì§€ ìŠ¤ìŠ¤ë¡œ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤(ì¶”ì²œ ê¸ˆì§€)",
        "style": "ìš°ì„ ìˆœìœ„/If-Then/í”„ë¦¬ëª¨í…œ/Quick Win",
        "method": [
            "ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°: íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ Top1~3 ì •ë¦¬",
            "ì‹¤í–‰ì„ â€˜ì–¸ì œâ€™ê°€ ì•„ë‹ˆë¼ â€˜If-Then íŠ¸ë¦¬ê±°â€™ë¡œ ì„¤ê³„",
            "ì‹¤íŒ¨ë¥¼ ë¯¸ë¦¬ ê°€ì •(í”„ë¦¬ëª¨í…œ)í•´ ë°©í•´ ìš”ì¸ì„ ë“œëŸ¬ë‚´ê¸°",
            "ë§ˆì§€ë§‰ì— â€˜ì˜¤ëŠ˜ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ ë„ì¶œ",
        ],
        "prompt_hint": "ìš°ì„ ìˆœìœ„, If-Then, í”„ë¦¬ëª¨í…œ, Quick Win",
    },
]

# Probing ê¸°ì¤€: 10ì ë¯¸ë§Œì´ë©´ 1íšŒ ì¶”ê°€ ì§ˆë¬¸
MIN_ANSWER_CHARS = 10

# ë‚œê° í‚¤ì›Œë“œ(â€œëª¨ë¥´ê² /ê°ì´ ì•ˆ ì™€â€ ë“±)
CONFUSED_ANSWER_PATTERNS = [
    r"ëª¨ë¥´ê² ",
    r"ì˜\s*ëª¨ë¥´",
    r"ê°ì´\s*ì•ˆ",
    r"ìƒê°ì´\s*ì•ˆ",
    r"ì–´ë µ",
]

# â€œì§§ì€/íšŒí”¼â€ ë‹µë³€ íŒ¨í„´(ê¸°ì¡´ probing)
SHORT_ANSWER_PATTERNS = [
    r"^ëª¨ë¥´ê² ",
    r"^ì˜\s*ëª¨ë¥´",
    r"^ê·¸ëƒ¥",
    r"^ì—†ì–´",
    r"^ëª¨ë¦„$",
    r"^ã„´ã„´$",
    r"^ëª°ë¼$",
]


# =========================
# Pebble SVG (no PIL)
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    return f"""
<svg width="160" height="120" viewBox="0 0 160 120" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="pebble">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="80%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M28 80
           C14 60, 20 30, 50 20
           C66 14, 96 12, 114 24
           C142 44, 150 68, 130 88
           C112 108, 54 110, 28 80 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M54 30 C68 22, 82 22, 94 30"
        fill="none" stroke="{shine}" stroke-width="7" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_svg_b64(progress_0_to_1: float, inactive: bool = False) -> str:
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    if inactive:
        fill, shine = "#2f3136", "#6b6f7a"
    else:
        fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
        shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"
    svg = _pebble_svg(fill=fill, shine=shine)
    return base64.b64encode(svg.encode("utf-8")).decode("ascii")


def render_pebble_bridge(current_idx: int, total: int, labels: List[str]) -> None:
    total = max(2, int(total))
    current_idx = max(0, min(int(current_idx), total - 1))
    left_pct = ((current_idx + 0.5) / total) * 100.0

    pebble_imgs = []
    for i in range(total):
        active = i <= current_idx
        p = (i + 1) / total
        b64 = pebble_svg_b64(p, inactive=not active)
        pebble_imgs.append(b64)

    html = """
<style>
.pebble-bridge-wrap{
  position: relative;
  width: 100%;
  margin: 6px 0 2px 0;
  padding: 16px 4px 0 4px;
}
.pebble-row{
  display: flex;
  gap: 10px;
  align-items: flex-end;
  justify-content: space-between;
}
.pebble-cell{
  flex: 1;
  min-width: 0;
  text-align: center;
}
.pebble-img{
  width: 100%;
  max-width: 120px;
  height: auto;
  display: inline-block;
}
.pebble-label{
  font-size: 12px;
  margin-top: 4px;
  opacity: 0.85;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}
.walker{
  position: absolute;
  top: -10px;
  left: VAR_LEFT%;
  transform: translateX(-50%) scaleX(-1);
  font-size: 40px;
  line-height: 1;
  transition: left 520ms cubic-bezier(.2,.9,.2,1);
  filter: drop-shadow(0px 2px 2px rgba(0,0,0,0.25));
  animation: bob 800ms ease-in-out infinite;
  user-select: none;
}
@keyframes bob{
  0%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
  50%{ transform: translateX(-50%) translateY(-3px) scaleX(-1); }
  100%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
}
</style>
<div class="pebble-bridge-wrap">
  <div class="walker">ğŸš¶</div>
  <div class="pebble-row">
    VAR_PEBBLES
  </div>
</div>
""".strip()

    pebble_cells = []
    for i in range(total):
        opacity = "1.0" if i <= current_idx else "0.55"
        cell = f"""
<div class="pebble-cell" style="opacity:{opacity}">
  <img class="pebble-img" src="data:image/svg+xml;base64,{pebble_imgs[i]}" />
  <div class="pebble-label">{labels[i] if i < len(labels) else ""}</div>
</div>
""".strip()
        pebble_cells.append(cell)

    html = html.replace("VAR_LEFT", f"{left_pct:.3f}")
    html = html.replace("VAR_PEBBLES", "\n".join(pebble_cells))
    st.markdown(html, unsafe_allow_html=True)


def render_hero_pebble(progress: float, label: str) -> None:
    b64 = pebble_svg_b64(progress, inactive=False)
    st.markdown(
        f"""
<div style="text-align:center;">
  <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:240px;"/>
  <div style="margin-top:6px; font-size:14px;">{label}</div>
</div>
""",
        unsafe_allow_html=True,
    )


# =========================
# OpenAI
# =========================
def get_api_key() -> str:
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install openai`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.6) -> Tuple[Optional[str], Optional[str], List[str]]:
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. Secretsì— OPENAI_API_KEYë¥¼ ë„£ê±°ë‚˜ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    # Responses API ìš°ì„ 
    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    # Chat Completions fallback
    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.", debug


# =========================
# State + routing
# =========================
def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def init_state() -> None:
    if "page" not in st.session_state:
        st.session_state.page = "landing"

    if "user_problem" not in st.session_state:
        st.session_state.user_problem = ""

    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]
    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]
    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]
    if "goal" not in st.session_state:
        st.session_state.goal = ""
    if "options" not in st.session_state:
        st.session_state.options = ""
    if "situation" not in st.session_state:
        st.session_state.situation = ""

    if "num_questions" not in st.session_state:
        st.session_state.num_questions = 5

    if "q_index" not in st.session_state:
        st.session_state.q_index = 0
    if "questions" not in st.session_state:
        st.session_state.questions = []
    if "answers" not in st.session_state:
        st.session_state.answers = []

    # probe ìƒíƒœ + ì¢…ë¥˜(ì§§ìŒ probe vs ì¬í”„ë ˆì´ë°)
    if "probe_active" not in st.session_state:
        st.session_state.probe_active = False
    if "probe_question" not in st.session_state:
        st.session_state.probe_question = ""
    if "probe_for_index" not in st.session_state:
        st.session_state.probe_for_index = None  # type: ignore
    if "probe_mode" not in st.session_state:
        st.session_state.probe_mode = ""  # "short" | "reframe" | ""

    # â˜… ì„¸ì…˜ ì§ë ¬í™” ì•ˆì •: set() ëŒ€ì‹  list ì €ì¥
    if "crosscheck_used_for" not in st.session_state:
        st.session_state.crosscheck_used_for = []  # list[int]

    if "final_report_json" not in st.session_state:
        st.session_state.final_report_json = None
    if "final_report_raw" not in st.session_state:
        st.session_state.final_report_raw = None
    if "report_just_entered" not in st.session_state:
        st.session_state.report_just_entered = False

    if "decision_matrix_df" not in st.session_state:
        st.session_state.decision_matrix_df = None

    # ì˜¨ë³´ë”© ì¶”ì²œ ìƒíƒœ
    if "onboarding_reco" not in st.session_state:
        st.session_state.onboarding_reco = None
    if "onboarding_raw" not in st.session_state:
        st.session_state.onboarding_raw = None
    if "onboarding_applied" not in st.session_state:
        st.session_state.onboarding_applied = False

    # í”„ë¦¬ì…‹(ì„¸ì…˜ í…œí”Œë¦¿)
    if "saved_templates" not in st.session_state:
        st.session_state.saved_templates = []  # list[dict]

    # ê°ì • íŠ¸ë˜í‚¹(ì…€í”„ ì²´í¬)
    if "emotion_pre" not in st.session_state:
        st.session_state.emotion_pre = None
    if "emotion_post" not in st.session_state:
        st.session_state.emotion_post = None

    # í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ
    if "privacy_mode" not in st.session_state:
        st.session_state.privacy_mode = False
    if "hide_history" not in st.session_state:
        st.session_state.hide_history = False
    if "mask_export" not in st.session_state:
        st.session_state.mask_export = True

    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []
    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""


def reset_flow(to_page: str = "landing", keep_problem: bool = False) -> None:
    """
    keep_problem=Trueë©´ user_problemì€ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ íë¦„ì„ ì´ˆê¸°í™”(ìœ ì‹¤ ë°©ì§€ ì˜µì…˜)
    """
    st.session_state.page = to_page

    if not keep_problem:
        st.session_state.user_problem = ""

    # ì˜¨ë³´ë”© ì¶”ì²œ ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.onboarding_reco = None
    st.session_state.onboarding_raw = None
    st.session_state.onboarding_applied = False

    # setup details
    st.session_state.category = TOPIC_CATEGORIES[0][0]
    st.session_state.decision_type = DECISION_TYPES[0]
    st.session_state.coach_id = COACHES[0]["id"]
    st.session_state.goal = ""
    st.session_state.options = ""
    st.session_state.situation = (st.session_state.user_problem or "").strip()

    st.session_state.num_questions = int(st.session_state.get("num_questions", 5))

    # q flow
    st.session_state.q_index = 0
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.probe_mode = ""
    st.session_state.crosscheck_used_for = []  # listë¡œ ì´ˆê¸°í™”

    # report
    st.session_state.final_report_json = None
    st.session_state.final_report_raw = None
    st.session_state.decision_matrix_df = None
    st.session_state.report_just_entered = False

    # emotion
    st.session_state.emotion_pre = None
    st.session_state.emotion_post = None

    st.session_state.debug_log = []


def add_answer(q: str, a: str, kind: str, main_index: int, subkind: str = "") -> None:
    st.session_state.answers.append(
        {
            "q": q,
            "a": a,
            "ts": datetime.now().isoformat(timespec="seconds"),
            "kind": kind,  # "main" | "probe"
            "subkind": subkind,  # "short" | "reframe" | ""
            "main_index": main_index,
        }
    )


def main_answer_count() -> int:
    return sum(1 for x in st.session_state.answers if x.get("kind") == "main")


# =========================
# Helpers
# =========================
def normalize(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


def token_overlap(a: str, b: str) -> float:
    def toks(s: str) -> set:
        s = re.sub(r"[^\wê°€-í£ ]", " ", s)
        s = re.sub(r"\s+", " ", s).strip().lower()
        return set([t for t in s.split(" ") if len(t) >= 2])

    ta, tb = toks(a), toks(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    denom = max(1, min(len(ta), len(tb)))
    return inter / denom


def is_similar(a: str, b: str) -> bool:
    a0, b0 = normalize(a), normalize(b)
    if not a0 or not b0:
        return False
    if a0 == b0:
        return True
    if a0 in b0 or b0 in a0:
        return True
    return token_overlap(a0, b0) >= 0.75


def is_too_short_answer(ans: str) -> bool:
    a = (ans or "").strip()
    if len(a) < MIN_ANSWER_CHARS:
        return True
    for pat in SHORT_ANSWER_PATTERNS:
        if re.search(pat, a):
            return True
    return False


def _has_meaningful_content(ans: str) -> bool:
    """
    ë‚œê° í‚¤ì›Œë“œê°€ ìˆì–´ë„, ì‹¤ì œë¡œëŠ” ê½¤ ë§ì€ êµ¬ì²´ ì •ë³´ê°€ ë‹´ê¸´ ê²½ìš°ê°€ ìˆìŒ.
    - â€˜ë‚œê° í‚¤ì›Œë“œ + ì •ë³´ ë¶€ì¡±â€™ì¼ ë•Œë§Œ ì¬í”„ë ˆì´ë°ì„ íŠ¸ë¦¬ê±°í•˜ê¸° ìœ„í•œ ë³´ì¡° í•¨ìˆ˜.
    """
    a = normalize(ans)
    if not a:
        return False

    # ìˆ«ì/ê¸°ê°„/ê³ ìœ ëª…/ì˜µì…˜(A,B ë“±) ê°™ì€ â€œì •ë³´ì„±â€ ì‹ í˜¸ê°€ ìˆìœ¼ë©´ ì˜ë¯¸ ìˆëŠ” ë‚´ìš©ìœ¼ë¡œ ê°„ì£¼
    signals = 0
    if re.search(r"\d", a):
        signals += 1
    if re.search(r"(ì´ë²ˆ\s*ì£¼|ë‹¤ìŒ\s*ì£¼|ì´ë²ˆ\s*ë‹¬|ì˜¬í•´|ë‚´ë…„|ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ|ì£¼ë§)", a):
        signals += 1
    if re.search(r"(A|B|C)\s*(ì•ˆ|ì„|ë¥¼)?", a):
        signals += 1
    if len(a) >= 35:
        signals += 1
    # ì‰¼í‘œ/ì¤„ë°”ê¿ˆ ë“± ë‚˜ì—´ êµ¬ì¡°ë„ ì •ë³´ì„± ì‹ í˜¸
    if a.count(",") >= 2:
        signals += 1

    return signals >= 2


def is_confused_answer(ans: str) -> bool:
    """
    ê°œì„ : â€œë‚œê° í‚¤ì›Œë“œâ€ê°€ ìˆë”ë¼ë„ ì •ë³´ê°€ ì¶©ë¶„í•˜ë©´ ì¬í”„ë ˆì´ë°ì„ ê°•ì œí•˜ì§€ ì•ŠìŒ.
    ì¦‰, (ë‚œê° í‚¤ì›Œë“œ) AND (ì§§ê±°ë‚˜ ì •ë³´ ë¶€ì¡±)ì¼ ë•Œë§Œ True.
    """
    a = (ans or "").strip()
    if not a:
        return False

    has_confused_kw = any(re.search(pat, a) for pat in CONFUSED_ANSWER_PATTERNS)
    if not has_confused_kw:
        return False

    # ì§§ê±°ë‚˜ ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œë§Œ ë‚œê° ì²˜ë¦¬
    if is_too_short_answer(a):
        return True
    if not _has_meaningful_content(a):
        return True
    return False


def parse_options() -> List[str]:
    return [o.strip() for o in (st.session_state.options or "").split(",") if o.strip()]


def mask_text_for_privacy(text: str) -> str:
    """
    í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ ë‚´ë³´ë‚´ê¸° ë§ˆìŠ¤í‚¹:
    - ì´ë©”ì¼, ì „í™”/ìˆ«ìì—´(ê¸¸ê²Œ), URL ë¹„ìŠ·í•œ ê²ƒ, ë‚ ì§œ/ì‹œê°„ ì¼ë¶€ ë§ˆìŠ¤í‚¹
    - ì™„ë²½í•œ ìµëª…í™”ê°€ ì•„ë‹ˆë¼ â€œê³µìœ  ìœ„í—˜ ë‚®ì¶”ê¸°â€ ëª©ì 
    """
    t = text or ""
    t = re.sub(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", "[ì´ë©”ì¼]", t)
    t = re.sub(r"(https?://\S+)", "[ë§í¬]", t)
    # ê¸¸ê²Œ ì´ì–´ì§„ ìˆ«ì(ê³„ì¢Œ/ì „í™” ë“± ê°€ëŠ¥)
    t = re.sub(r"\b\d{6,}\b", "[ìˆ«ì]", t)
    # ë‚ ì§œ í˜•íƒœ ì¼ë¶€
    t = re.sub(r"\b\d{4}-\d{2}-\d{2}\b", "[ë‚ ì§œ]", t)
    # ì‹œê°„ í˜•íƒœ ì¼ë¶€
    t = re.sub(r"\b\d{1,2}:\d{2}(:\d{2})?\b", "[ì‹œê°„]", t)
    return t


# =========================
# JSON parsing robustness
# =========================
def extract_json_candidates(text: str) -> List[str]:
    """
    ì¤‘ê´„í˜¸ ê· í˜• ìŠ¤ìº”ìœ¼ë¡œ JSON í›„ë³´ë“¤ì„ ì¶”ì¶œ.
    - ëª¨ë¸ì´ JSON ì•ë’¤ë¡œ ì„¤ëª…ì„ ë¶™ì´ê±°ë‚˜
    - ì¤‘ê´„í˜¸ ë¸”ë¡ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°ë¥¼ ê²¬ë”¤
    """
    if not text:
        return []
    s = text.strip()

    candidates: List[str] = []
    stack = 0
    start = None

    for i, ch in enumerate(s):
        if ch == "{":
            if stack == 0:
                start = i
            stack += 1
        elif ch == "}":
            if stack > 0:
                stack -= 1
                if stack == 0 and start is not None:
                    block = s[start : i + 1].strip()
                    if len(block) >= 2:
                        candidates.append(block)
                    start = None

    # ê°€ì¥ í° ë¸”ë¡ì„ ìš°ì„ (ëŒ€ê°œ ìµœì¢… JSON)
    candidates = sorted(set(candidates), key=len, reverse=True)
    return candidates


def safe_json_parse(text: str) -> Optional[Dict[str, Any]]:
    if not text:
        return None
    raw = text.strip()

    # 1) í†µìœ¼ë¡œ íŒŒì‹± ì‹œë„
    try:
        obj = json.loads(raw)
        if isinstance(obj, dict):
            return obj
    except Exception:
        pass

    # 2) í›„ë³´ ë¸”ë¡ë“¤ ì¤‘ ì²« ì„±ê³µ ì‚¬ìš©
    for cand in extract_json_candidates(raw):
        try:
            obj = json.loads(cand)
            if isinstance(obj, dict):
                return obj
        except Exception:
            continue

    return None


# =========================
# Onboarding: AI ë¶„ì„/ì¶”ì²œ(2ë‹¨ê³„)
# =========================
def system_prompt_for_onboarding() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì˜¨ë³´ë”© ë¶„ì„ê¸°ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìì˜ ê³ ë¯¼ í…ìŠ¤íŠ¸ë¥¼ ì½ê³ , ì•„ë˜ í•­ëª©ì„ 'ì¶”ì²œ'í•˜ë˜, ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì¶”ì²œì€ 'ë¶„ë¥˜/ì´ˆì•ˆ ì œì•ˆ' ìˆ˜ì¤€ì´ë©° ì‚¬ìš©ìê°€ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ(ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€).\n"
    )


def user_prompt_for_onboarding(problem_text: str) -> str:
    cats = [c[0] for c in TOPIC_CATEGORIES]
    coaches = [{"id": c["id"], "name": c["name"], "tagline": c["tagline"]} for c in COACHES]
    dtypes = DECISION_TYPES

    return textwrap.dedent(
        f"""
        [ì‚¬ìš©ì ê³ ë¯¼]
        {problem_text}

        [ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬]
        {cats}

        [ê°€ëŠ¥í•œ ê²°ì • ìœ í˜•]
        {dtypes}

        [ê°€ëŠ¥í•œ ì½”ì¹˜]
        {coaches}

        ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:
        {{
          "recommended_category": "string (cats ì¤‘ í•˜ë‚˜)",
          "recommended_decision_type": "string (dtypes ì¤‘ í•˜ë‚˜)",
          "recommended_coach_id": "string (logic|value|action)",
          "coach_reason": "string (ì§§ê²Œ, ì™œ ì´ ì½”ì¹˜ê°€ ë§ëŠ”ì§€)",
          "goal_draft": "string (ì‚¬ìš©ìê°€ ì–»ê³  ì‹¶ì–´ í•  ë²•í•œ 'ì›í•˜ëŠ” ëª©í‘œ' ì´ˆì•ˆ, ì§€ì‹œ/ì¶”ì²œ ê¸ˆì§€ í‘œí˜„)",
          "options_hint": "string (ì˜µì…˜ì´ ìˆì„ ìˆ˜ë„ ìˆìŒì„ ìƒê¸°ì‹œí‚¤ëŠ” ì§§ì€ ì§ˆë¬¸í˜• íŒíŠ¸. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥)"
        }}

        ê·œì¹™:
        - ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ/ê°•ìš” ê¸ˆì§€
        - goal_draftëŠ” 'ì´ˆì•ˆ'ìœ¼ë¡œë§Œ ì œì‹œ
        """
    ).strip()


def onboarding_fallback(problem_text: str) -> Dict[str, Any]:
    # ì•„ì£¼ ë³´ìˆ˜ì ì¸ ê·œì¹™ ê¸°ë°˜ ì´ˆì•ˆ
    txt = normalize(problem_text)
    cat = "ğŸ“¦ ê¸°íƒ€"
    if any(k in txt for k in ["ì·¨ì—…", "ì´ì§", "ì§„ë¡œ", "ì „ê³µ", "í•™ì—…", "ëŒ€í•™ì›"]):
        cat = "ğŸ“ í•™ì—…/ì§„ë¡œ"
    elif any(k in txt for k in ["í”„ë¡œì íŠ¸", "ì—…ë¬´", "íŒ€", "íšŒì‚¬", "ë¦¬ë”", "ì„±ê³¼", "ì»¤ë¦¬ì–´"]):
        cat = "ğŸ’¼ ì»¤ë¦¬ì–´/ì¼"
    elif any(k in txt for k in ["ì—°ì¸", "ì¹œêµ¬", "ê°€ì¡±", "ê°ˆë“±", "ê´€ê³„", "ëŒ€í™”"]):
        cat = "ğŸ’– ê´€ê³„"
    elif any(k in txt for k in ["ëˆ", "ì˜ˆì‚°", "ì†Œë¹„", "ì €ì¶•", "íˆ¬ì", "êµ¬ë§¤"]):
        cat = "ğŸ’° ëˆ/ì†Œë¹„"
    elif any(k in txt for k in ["ë¶ˆì•ˆ", "ë²ˆì•„ì›ƒ", "ìš°ìš¸", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë§ˆìŒ", "ì‚¶"]):
        cat = "ğŸ§  ë§ˆìŒ/ì‚¶"

    dtype = "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)" if any(k in txt for k in ["í• ê¹Œ", "ë§ê¹Œ", "í•´ì•¼", "ê·¸ë§Œ", "ì‹œì‘"]) else "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ"
    coach_id = "logic"
    if any(k in txt for k in ["ë¶ˆì•ˆ", "í›„íšŒ", "ê°ì •", "ë§ˆìŒ", "ê´€ê³„"]):
        coach_id = "value"
    if any(k in txt for k in ["ê³„íš", "ì‹¤í–‰", "ë£¨í‹´", "ìŠµê´€", "ì¼ì •", "ê³µë¶€ë²•"]):
        coach_id = "action"

    return {
        "recommended_category": cat,
        "recommended_decision_type": dtype,
        "recommended_coach_id": coach_id,
        "coach_reason": "ì‚¬ìš©ìê°€ ë§í•œ ê³ ë¯¼ì—ì„œ â€˜ì •ë¦¬/ê¸°ì¤€/ê°ì •/ì‹¤í–‰â€™ ì¤‘ ë¬´ì—‡ì´ ë‘ë“œëŸ¬ì§€ëŠ”ì§€ì— ë§ì¶˜ ì´ˆì•ˆì…ë‹ˆë‹¤.",
        "goal_draft": "ì§€ê¸ˆ ê³ ë¯¼ì—ì„œ ë‚´ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê¸°ì¤€ê³¼ ê°ë‹¹ ê°€ëŠ¥í•œ ë¦¬ìŠ¤í¬ë¥¼ ë” ì„ ëª…í•˜ê²Œ ì ì–´ë³´ê³  ì‹¶ë‹¤(ì´ˆì•ˆ).",
        "options_hint": "ì§€ê¸ˆ ë– ì˜¤ë¥´ëŠ” ì„ íƒì§€/ê°€ëŠ¥ì„±(ìˆë‹¤ë©´)ì„ ì‰¼í‘œë¡œ 2~4ê°œë§Œ ì ì–´ë³¼ ìˆ˜ ìˆì„ê¹Œìš”?",
    }


def generate_onboarding_recommendation(problem_text: str) -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    system = system_prompt_for_onboarding()
    user = user_prompt_for_onboarding(problem_text)
    txt, err, dbg = call_openai_text(system=system, user=user, temperature=0.2)
    if not txt:
        # fallback
        fb = onboarding_fallback(problem_text)
        dbg.append("Onboarding fallback used (no model output).")
        return fb, err, dbg, None

    data = safe_json_parse(txt)
    if not data:
        fb = onboarding_fallback(problem_text)
        dbg.append("Onboarding fallback used (JSON parse fail).")
        return fb, "ì˜¨ë³´ë”© ì¶”ì²œ JSON íŒŒì‹± ì‹¤íŒ¨(ëŒ€ì²´ ì´ˆì•ˆì„ í‘œì‹œí•©ë‹ˆë‹¤)", dbg, txt

    return data, None, dbg, txt


# =========================
# Question generation
# =========================
def system_prompt_for_questions(coach: Dict[str, Any]) -> str:
    base = (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì •ë‹µ/í•´ê²°ì±…/ì¶”ì²œì„ ì£¼ì§€ ë§ê³ , ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ì§ˆë¬¸ë§Œ ë˜ì§€ì„¸ìš”.\n"
        "ê¸ˆì§€: ê²°ë¡ , ì¶”ì²œ, ì„ íƒ ê°•ìš”, íŒë‹¨ë¬¸(ì˜ˆ: Aê°€ ë‚«ë‹¤), ì§€ì‹œë¬¸(í•´ì•¼ í•œë‹¤/í•˜ì).\n"
        "ì¶œë ¥: ì§ˆë¬¸ 1ê°œë§Œ. (ì„¤ëª…/ë²ˆí˜¸/ë¨¸ë¦¬ë§ ê¸ˆì§€)\n"
    )
    if coach["id"] == "logic":
        return base + "ìŠ¤íƒ€ì¼: êµ¬ì¡°í™”/ê¸°ì¤€/ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°) ì§ˆë¬¸.\n"
    if coach["id"] == "value":
        return base + "ìŠ¤íƒ€ì¼: ê°ì • ë¼ë²¨ë§ + ê°ì •/ê°€ì¹˜ ë¶„ë¦¬ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸.\n"
    return base + "ìŠ¤íƒ€ì¼: If-Then íŠ¸ë¦¬ê±°/í”„ë¦¬ëª¨í…œ/ìš°ì„ ìˆœìœ„/Quick Winì„ ëª¨ë‘ ì§ˆë¬¸ìœ¼ë¡œë§Œ ìœ ë„.\n"


def build_context_block() -> str:
    hist = ""
    tail = st.session_state.answers[-6:]
    for i, qa in enumerate(tail, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        hist += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"

    opts = parse_options()
    opts_txt = "\n".join([f"- {o}" for o in opts]) if opts else "(ë¯¸ì…ë ¥)"

    return textwrap.dedent(
        f"""
        [ì„¸ì…˜ ì‹œì‘ ì •ë³´]
        - ì¹´í…Œê³ ë¦¬: {st.session_state.category}
        - ê²°ì • ìœ í˜•: {st.session_state.decision_type}
        - ìƒí™© ì„¤ëª…: {st.session_state.situation or "(ë¯¸ì…ë ¥)"}
        - ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal or "(ë¯¸ì…ë ¥)"}
        - ê³ ë ¤ ì˜µì…˜(ìˆë‹¤ë©´): {opts_txt}

        [ìµœê·¼ Q/A]
        {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
        """
    ).strip()


def probing_instruction(last_q: str, last_a: str) -> str:
    return textwrap.dedent(
        f"""
        ì‚¬ìš©ìì˜ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª¨í˜¸í•©ë‹ˆë‹¤.
        ì•„ë˜ì˜ ì§ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ êµ¬ì²´í™”í•  ìˆ˜ ìˆë„ë¡ ë”± 1ê°œì˜ ì¶”ê°€ ì§ˆë¬¸(Probe)ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

        - ì§ì „ ì§ˆë¬¸: {last_q}
        - ì§ì „ ë‹µë³€: {last_a}

        ìš”êµ¬ì‚¬í•­:
        - 'êµ¬ì²´í™”'ë¥¼ ë•ëŠ” ì§ˆë¬¸(ì˜ˆ: ì˜ˆì‹œ/ìƒí™©/ê¸°ì¤€/ì´ìœ /ë²”ìœ„/ê¸°ê°„/ìš°ì„ ìˆœìœ„ ì¤‘ í•˜ë‚˜ë¥¼ ë” ë¬»ê¸°)
        - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ ê¸ˆì§€
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
        """
    ).strip()


def reframe_instruction(last_q: str, last_a: str) -> str:
    return textwrap.dedent(
        f"""
        ì‚¬ìš©ìê°€ ì§ˆë¬¸ì— ëŒ€í•´ "ì˜ ëª¨ë¥´ê² ì–´ìš”/ê°ì´ ì•ˆ ì™€ìš”/ì–´ë ¤ì›Œìš”" ê°™ì€ ë°˜ì‘ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
        ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•´, ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ê²Œ ì§ˆë¬¸ì„ ë” ì‰½ê²Œ í’€ì–´ ì“°ê±°ë‚˜(ì¬í”„ë ˆì´ë°),
        ë˜ëŠ” ë” ë‹µí•˜ê¸° ì‰¬ìš´ ëŒ€ì²´ ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

        [ì‚¬ìš©ì ìƒí™© ì„¤ëª…]
        {st.session_state.situation or "(ë¯¸ì…ë ¥)"}

        [ì§ì „ ì§ˆë¬¸]
        {last_q}

        [ì‚¬ìš©ì ë‹µë³€(ë‚œê° í‘œí˜„ í¬í•¨)]
        {last_a}

        ìš”êµ¬ì‚¬í•­:
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
        - ì •ë‹µ/ì¶”ì²œ/ì§€ì‹œ/íŒë‹¨ ê¸ˆì§€
        - â€œë¨¼ì € Aë¥¼ í•˜ì„¸ìš”â€ ê°™ì€ ë‹¨ê³„ ì§€ì‹œ ê¸ˆì§€
        - ë‹µí•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ:
          ì˜ˆ) ì„ íƒì§€ë¥¼ ì œê³µ(ë‘˜ ì¤‘ ë¬´ì—‡ì— ë” ê°€ê¹Œìš´ì§€), ì˜ˆì‹œ ìš”êµ¬, ë²”ìœ„ ì¢íˆê¸°(ì´ë²ˆ ì£¼/ì˜¤ëŠ˜), ê¸°ì¤€ 1ê°œë§Œ ë¬»ê¸° ë“±
        """
    ).strip()


def crosscheck_system_prompt() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ë…¼ë¦¬ ì¶©ëŒ ê°ì§€ê¸°ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìì˜ ì´ì „ ë‹µë³€ë“¤ ì‚¬ì´ì— 'ìš°ì„ ìˆœìœ„/ê¸°ì¤€/ëª©í‘œ'ê°€ ì„œë¡œ ì¶©ëŒí•˜ëŠ”ì§€ ì ê²€í•˜ì„¸ìš”.\n"
        "ì¤‘ìš”: ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”. ì§ˆë¬¸ì„ ë§Œë“¤ ë•Œë„ ê°•ìš”/íŒë‹¨ ê¸ˆì§€.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ. (ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€)\n"
    )


def crosscheck_user_prompt(current_main_index: int) -> str:
    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    tail = mains[-6:]
    qa = ""
    for i, x in enumerate(tail, start=1):
        qa += f"{i}) Q: {x['q']}\n   A: {x['a']}\n"

    return textwrap.dedent(
        f"""
        ì•„ë˜ëŠ” ì‚¬ìš©ì ë‹µë³€ ì¼ë¶€ì…ë‹ˆë‹¤. ë‹µë³€ë“¤ ì‚¬ì´ì— ë…¼ë¦¬ì  ì¶©ëŒ(ê¸°ì¤€/ìš°ì„ ìˆœìœ„ì˜ ìƒì¶©)ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.
        ì¶©ëŒì´ ìˆë‹¤ë©´, ê·¸ ì¶©ëŒì„ ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ 'ì •ë¦¬'í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì œì•ˆí•˜ì„¸ìš”.
        ì¶©ëŒì´ ì—†ë‹¤ë©´ has_conflict=falseë¡œ ë‘ì„¸ìš”.

        [ë‹µë³€ë“¤]
        {qa if qa.strip() else "(ë‹µë³€ ì—†ìŒ)"}

        [ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]
        {{
          "has_conflict": true/false,
          "conflict_summary": "string (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
          "question": "string (has_conflict=trueì¼ ë•Œë§Œ, ì§ˆë¬¸ 1ê°œ)"
        }}

        ì¶”ê°€ ê·œì¹™:
        - questionì€ ì§ˆë¬¸ 1ê°œë§Œ
        - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ/ì„ íƒ ê°•ìš” ê¸ˆì§€
        - current_main_index={current_main_index}
        """
    ).strip()


def try_logic_crosscheck_question(main_index: int) -> Tuple[Optional[str], List[str]]:
    dbg: List[str] = []
    used_set = set(int(x) for x in (st.session_state.crosscheck_used_for or []))

    if main_index in used_set:
        return None, dbg

    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    if len(mains) < 2:
        return None, dbg

    system = crosscheck_system_prompt()
    user = crosscheck_user_prompt(main_index)
    txt, err, d = call_openai_text(system=system, user=user, temperature=0.2)
    dbg.extend(d)
    if not txt:
        if err:
            dbg.append(f"Crosscheck error: {err}")
        return None, dbg

    data = safe_json_parse(txt)
    if not data:
        dbg.append("Crosscheck JSON parse failed.")
        return None, dbg

    has_conflict = bool(data.get("has_conflict", False))
    q = normalize(str(data.get("question", "") or ""))

    # listë¡œ ì €ì¥
    used_set.add(main_index)
    st.session_state.crosscheck_used_for = sorted(list(used_set))

    if has_conflict and q:
        dbg.append("Crosscheck conflict detected -> using conflict question.")
        return q, dbg

    dbg.append("Crosscheck: no conflict (or no question).")
    return None, dbg


def instruction_for_question(i: int, n: int, coach_id: str) -> str:
    if i == 0:
        return "ìƒí™©ì˜ í•µì‹¬ì„ ë” êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
    if i == 1:
        return "ì›í•˜ëŠ” ëª©í‘œë¥¼ ì¸¡ì • ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "action":
        if i == n - 1:
            return "â€˜ì§€ê¸ˆ ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ì„ ìŠ¤ìŠ¤ë¡œ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ(Quick Win, ì¶”ì²œ ê¸ˆì§€)"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ í¼ì¹˜ê³  Top1~3 ìš°ì„ ìˆœìœ„ë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸(íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ì„ ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œ)"
        if n >= 6 and i == 3:
            return "Top1ì„ â€˜1ë…„â†’ì´ë²ˆ ë‹¬â†’ì´ë²ˆ ì£¼â€™ë¡œ ìª¼ê°œ ì‚¬ìš©ìê°€ ê³„íšì„ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ(ì§€ì‹œ ê¸ˆì§€)"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return (
                "í”„ë¦¬ëª¨í…œ(Pre-mortem) + If-Then íŠ¸ë¦¬ê±° ì„¤ê³„ ì§ˆë¬¸ 1ê°œ. "
                "ì˜ˆ: â€˜2ì£¼ ë’¤ ì‹¤íŒ¨í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ 3ê°€ì§€ëŠ”?â€™ "
                "ê·¸ë¦¬ê³  ê° ì›ì¸ì— ëŒ€í•´ â€˜ë§Œì•½ (If) ~ ìƒí™©ì´ë©´ â†’ (Then) ~ í–‰ë™â€™ìœ¼ë¡œ ëŒ€ì‘ì„ ì ê²Œ í•˜ê¸°"
            )
        if n >= 6 and i == 4:
            return "ì‹¤í–‰ì„ â€˜ì–¸ì œâ€™ê°€ ì•„ë‹ˆë¼ â€˜If(ì–´ë–¤ ìƒí™©) â†’ Then(ì–´ë–¤ í–‰ë™)â€™ìœ¼ë¡œ ì„¤ê³„í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(íŠ¸ë¦¬ê±° 2~3ê°œ)"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ì¡°ê±´ì—ì„œ)í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "logic":
        if n >= 5 and i == n - 2:
            return "ì—­ë°œìƒ/ë°˜ëŒ€ ìƒí™© ê°€ì • ì§ˆë¬¸ 1ê°œ."
        if i == 2:
            return "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        if i == n - 2 and n < 5:
            return "ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì¶”ê°€ë¡œ í™•ì¸í•  ì •ë³´ 1~2ê°œë¥¼ ë“œëŸ¬ë‚´ëŠ” ì§ˆë¬¸ 1ê°œ"
        return "ì˜µì…˜/ì •ë³´/ì œì•½ì„ ë” ë¶„ë¦¬í•´ ëª…ë£Œí™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "value":
        if i == 2:
            return "ì§€ê¸ˆ ê°ì •(2~3ê°œ)ê³¼ ê·¸ ê°ì •ì˜ ì´ìœ ë¥¼ ë§í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == 3 and n >= 5:
            return "ê°ì •ê³¼ ê°€ì¹˜ì˜ ë¶„ë¦¬ ì§ˆë¬¸ 1ê°œ."
        if i == n - 2:
            return "í›„íšŒ ìµœì†Œí™” ê´€ì (1ë…„/5ë…„ í›„)ì„ ì ê²€í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ â€˜ë‚´ ê¸°ì¤€â€™ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        return "ê°€ì¹˜ Top3(ë‚´ê²Œ ì¤‘ìš”í•œ ê²ƒ)ì™€ ë‚´ë ¤ë†“ì„ ê²ƒ 1ê°œë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    return "ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œ"


def fallback_question(coach_id: str, i: int, n: int) -> str:
    if i == 0:
        return "ì§€ê¸ˆ ê³ ë¯¼ì—ì„œ â€˜ê°€ì¥ í•µì‹¬ì ì¸ ìŸì â€™ì€ ë¬´ì—‡ì¸ê°€ìš”? (í•œ ë¬¸ì¥)"
    if i == 1:
        return "ì´ë²ˆ ê²°ì •ìœ¼ë¡œ ì–»ê³  ì‹¶ì€ ëª©í‘œë¥¼ â€˜ì¸¡ì • ê°€ëŠ¥í•˜ê²Œâ€™ ë°”ê¾¸ë©´ ì–´ë–»ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‚˜ìš”? (ì–¸ì œê¹Œì§€/ì–´ëŠ ì •ë„)"

    if coach_id == "action":
        if i == n - 1:
            return "ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” â€˜ê°€ì¥ ì‘ì€ í–‰ë™â€™ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ ì ê³ , íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return "2ì£¼ ë’¤ ì‹¤íŒ¨í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ 3ê°€ì§€ëŠ” ë¬´ì—‡ì´ê³  ê°ê° â€˜ë§Œì•½ ~ì´ë©´ â†’ ~í•œë‹¤â€™ë¡œ ëŒ€ì‘ì„ ì ì–´ë³¼ ìˆ˜ ìˆë‚˜ìš”?"
        if n >= 6 and i == 3:
            return "Top1ì„ â€˜1ë…„ ëª©í‘œ â†’ ì´ë²ˆ ë‹¬ ëª©í‘œ â†’ ì´ë²ˆ ì£¼ ê³„íš(3ê°œ)â€™ë¡œ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if n >= 6 and i == 4:
            return "ì‹¤í–‰ì„ â€˜ë§Œì•½(If) ~ ìƒí™©ì´ë©´ â†’ ê·¸ëŸ¬ë©´(Then) ~ í–‰ë™â€™ìœ¼ë¡œ íŠ¸ë¦¬ê±° 2~3ê°œë¥¼ ë§Œë“¤ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”í•˜ë©´(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ì¡°ê±´ì—ì„œ) ì–´ë–»ê²Œ ì ì„ ìˆ˜ ìˆë‚˜ìš”?"

    if coach_id == "logic":
        if n >= 5 and i == n - 2:
            return "ë§Œì•½ ë‹¹ì‹ ì´ ì„¸ìš´ ê¸°ì¤€ì´ ì™„ì „íˆ í‹€ë ¸ë‹¤ë©´ ì–´ë–¤ ìƒí™©ì´ ë²Œì–´ì§ˆê¹Œìš”?"
        if i == 2:
            return "ì´ ì„ íƒì„ í‰ê°€í•  ê¸°ì¤€ 3~5ê°œë¥¼ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 1:
            return "ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 2 and n < 5:
            return "ì§€ê¸ˆ ê²°ì •ì„ ì–´ë µê²Œ ë§Œë“œëŠ” â€˜ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì •ë³´â€™ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        return "ì˜µì…˜/ì œì•½/ì •ë³´ë¥¼ ë¶„ë¦¬í•´ì„œ ì§€ê¸ˆ ë¶€ì¡±í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ì§€ ì ì–´ë³¼ê¹Œìš”?"

    if i == 2:
        return "ì§€ê¸ˆ ê°ì •ì„ 2~3ê°œ ë‹¨ì–´ë¡œ ì ê³ , ê° ê°ì •ì´ ìƒê¸´ ì´ìœ ë¥¼ í•œ ì¤„ì”© ì¨ë³¼ê¹Œìš”?"
    if i == 3 and n >= 5:
        return "ê·¸ ê°ì •ì€ â€˜ì§€ê¸ˆ ë‹¹ì¥ì˜ í¸ì•ˆí•¨â€™ ë•Œë¬¸ì¸ê°€ìš”, â€˜ë¯¸ë˜ì˜ ë‚˜ë¥¼ ìœ„í•œ ê°€ì¹˜â€™ ë•Œë¬¸ì¸ê°€ìš”?"
    if i == n - 2:
        return "1ë…„/5ë…„ ë’¤ì˜ ë‚´ê°€ ì§€ê¸ˆì˜ ë‚˜ì—ê²Œ ë­ë¼ê³  ë§í•´ì¤„ ê²ƒ ê°™ë‚˜ìš”?"
    return "ì´ ê³ ë¯¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°€ì¹˜ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"


def generate_question(i: int, n: int) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    prev_qs = st.session_state.questions[:]

    cross_q, cross_dbg = try_logic_crosscheck_question(i)
    if cross_q and not any(is_similar(cross_q, pq) for pq in prev_qs):
        return cross_q, None, cross_dbg

    dbg_acc: List[str] = cross_dbg[:]

    def prompt(nonce: int) -> str:
        prev_txt = "\n".join([f"- {q}" for q in prev_qs[-6:]]) if prev_qs else "(ì—†ìŒ)"
        return textwrap.dedent(
            f"""
            [ìµœê·¼ ì§ˆë¬¸ ëª©ë¡]
            {prev_txt}

            {build_context_block()}

            [ì´ë²ˆ ì§ˆë¬¸ ëª©ì ]
            {instruction_for_question(i, n, coach["id"])}

            ê·œì¹™:
            - ê²°ë¡ /ì¶”ì²œ/ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
            - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
            - ì´ì „ ì§ˆë¬¸ê³¼ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ í”¼í•˜ê¸°

            (nonce={nonce})
            """
        ).strip()

    q1, err, dbg = call_openai_text(system=system, user=prompt(random.randint(1000, 9999)), temperature=0.7)
    dbg_acc.extend(dbg)
    if not q1:
        return fallback_question(coach["id"], i, n), err, dbg_acc

    q1 = normalize(q1)
    if not any(is_similar(q1, pq) for pq in prev_qs):
        return q1, None, dbg_acc

    dbg_acc.append("Similar question detected. Regenerating once.")
    q2, err2, dbg2 = call_openai_text(system=system, user=prompt(random.randint(10000, 99999)), temperature=0.85)
    dbg_acc.extend(dbg2)
    if q2:
        q2 = normalize(q2)
        if not any(is_similar(q2, pq) for pq in prev_qs):
            return q2, None, dbg_acc

    dbg_acc.append("Still similar after retry. Using fallback.")
    return fallback_question(coach["id"], i, n), err2, dbg_acc


def ensure_question(index: int, total: int) -> None:
    while len(st.session_state.questions) <= index:
        i = len(st.session_state.questions)
        q, err, dbg = generate_question(i, total)
        st.session_state.debug_log = dbg
        st.session_state.questions.append(q)


def generate_probe_question(last_q: str, last_a: str) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    user = probing_instruction(last_q, last_a)
    q, err, dbg = call_openai_text(system=system, user=user, temperature=0.6)
    if not q:
        return "ë°©ê¸ˆ ë‹µë³€ì—ì„œ â€˜ì˜ˆì‹œ 1ê°œâ€™ë§Œ ë“¤ì–´ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì„¤ëª…í•´ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?", err, dbg
    return normalize(q), None, dbg


def generate_reframe_question(last_q: str, last_a: str) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    user = reframe_instruction(last_q, last_a)
    q, err, dbg = call_openai_text(system=system, user=user, temperature=0.55)
    if not q:
        return "ì´ ì§ˆë¬¸ì´ ì–´ë µë‹¤ë©´, â€˜ì´ë²ˆ ìƒí™©ì—ì„œ ê°€ì¥ ì‹ ê²½ ì“°ì´ëŠ” í•œ ê°€ì§€â€™ë§Œ ê³ ë¥´ë©´ ë¬´ì—‡ì¸ê°€ìš”?", err, dbg
    return normalize(q), None, dbg


# =========================
# Report generation + rendering
# =========================
# ê¸ˆì¹™ì–´(ì¶”ì²œ/ì§€ì‹œ) íƒì§€ ì •ë°€ë„ ê°œì„ : â€œì¶”ì²œâ€ ë‹¨ë… ì œê±°, ë¬¸ì¥ íŒ¨í„´ ì¤‘ì‹¬
FORBIDDEN_RECOMMEND_PATTERNS = [
    r"ì¶”ì²œí•©ë‹ˆë‹¤",
    r"ì¶”ì²œë“œ",
    r"~?í•˜ëŠ” ê²ƒì´ ì¢‹",
    r"~?í•˜ëŠ” ê²Œ ì¢‹",
    r"~?í•˜ì‹œë©´ ì¢‹",
    r"í•´ì•¼ í•©ë‹ˆë‹¤",
    r"í•˜ì‹œê¸¸",
    r"í•˜ëŠ” ê²Œ ë‚«",
    r"ì •ë‹µ(ì€|:)",
    r"ê²°ë¡ (ì€|:)",
    r"\bAë¥¼\s*ì„ íƒ",
    r"\bBë¥¼\s*ì„ íƒ",
]


def contains_forbidden_recommendation(text: str) -> bool:
    t = text or ""
    for pat in FORBIDDEN_RECOMMEND_PATTERNS:
        if re.search(pat, t):
            return True
    return False


def report_schema_hint(coach_id: str) -> str:
    base = """
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”(ì½”ë“œë¸”ë¡/ì„¤ëª… ê¸ˆì§€).
ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.
coaching_messageëŠ” ë°˜ë“œì‹œ "ê±°ìš¸ ë¹„ì¶”ê¸°(Mirroring)" í™”ë²•ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
ê¸ˆì§€ í‘œí˜„: "ì¶”ì²œí•©ë‹ˆë‹¤", "ì¢‹ê² ìŠµë‹ˆë‹¤", "í•´ì•¼ í•©ë‹ˆë‹¤", "í•˜ì", "ì •ë‹µ", "ê²°ë¡ ", "Aë¥¼ ì„ íƒ".
"""

    common_extra = """
ì¶”ê°€ í•„ë“œ(ì›ì¹™ ìœ ì§€):
- "info_check_questions": ["string", ...]  # â€˜ì¶”ê°€ë¡œ í™•ì¸í•˜ë©´â€™ ê²°ì •ì„ ê°€ë³ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1~3ê°œ(ì§ˆë¬¸ í˜•íƒœë§Œ)
"""

    if coach_id == "action":
        return textwrap.dedent(
            base
            + common_extra
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue": "string",
    "goal": "string",
    "constraints": ["string"],
    "options_mentioned": ["string"]
  },
  "criteria": [
    {"name":"string","priority":1-5,"why":"string"}
  ],
  "plan_visualization": {
    "year": "string",
    "month": "string",
    "week": ["string","string","string"]
  },
  "weekly_table": {
    "Mon": ["string"], "Tue": ["string"], "Wed": ["string"], "Thu": ["string"],
    "Fri": ["string"], "Sat": ["string"], "Sun": ["string"]
  },
  "info_check_questions": ["string"],
  "coaching_message": ["string","string"],
  "next_self_question": "string"
}
"""
        ).strip()

    if coach_id == "logic":
        return textwrap.dedent(
            base
            + common_extra
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "key_points": {"uncertainties":["string"], "tradeoffs":["string"]},
  "info_check_questions": ["string"],
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
        ).strip()

    return textwrap.dedent(
        base
        + common_extra
        + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "emotions_values": {"emotions":["string","string"], "top_values":["string","string","string"]},
  "info_check_questions": ["string"],
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
    ).strip()


def system_prompt_for_report() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ìµœì¢… ìš”ì•½ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì˜¤ì§ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬/ê¸°ì¤€/ê¸´ì¥/ë¶ˆí™•ì‹¤ì„±ì„ ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)í•˜ì„¸ìš”.\n"
        "coaching_messageëŠ” ë°˜ë“œì‹œ ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.\n"
    )


def build_qa_text_for_report() -> str:
    qa_text = ""
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        qa_text += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"
    return qa_text


def fallback_report_json() -> Dict[str, Any]:
    coach = coach_by_id(st.session_state.coach_id)
    opts = parse_options()
    base = {
        "summary": {
            "core_issue": normalize(st.session_state.situation)[:180] or "í•µì‹¬ ê³ ë¯¼ì´ ìš”ì•½ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "goal": normalize(st.session_state.goal)[:180] or "ëª©í‘œê°€ ëª…í™•íˆ ì íˆì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "constraints": [],
            "options_mentioned": opts or [],
        },
        "criteria": [],
        "info_check_questions": [
            "ì´ ê²°ì •ì„ ë” ê°€ë³ê²Œ ë§Œë“¤ê¸° ìœ„í•´, ì§€ê¸ˆ â€˜í™•ì¸ë˜ì§€ ì•Šì€ ì‚¬ì‹¤/ê°€ì •â€™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ìµœì•…ì˜ ê²½ìš°ë¥¼ ìƒìƒí–ˆì„ ë•Œ, ì‹¤ì œë¡œ ê°ë‹¹ ê°€ëŠ¥í•œ ë¹„ìš©/ì†ì‹¤ì˜ ë²”ìœ„ëŠ” ì–´ëŠ ì •ë„ì¸ê°€ìš”?",
        ],
        "coaching_message": [
            "ì§€ê¸ˆì€ â€˜ì •ë¦¬â€™ê°€ í•„ìš”í•˜ë‹¤ëŠ” ëŠë‚Œê³¼, ë™ì‹œì— â€˜í™•ì‹ ì´ ë¶€ì¡±í•˜ë‹¤â€™ëŠ” ëŠë‚Œì´ í•¨ê»˜ ìˆëŠ” ìƒíƒœì²˜ëŸ¼ ë³´ì…ë‹ˆë‹¤.",
            "ë‹¹ì‹ ì—ê²Œ ì¤‘ìš”í•œ ê¸°ì¤€ì´ ë¬´ì—‡ì¸ì§€ê°€ ì„ ëª…í•´ì§ˆìˆ˜ë¡, ì„ íƒì´ ëœ ë¬´ê²ê²Œ ëŠê»´ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”.",
        ],
        "next_self_question": "ë‚´ê°€ ì§€ê¸ˆ ê°€ì¥ ë†“ì¹˜ê¸° ì‹«ì€ ê¸°ì¤€ 1ê°œëŠ” ë¬´ì—‡ì´ê³ , ì™œ ê·¸ê²ƒì´ ì¤‘ìš”í•œê°€ìš”?",
    }
    if coach["id"] == "logic":
        base["key_points"] = {"uncertainties": [], "tradeoffs": []}
    elif coach["id"] == "action":
        base["plan_visualization"] = {"year": "", "month": "", "week": []}
        base["weekly_table"] = {"Mon": [], "Tue": [], "Wed": [], "Thu": [], "Fri": [], "Sat": [], "Sun": []}
    else:
        base["emotions_values"] = {"emotions": [], "top_values": []}
    return base


def generate_final_report_json() -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_report()

    qa_text = build_qa_text_for_report()
    opts = parse_options()

    user = textwrap.dedent(
        f"""
{report_schema_hint(coach["id"])}

[ì„¸ì…˜ ì‹œì‘ ì •ë³´]
- ì¹´í…Œê³ ë¦¬: {st.session_state.category}
- ê²°ì • ìœ í˜•: {st.session_state.decision_type}
- ìƒí™© ì„¤ëª…: {st.session_state.situation}
- ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal}
- ì˜µì…˜(ìˆë‹¤ë©´): {opts if opts else "(ì—†ìŒ)"}

[Q/A]
{qa_text}

ì¤‘ìš”:
- ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
- coaching_messageëŠ” ê±°ìš¸ ë¹„ì¶”ê¸°ë§Œ
- ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ê³„íšì„ â€˜ì§€ì–´ë‚´ì§€â€™ ë§ˆì„¸ìš”
- info_check_questionsëŠ” ì§ˆë¬¸ í˜•íƒœë¡œ 1~3ê°œë§Œ
"""
    ).strip()

    text, err, dbg = call_openai_text(system=system, user=user, temperature=0.25)
    if not text:
        fb = fallback_report_json()
        dbg.append("Report fallback used (no model output).")
        return fb, err, dbg, None

    data = safe_json_parse(text)
    if data is None:
        fb = fallback_report_json()
        dbg.append("Report fallback used (JSON parse fail).")
        return fb, "ë¦¬í¬íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨(ëŒ€ì²´ ì •ë¦¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤)", dbg, text

    combined = json.dumps(data, ensure_ascii=False)
    if contains_forbidden_recommendation(combined):
        dbg.append("Forbidden recommendation-like phrasing detected. Regenerating once with stricter warning.")
        stricter_user = user + "\n\n[ê²½ê³ ] ì´ì „ ì¶œë ¥ì— ì¶”ì²œ/ì§€ì‹œ í‘œí˜„ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ê³  ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
        text2, err2, dbg2 = call_openai_text(system=system, user=stricter_user, temperature=0.1)
        dbg.extend(dbg2)
        if text2:
            data2 = safe_json_parse(text2)
            if data2 is not None and not contains_forbidden_recommendation(json.dumps(data2, ensure_ascii=False)):
                return data2, None, dbg, text2
        dbg.append("Regeneration did not fully remove forbidden phrasing.")
        return data, None, dbg, text

    return data, None, dbg, text


def render_summary_block(data: Dict[str, Any]) -> None:
    s = data.get("summary", {}) or {}
    st.subheader("ê³ ë¯¼ì˜ í•µì‹¬ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.write(f"**í•µì‹¬ ê³ ë¯¼:** {s.get('core_issue','')}")
        st.write(f"**ëª©í‘œ:** {s.get('goal','')}")
    with c2:
        cons = s.get("constraints", []) or []
        opts = s.get("options_mentioned", []) or []
        st.write("**ì œì•½/ì¡°ê±´:**")
        if cons:
            for x in cons:
                st.write(f"- {x}")
        else:
            st.caption("ì œì•½ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        st.write("**ì–¸ê¸‰ëœ ì˜µì…˜:**")
        if opts:
            for x in opts:
                st.write(f"- {x}")
        else:
            st.caption("ì˜µì…˜ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")


def render_criteria(data: Dict[str, Any]) -> List[str]:
    st.subheader("ì„ íƒ ê¸°ì¤€ ì •ë¦¬(ìš°ì„ ìˆœìœ„ í¬í•¨)")
    crit = data.get("criteria", []) or []
    if not crit:
        st.caption("ì„ íƒ ê¸°ì¤€ì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
        return []
    rows = []
    names: List[str] = []
    for c in crit:
        nm = str(c.get("name", "") or "").strip()
        if nm:
            names.append(nm)
        rows.append({"ê¸°ì¤€": nm, "ìš°ì„ ìˆœìœ„(1~5)": c.get("priority", ""), "ì™œ ì¤‘ìš”í•œê°€": c.get("why", "")})
    st.dataframe(rows, use_container_width=True, hide_index=True)
    return names


def render_action_visualization(data: Dict[str, Any]) -> None:
    st.subheader("ê³„íš ì •ë¦¬(ë…„ â†’ ë‹¬ â†’ ì£¼) â€” ì‚¬ìš©ì ë‹µë³€ ê¸°ë°˜")
    pv = data.get("plan_visualization", {}) or {}
    c1, c2, c3 = st.columns(3)
    c1.metric("ë…„", pv.get("year", "") or "-")
    c2.metric("ë‹¬", pv.get("month", "") or "-")
    c3.metric("ì£¼(í•µì‹¬ 3ê°œ)", " ")

    week = pv.get("week", []) or []
    if week:
        for x in week:
            st.write(f"- {x}")
    else:
        st.caption("ì‚¬ìš©ì ë‹µë³€ì—ì„œ ì£¼ ë‹¨ìœ„ ê³„íšì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")

    st.subheader("ì£¼ê°„ í…Œì´ë¸”(ì •ë¦¬ìš©)")
    cal = data.get("weekly_table", {}) or {}
    days = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
    table = [{"Day": d, "Tasks": "\n".join(cal.get(d, []) or [])} for d in days]
    st.dataframe(table, use_container_width=True, hide_index=True)


def render_key_points_logic(data: Dict[str, Any]) -> None:
    kp = data.get("key_points", {}) or {}
    st.subheader("ì •ë¦¬ í¬ì¸íŠ¸")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„(ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ê²ƒ)**")
        for x in kp.get("uncertainties", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**íŠ¸ë ˆì´ë“œì˜¤í”„(ì–»ëŠ” ê²ƒ vs ìƒëŠ” ê²ƒ)**")
        for x in kp.get("tradeoffs", []) or []:
            st.write(f"- {x}")


def render_emotions_values(data: Dict[str, Any]) -> None:
    ev = data.get("emotions_values", {}) or {}
    st.subheader("ê°ì •/ê°€ì¹˜ ì •ë¦¬")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ê°ì •**")
        for x in ev.get("emotions", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**ê°€ì¹˜ Top3**")
        for x in ev.get("top_values", []) or []:
            st.write(f"- {x}")


def render_info_check_questions(data: Dict[str, Any]) -> None:
    st.subheader("ì •ë³´ ë¶€ì¡± ì²´í¬ë¦¬ìŠ¤íŠ¸(ì§ˆë¬¸ í˜•íƒœ)")
    qs = data.get("info_check_questions", []) or []
    qs = [str(x).strip() for x in qs if str(x).strip()]
    if not qs:
        st.caption("ì¶”ê°€ë¡œ í™•ì¸í•  ì§ˆë¬¸ì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
        return
    for q in qs[:3]:
        # ì§ˆë¬¸ í˜•íƒœ ìœ ì§€(ì¶”ì²œ/ì§€ì‹œ ê¸ˆì§€)
        st.write(f"- {q}")


# ---- â€œëª¨ìˆœ/ê¸´ì¥ ì§€ë„â€ ì‹œê°í™”(ì›ì¹™ ìœ ì§€) ----
TENSION_AXES = [
    ("ì•ˆì •", "ì„±ì¥"),
    ("ììœ ", "ì•ˆì •"),
    ("ëˆ", "ì‹œê°„"),
    ("ì†ë„", "ì™„ì„±ë„"),
    ("ì„±ê³¼", "ê±´ê°•"),
    ("ê´€ê³„", "ê²½ê³„"),
    ("ë„ì „", "ì•ˆì •"),
    ("ë‹¨ê¸°", "ì¥ê¸°"),
]


def _collect_tension_signals(data: Dict[str, Any]) -> Dict[str, str]:
    """
    ë¦¬í¬íŠ¸ ê¸°ë°˜ìœ¼ë¡œ â€˜ì‹ í˜¸ í…ìŠ¤íŠ¸â€™ë¥¼ ëª¨ì•„ ê°„ë‹¨ ë§¤ì¹­ìš© í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    s = data.get("summary", {}) or {}
    crit = data.get("criteria", []) or []
    crit_text = " ".join([str(c.get("name", "")) + " " + str(c.get("why", "")) for c in crit if isinstance(c, dict)])
    core = str(s.get("core_issue", "") or "")
    goal = str(s.get("goal", "") or "")

    extras = ""
    if "key_points" in data:
        kp = data.get("key_points", {}) or {}
        extras += " " + " ".join(kp.get("uncertainties", []) or [])
        extras += " " + " ".join(kp.get("tradeoffs", []) or [])
    if "emotions_values" in data:
        ev = data.get("emotions_values", {}) or {}
        extras += " " + " ".join(ev.get("emotions", []) or [])
        extras += " " + " ".join(ev.get("top_values", []) or [])

    blob = normalize(" ".join([core, goal, crit_text, extras]))
    return {"blob": blob, "core": core, "goal": goal, "crit": crit_text, "extras": extras}


def render_tension_map(data: Dict[str, Any]) -> None:
    st.subheader("ëª¨ìˆœ/ê¸´ì¥ ì§€ë„(ê´€ì°°ìš©)")
    st.caption("ê²°ë¡ ì„ ë‚´ê¸° ìœ„í•œ ê²Œ ì•„ë‹ˆë¼, â€˜ë‚´ ì•ˆì˜ ê¸°ì¤€ë“¤ì´ ì–´ë””ì—ì„œ ì„œë¡œ ë‹¹ê¸°ëŠ”ì§€â€™ë¥¼ í•œ ë²ˆ ë” ë³´ë ¤ëŠ” ì§€ë„ì˜ˆìš”.")

    sig = _collect_tension_signals(data)
    blob = sig["blob"]

    # 1) ì¶• ê°ì§€
    found_axes = []
    for a, b in TENSION_AXES:
        if (a in blob) and (b in blob):
            found_axes.append((a, b))

    # 2) ê¸°ì¤€ Top3 + ë¶ˆí™•ì‹¤/íŠ¸ë ˆì´ë“œì˜¤í”„ + ê°ì •ì–´(ë¯¸ëŸ¬ë§ì—ì„œ ê°€ì ¸ì˜¤ëŠ” ê±´ ë³„ë„ì´ë¯€ë¡œ ì—¬ê¸°ì„  ë¦¬í¬íŠ¸ë§Œ)
    crit = data.get("criteria", []) or []
    crit_sorted = []
    for c in crit:
        try:
            p = int(c.get("priority", 999))
        except Exception:
            p = 999
        crit_sorted.append((p, str(c.get("name", "") or "").strip()))
    crit_sorted = [x for x in sorted(crit_sorted, key=lambda x: x[0]) if x[1]]
    top3 = [x[1] for x in crit_sorted[:3]]

    uncertainties = []
    tradeoffs = []
    if "key_points" in data:
        kp = data.get("key_points", {}) or {}
        uncertainties = [str(x).strip() for x in (kp.get("uncertainties", []) or []) if str(x).strip()]
        tradeoffs = [str(x).strip() for x in (kp.get("tradeoffs", []) or []) if str(x).strip()]

    emotions = []
    if "emotions_values" in data:
        ev = data.get("emotions_values", {}) or {}
        emotions = [str(x).strip() for x in (ev.get("emotions", []) or []) if str(x).strip()]

    c1, c2, c3 = st.columns(3)
    with c1:
        st.write("**ê¸°ì¤€ Top3(ìš°ì„ ìˆœìœ„ ê¸°ì¤€)**")
        if top3:
            for x in top3:
                st.write(f"- {x}")
        else:
            st.caption("ê¸°ì¤€ Top3ê°€ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
    with c2:
        st.write("**ë¶ˆí™•ì‹¤/ë¦¬ìŠ¤í¬ ì‹ í˜¸**")
        if uncertainties:
            for x in uncertainties[:4]:
                st.write(f"- {x}")
        else:
            st.caption("ë¶ˆí™•ì‹¤ ì‹ í˜¸ê°€ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
    with c3:
        st.write("**ê°ì • ì‹ í˜¸(ë¦¬í¬íŠ¸ ê¸°ë°˜)**")
        if emotions:
            for x in emotions[:4]:
                st.write(f"- {x}")
        else:
            st.caption("ê°ì • ì‹ í˜¸ê°€ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")

    st.write("**ê¸´ì¥ ì¶•(í…ìŠ¤íŠ¸ ë§¤ì¹­ ê¸°ë°˜)**")
    if found_axes:
        for a, b in found_axes:
            st.write(f"- {a} â†” {b}")
    else:
        st.caption("ëª…í™•í•œ â€˜ê¸´ì¥ ì¶•â€™ì´ ìë™ìœ¼ë¡œ ì¡íˆì§€ ì•Šì•˜ì–´ìš”. (ê¸°ì¤€/ë¶ˆí™•ì‹¤/ê°ì •ì—ì„œ í‚¤ì›Œë“œê°€ ë‹¤ë¥´ê²Œ í‘œí˜„ëì„ ìˆ˜ ìˆì–´ìš”.)")

    if tradeoffs:
        st.write("**ì‚¬ìš©ìê°€ ë§í•œ íŠ¸ë ˆì´ë“œì˜¤í”„(ë¦¬í¬íŠ¸ ê¸°ë°˜)**")
        for x in tradeoffs[:5]:
            st.write(f"- {x}")


def render_coaching_message(data: Dict[str, Any]) -> None:
    st.subheader("ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    msgs = data.get("coaching_message", []) or []
    for m in msgs:
        st.write(f"- {m}")


def render_next_question(data: Dict[str, Any]) -> None:
    st.subheader("ë‹¤ìŒì— ìŠ¤ìŠ¤ë¡œì—ê²Œ ë˜ì§ˆ ì§ˆë¬¸(1ê°œ)")
    st.write(f"**{data.get('next_self_question','')}**")


STOPWORDS = {
    "ê·¸ëƒ¥",
    "ë„ˆë¬´",
    "ì§„ì§œ",
    "ê·¼ë°",
    "ê·¸ë¦¬ê³ ",
    "ê·¸ë˜ì„œ",
    "í•˜ì§€ë§Œ",
    "ì œê°€",
    "ì €ëŠ”",
    "ë‚˜ëŠ”",
    "ë‚´ê°€",
    "ì´ê²Œ",
    "ê·¸ê²Œ",
    "ì €",
    "ê²ƒ",
    "ìˆ˜",
    "ì¢€",
    "ì•½ê°„",
    "ë•Œë¬¸",
    "ë•Œë¬¸ì—",
    "ê°™ì•„ìš”",
    "ê°™ì€",
    "í•˜ëŠ”",
    "í•´ì•¼",
    "í•˜ê³ ",
    "ìˆëŠ”",
    "ìˆë‹¤",
    "ì—†ë‹¤",
    "ì—†ì–´ìš”",
    "ëª¨ë¥´ê² ",
    "ëª¨ë¥´ê² ì–´ìš”",
}

EMOTION_WORDS = [
    "ë¶ˆì•ˆ",
    "ë‘ë ¤ì›€",
    "ê±±ì •",
    "ê¸´ì¥",
    "ë‹µë‹µ",
    "í›„íšŒ",
    "ì£„ì±…ê°",
    "ë¶€ë‹´",
    "ìŠ¤íŠ¸ë ˆìŠ¤",
    "ìš°ìš¸",
    "ì§œì¦",
    "í™”",
    "ë¶„ë…¸",
    "ì„¤ë ˜",
    "ê¸°ëŒ€",
    "ì•ˆë„",
    "í¸ì•ˆ",
    "í–‰ë³µ",
    "ì˜ìš•",
    "ì§€ì¹¨",
    "ë²ˆì•„ì›ƒ",
]


def analyze_mirroring_from_answers() -> Tuple[pd.DataFrame, pd.DataFrame]:
    text = " ".join([str(x.get("a", "")) for x in st.session_state.answers if x.get("a")])
    clean = re.sub(r"[^\wê°€-í£ ]", " ", text)
    clean = re.sub(r"\s+", " ", clean).strip().lower()

    toks = [t for t in clean.split(" ") if len(t) >= 2 and t not in STOPWORDS]
    freq: Dict[str, int] = {}
    for t in toks:
        freq[t] = freq.get(t, 0) + 1
    kw = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:10]
    kw_df = pd.DataFrame(kw, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„"])

    emo_freq: Dict[str, int] = {}
    for ew in EMOTION_WORDS:
        c = len(re.findall(re.escape(ew), text))
        if c > 0:
            emo_freq[ew] = c
    emo = sorted(emo_freq.items(), key=lambda x: x[1], reverse=True)[:10]
    emo_df = pd.DataFrame(emo, columns=["ê°ì •ì–´", "ë¹ˆë„"])
    return kw_df, emo_df


def render_mirroring_visual() -> None:
    st.subheader("ë‚´ë©´ì˜ ëª©ì†Œë¦¬(Mirroring) â€” ë‹µë³€ì—ì„œ ë§ì´ ë“±ì¥í•œ í‘œí˜„")
    kw_df, emo_df = analyze_mirroring_from_answers()

    c1, c2 = st.columns(2)
    with c1:
        st.write("**ìì£¼ ë“±ì¥í•œ í‚¤ì›Œë“œ(Top 10)**")
        if len(kw_df) == 0:
            st.caption("í‚¤ì›Œë“œê°€ ì¶©ë¶„íˆ ì¡íˆì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(kw_df, use_container_width=True, hide_index=True)
            st.bar_chart(kw_df.set_index("í‚¤ì›Œë“œ")["ë¹ˆë„"])
    with c2:
        st.write("**ê°ì •ì–´(Top 10)**")
        if len(emo_df) == 0:
            st.caption("ëšœë ·í•œ ê°ì •ì–´ê°€ ë§ì´ ë“±ì¥í•˜ì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(emo_df, use_container_width=True, hide_index=True)
            st.bar_chart(emo_df.set_index("ê°ì •ì–´")["ë¹ˆë„"])

    st.caption("ì´ ê²°ê³¼ëŠ” â€˜ì •ë‹µâ€™ì´ ì•„ë‹ˆë¼, ë‹¹ì‹ ì˜ ë‹µë³€ì— ë‚˜íƒ€ë‚œ ë°˜ë³µ í‘œí˜„ì„ ìš”ì•½í•œ ê±°ìš¸ì…ë‹ˆë‹¤.")


def build_decision_matrix(options: List[str], criteria_names: List[str]) -> pd.DataFrame:
    if not options:
        options = ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]
    if not criteria_names:
        criteria_names = ["ê¸°ì¤€ 1", "ê¸°ì¤€ 2", "ê¸°ì¤€ 3"]

    cols = ["ì˜µì…˜"] + criteria_names + ["ë©”ëª¨"]
    rows = []
    for opt in options:
        r = {"ì˜µì…˜": opt, "ë©”ëª¨": ""}
        for c in criteria_names:
            r[c] = 3
        rows.append(r)
    return pd.DataFrame(rows, columns=cols)


def render_decision_matrix(criteria_names: List[str], data: Dict[str, Any]) -> None:
    st.subheader("ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(ì§ì ‘ ì ìˆ˜ ë§¤ê¸°ê¸°)")
    st.caption("ê° ì˜µì…˜ì´ â€˜ë‚´ ê¸°ì¤€â€™ì—ì„œ ì–´ëŠ ì •ë„ì¸ì§€ 1~5ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”. ì ìˆ˜ëŠ” ê²°ë¡ ì´ ì•„ë‹ˆë¼ ìƒê°ì„ êº¼ë‚´ëŠ” ë„êµ¬ì˜ˆìš”.")

    user_opts = parse_options()
    report_opts = (data.get("summary", {}) or {}).get("options_mentioned", []) or []
    opts = user_opts or [str(x) for x in report_opts if str(x).strip()] or ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]

    if st.session_state.decision_matrix_df is None:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)

    df: pd.DataFrame = st.session_state.decision_matrix_df

    existing_opts = [str(x) for x in df["ì˜µì…˜"].tolist()] if "ì˜µì…˜" in df.columns else []
    if set(existing_opts) != set(opts):
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    desired_cols = ["ì˜µì…˜"] + (criteria_names or []) + ["ë©”ëª¨"]
    if list(df.columns) != desired_cols:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    col_cfg: Dict[str, Any] = {}
    for c in criteria_names:
        col_cfg[c] = st.column_config.NumberColumn(c, min_value=1, max_value=5, step=1, format="%d")

    edited = st.data_editor(
        df,
        use_container_width=True,
        hide_index=True,
        column_config=col_cfg,
        num_rows="fixed",
    )
    st.session_state.decision_matrix_df = edited

    if criteria_names:
        try:
            totals = edited[criteria_names].sum(axis=1)
            show = edited.copy()
            show["ì´ì (ì°¸ê³ )"] = totals
            st.write("**ì´ì (ì°¸ê³ ìš©)**")
            st.dataframe(show[["ì˜µì…˜", "ì´ì (ì°¸ê³ )"]], use_container_width=True, hide_index=True)
            st.caption("ì´ì ì€ â€˜ê²°ë¡ â€™ì´ ì•„ë‹ˆë¼, ì–´ë–¤ ì˜µì…˜ì´ ì–´ë–¤ ê¸°ì¤€ì—ì„œ ê°•/ì•½í•œì§€ ë‹¤ì‹œ ë³´ê²Œ í•˜ëŠ” ì°¸ê³ ì¹˜ì˜ˆìš”.")
        except Exception:
            pass


def render_copy_to_clipboard_button(text: str, button_label: str = "í´ë¦½ë³´ë“œì— ë³µì‚¬") -> None:
    safe = text.replace("\\", "\\\\").replace("`", "\\`").replace("${", "\\${")
    html = f"""
    <div style="display:flex; gap:8px; align-items:center;">
      <button
        onclick="navigator.clipboard.writeText(`{safe}`).then(()=>{{const el=document.getElementById('cpmsg'); el.innerText='ë³µì‚¬ë¨'; setTimeout(()=>el.innerText='',1200);}});"
        style="padding:8px 12px; border-radius:10px; border:1px solid #444; background:#111; color:#fff; cursor:pointer;">
        {button_label}
      </button>
      <span id="cpmsg" style="font-size:12px; opacity:0.8;"></span>
    </div>
    """
    st.components.v1.html(html, height=55)


def build_report_text_for_export(data: Dict[str, Any]) -> str:
    lines: List[str] = []
    lines.append("ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ â€” ìµœì¢… ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    lines.append(f"- ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("[ì„¸ì…˜ ì •ë³´]")
    lines.append(f"- ì¹´í…Œê³ ë¦¬: {st.session_state.category}")
    lines.append(f"- ê²°ì • ìœ í˜•: {st.session_state.decision_type}")
    lines.append(f"- ìƒí™© ì„¤ëª…: {st.session_state.situation}")
    lines.append(f"- ëª©í‘œ: {st.session_state.goal}")
    lines.append(f"- ì˜µì…˜: {st.session_state.options or '(ì—†ìŒ)'}")
    if st.session_state.emotion_pre is not None or st.session_state.emotion_post is not None:
        lines.append(f"- ê°ì • ê°•ë„(ì‹œì‘/ë): {st.session_state.emotion_pre} â†’ {st.session_state.emotion_post}")
    lines.append("")
    lines.append("[ë¦¬í¬íŠ¸ JSON]")
    lines.append(json.dumps(data, ensure_ascii=False, indent=2))
    lines.append("")
    lines.append("[Q/A]")
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        lines.append(f"{i}. ({tag}) Q: {qa['q']}")
        lines.append(f"   A: {qa['a']}")
        lines.append(f"   ts: {qa['ts']}")
        lines.append("")
    return "\n".join(lines).strip()


# =========================
# Back ë²„íŠ¼ ë¡œì§
# =========================
def handle_back() -> None:
    if not st.session_state.answers:
        st.session_state.q_index = max(0, int(st.session_state.q_index) - 1)
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        st.session_state.probe_mode = ""
        return

    last = st.session_state.answers.pop()

    if last.get("kind") == "probe":
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        st.session_state.probe_mode = ""
        st.session_state.q_index = int(last.get("main_index", st.session_state.q_index))
        return

    mi = int(last.get("main_index", 0))
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.probe_mode = ""
    st.session_state.q_index = max(0, mi)


# =========================
# Sidebar (ë³´ì¡° ê¸°ëŠ¥ + í”„ë¼ì´ë²„ì‹œ + í”„ë¦¬ì…‹)
# =========================
init_state()

with st.sidebar:
    st.header("ë³´ì¡° ë©”ë‰´")
    st.text_input("OpenAI API Key (Secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()

    st.subheader("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ")
    st.toggle("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ", key="privacy_mode")
    if st.session_state.privacy_mode:
        st.toggle("ë‹µë³€ ê¸°ë¡ ìˆ¨ê¸°ê¸°", key="hide_history")
        st.toggle("ë‚´ë³´ë‚´ê¸° ë§ˆìŠ¤í‚¹(ê¶Œì¥)", key="mask_export")
        st.caption("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œëŠ” â€˜í‘œì‹œ/ê³µìœ  ìœ„í—˜â€™ì„ ë‚®ì¶”ëŠ” ì˜µì…˜ì…ë‹ˆë‹¤(ì™„ì „ ìµëª…í™”ëŠ” ì•„ë‹˜).")
    else:
        st.session_state.hide_history = False

    st.divider()
    st.subheader("ì„¸ì…˜ í…œí”Œë¦¿(í”„ë¦¬ì…‹)")
    st.caption("ì¹´í…Œê³ ë¦¬/ê²°ì •ìœ í˜•/ì½”ì¹˜/ì§ˆë¬¸ê°œìˆ˜ë¥¼ ì €ì¥í•´ ë‹¤ìŒì— ë¹ ë¥´ê²Œ ì‹œì‘í•  ìˆ˜ ìˆì–´ìš”.")

    with st.expander("í”„ë¦¬ì…‹ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°"):
        tpl_name = st.text_input("í”„ë¦¬ì…‹ ì´ë¦„", placeholder="ì˜ˆ: ì»¤ë¦¬ì–´ ê²°ì •(êµ¬ì¡° ì½”ì¹˜)")
        colx, coly = st.columns(2)
        with colx:
            if st.button("í˜„ì¬ ì„¤ì • ì €ì¥", use_container_width=True):
                if tpl_name.strip():
                    st.session_state.saved_templates.append(
                        {
                            "name": tpl_name.strip(),
                            "category": st.session_state.category,
                            "decision_type": st.session_state.decision_type,
                            "coach_id": st.session_state.coach_id,
                            "num_questions": int(st.session_state.num_questions),
                            "saved_at": datetime.now().isoformat(timespec="seconds"),
                        }
                    )
                    st.success("ì €ì¥í–ˆì–´ìš”.")
                else:
                    st.warning("í”„ë¦¬ì…‹ ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        with coly:
            if st.button("í”„ë¦¬ì…‹ ì „ì²´ ë‚´ë³´ë‚´ê¸°(JSON)", use_container_width=True):
                pass  # ì•„ë˜ download_buttonë¡œ ëŒ€ì²´

        if st.session_state.saved_templates:
            names = [t["name"] for t in st.session_state.saved_templates]
            picked = st.selectbox("ë¶ˆëŸ¬ì˜¬ í”„ë¦¬ì…‹", names, index=0)
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ë¶ˆëŸ¬ì˜¤ê¸°(í˜„ì¬ ì„¤ì •ì— ì ìš©)", use_container_width=True):
                    t = next((x for x in st.session_state.saved_templates if x["name"] == picked), None)
                    if t:
                        st.session_state.category = t["category"]
                        st.session_state.decision_type = t["decision_type"]
                        st.session_state.coach_id = t["coach_id"]
                        st.session_state.num_questions = int(t["num_questions"])
                        st.success("ì ìš©í–ˆì–´ìš”.")
            with col2:
                if st.button("ì‚­ì œ", use_container_width=True):
                    st.session_state.saved_templates = [x for x in st.session_state.saved_templates if x["name"] != picked]
                    st.success("ì‚­ì œí–ˆì–´ìš”.")
                    st.rerun()

            st.download_button(
                "í”„ë¦¬ì…‹ JSON ë‹¤ìš´ë¡œë“œ",
                data=json.dumps(st.session_state.saved_templates, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name="pebble_templates.json",
                mime="application/json",
                use_container_width=True,
            )

            up = st.file_uploader("í”„ë¦¬ì…‹ JSON ë¶ˆëŸ¬ì˜¤ê¸°", type=["json"])
            if up is not None:
                try:
                    loaded = json.loads(up.read().decode("utf-8"))
                    if isinstance(loaded, list):
                        # ë‹¨ìˆœ ë³‘í•©(ë™ëª… ì¤‘ë³µì€ ë’¤ì— ì¶”ê°€)
                        for item in loaded:
                            if isinstance(item, dict) and "name" in item:
                                st.session_state.saved_templates.append(item)
                        st.success("ë¶ˆëŸ¬ì™”ì–´ìš”.")
                        st.rerun()
                    else:
                        st.warning("í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤(ë¦¬ìŠ¤íŠ¸ JSONì´ì–´ì•¼ í•´ìš”).")
                except Exception:
                    st.warning("JSONì„ ì½ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”.")
        else:
            st.caption("ì €ì¥ëœ í”„ë¦¬ì…‹ì´ ì•„ì§ ì—†ì–´ìš”.")

    st.divider()
    if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸°", use_container_width=True):
        reset_flow("landing", keep_problem=False)
        st.rerun()

    if st.session_state.page in ("setup_details", "questions", "report"):
        if st.button("ê³ ë¯¼ë§Œ ìœ ì§€í•˜ê³  ë‹¤ì‹œ ì„¤ì •", use_container_width=True):
            reset_flow("landing", keep_problem=True)
            st.rerun()

    st.divider()
    with st.expander("ë””ë²„ê·¸ ë¡œê·¸"):
        st.write(st.session_state.debug_log)

    st.caption("ì‚¬ì´ë“œë°”ëŠ” ë³´ì¡° ê¸°ëŠ¥ë§Œ ì œê³µí•©ë‹ˆë‹¤.")


# =========================
# Progress Bar indexing
# =========================
nq = int(st.session_state.num_questions)
labels = ["ê³ ë¯¼", "ì„¤ì •"] + [f"Q{i}" for i in range(1, nq + 1)] + ["ìš”ì•½"]

if st.session_state.page == "landing":
    idx = 0
elif st.session_state.page == "setup_details":
    idx = 1
elif st.session_state.page == "questions":
    idx = 2 + int(st.session_state.q_index)
else:
    idx = 2 + nq

render_pebble_bridge(idx, len(labels), labels)
progress = idx / max(1, (len(labels) - 1))
with st.columns([1, 2, 1])[1]:
    render_hero_pebble(progress, f"ì§„í–‰ë„: {int(progress * 100)}%")

st.divider()


# =========================
# Pages
# =========================
def render_landing() -> None:
    st.title("ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­")
    st.caption("ì •ë‹µì„ ì£¼ê¸°ë³´ë‹¤, ì§ˆë¬¸ìœ¼ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.")

    cols = st.columns([1, 3, 1])
    with cols[1]:
        st.subheader("1ë‹¨ê³„ Â· ê³ ë¯¼ ì‘ì„±")
        st.caption("ì§€ê¸ˆ ê³ ë¯¼ ì¤‘ì¸ ìƒí™©ì„ ììœ ë¡­ê²Œ ì ì–´ì£¼ì„¸ìš”.")

        with st.container(border=True):
            if st.session_state.privacy_mode:
                st.caption("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ: ì…ë ¥ì€ ë™ì¼í•˜ì§€ë§Œ í™”ë©´ ê³µìœ  ì‹œ ì£¼ì˜ê°€ ëœ ë˜ë„ë¡ ì¼ë¶€ í‘œì‹œë¥¼ ì¤„ì…ë‹ˆë‹¤.")
            st.text_area(
                "ê³ ë¯¼ ë‚´ìš©",
                key="user_problem",
                height=220,
                placeholder="ì˜ˆ: ì´ì§ ì œì•ˆì„ ë°›ì•˜ëŠ”ë° ì•ˆì •ì„±ê³¼ ì„±ì¥ ì‚¬ì´ì—ì„œ ê³ ë¯¼ë¼ìš”. ì§€ê¸ˆ íŒ€ë„ ì¢‹ì§€ë§Œâ€¦",
                label_visibility="collapsed",
            )

        c1, c2 = st.columns([2, 1])
        with c1:
            st.session_state.num_questions = st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions))
        with c2:
            if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ", type="primary", use_container_width=True):
                txt = (st.session_state.user_problem or "").strip()
                if not txt:
                    st.warning("ê³ ë¯¼ ë‚´ìš©ì„ ë¨¼ì € í•œ ì¤„ì´ë¼ë„ ì ì–´ì£¼ì„¸ìš”.")
                else:
                    if not (st.session_state.situation or "").strip():
                        st.session_state.situation = txt
                    st.session_state.page = "setup_details"
                    st.rerun()


def render_setup_details() -> None:
    st.title("2ë‹¨ê³„ Â· AI ë¶„ì„ ë° ì¶”ì²œ")
    st.caption("ì•„ë˜ ê°’ë“¤ì€ â€˜ì¶”ì²œ/ì´ˆì•ˆâ€™ì…ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ì§ì ‘ ë°”ê¿”ë„ ê´œì°®ì•„ìš”.")

    problem_text = (st.session_state.user_problem or "").strip()

    # ìë™ 1íšŒ ìƒì„±: onboarding_recoê°€ Noneì´ë©´ ìƒì„±
    auto_generate = st.session_state.onboarding_reco is None and bool(problem_text)
    if auto_generate:
        with st.spinner("AIê°€ ê³ ë¯¼ì„ ì½ê³  ì¶”ì²œì„ ë§Œë“œëŠ” ì¤‘..."):
            reco, err, dbg, raw = generate_onboarding_recommendation(problem_text)
            st.session_state.debug_log = dbg
            st.session_state.onboarding_reco = reco
            st.session_state.onboarding_raw = raw
            if err:
                st.warning(err)

    top = st.columns([2, 1])
    with top[0]:
        st.subheader("ë‚´ê°€ ì ì€ ê³ ë¯¼")
    with top[1]:
        if st.button("ì¶”ì²œ ë‹¤ì‹œ ìƒì„±", use_container_width=True):
            with st.spinner("ì¶”ì²œì„ ë‹¤ì‹œ ìƒì„±í•˜ëŠ” ì¤‘..."):
                reco, err, dbg, raw = generate_onboarding_recommendation(problem_text)
                st.session_state.debug_log = dbg
                st.session_state.onboarding_reco = reco
                st.session_state.onboarding_raw = raw
                st.session_state.onboarding_applied = False  # ë‹¤ì‹œ ì ìš© ê°€ëŠ¥í•˜ê²Œ
                if err:
                    st.warning(err)
            st.rerun()

    with st.container(border=True):
        if st.session_state.privacy_mode:
            st.write("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ: (í‘œì‹œ ìˆ¨ê¹€) â€” ì´ ì˜ì—­ì€ í™”ë©´ ê³µìœ  ì‹œ ë¯¼ê°í•  ìˆ˜ ìˆì–´ìš”.")
        else:
            st.write(problem_text)

    reco = st.session_state.onboarding_reco or {}

    # ì¶”ì²œê°’ ë°˜ì˜(ì´ˆê¸° 1íšŒë§Œ, ì‚¬ìš©ì ìˆ˜ì • ë³´í˜¸)
    if reco and not st.session_state.onboarding_applied:
        rec_cat = reco.get("recommended_category", "")
        if rec_cat in [c[0] for c in TOPIC_CATEGORIES]:
            st.session_state.category = rec_cat

        rec_dt = reco.get("recommended_decision_type", "")
        if rec_dt in DECISION_TYPES:
            st.session_state.decision_type = rec_dt

        rec_coach = reco.get("recommended_coach_id", "")
        if rec_coach in [c["id"] for c in COACHES]:
            st.session_state.coach_id = rec_coach

        goal_draft = str(reco.get("goal_draft", "") or "").strip()
        if goal_draft and not (st.session_state.goal or "").strip():
            st.session_state.goal = goal_draft

        if not (st.session_state.situation or "").strip():
            st.session_state.situation = problem_text

        st.session_state.onboarding_applied = True

    st.divider()
    st.subheader("ì¶”ì²œê°’ í™•ì¸/ìˆ˜ì •")

    c1, c2 = st.columns(2)
    with c1:
        st.selectbox("ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")
        st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type")
        st.text_input("ì›í•˜ëŠ” ëª©í‘œ(ì´ˆì•ˆ)", key="goal", placeholder="ì˜ˆ: ë‚´ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê¸°ì¤€ì„ ì„ ëª…í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ë‹¤")
        st.text_input("ì˜µì…˜(ì‰¼í‘œë¡œ êµ¬ë¶„, ì„ íƒ)", key="options", placeholder="ì˜ˆ: A, B, C")
        st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions), key="num_questions")
    with c2:
        coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
        cur = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
        picked = st.radio("ì½”ì¹˜ ì„ íƒ", coach_labels, index=cur)
        st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]
        coach = coach_by_id(st.session_state.coach_id)

        reason = str(reco.get("coach_reason", "") or "").strip()
        if reason:
            st.info(f"**AIê°€ ì´ ì½”ì¹˜ë¥¼ ì¶”ì²œí•œ ì´ìœ (ì°¸ê³ ):** {reason}")

        with st.expander("ì½”ì¹˜ ì§„í–‰ ë°©ì‹"):
            st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
            for m in coach["method"]:
                st.write(f"- {m}")
            st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.subheader("ìƒí™© ì„¤ëª…(í¸ì§‘ ê°€ëŠ¥)")
    st.caption("ê¸°ë³¸ê°’ì€ 1ë‹¨ê³„ì—ì„œ ì ì€ ê³ ë¯¼ì…ë‹ˆë‹¤. í•„ìš”í•˜ë©´ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”.")
    st.text_area("ìƒí™© ì„¤ëª…", key="situation", height=180)

    with st.expander("ê²°ì • ìœ í˜• ê°€ì´ë“œ(í…œí”Œë¦¿)"):
        st.caption("í•„ìš”í•˜ë©´ ì•„ë˜ ê°€ì´ë“œë¥¼ ìƒí™© ì„¤ëª…ì— ì‚½ì…í•  ìˆ˜ ìˆì–´ìš”.")
        tmpl = DECISION_TEMPLATES.get(st.session_state.decision_type, "")
        if tmpl:
            st.code(tmpl, language="text")
            if st.button("ê°€ì´ë“œ ì‚½ì…(ìƒí™© ì„¤ëª…ì— ì¶”ê°€)", use_container_width=True):
                cur_txt = (st.session_state.situation or "").strip()
                st.session_state.situation = (cur_txt + "\n\n" + tmpl).strip() if cur_txt else tmpl
                st.rerun()

    st.divider()
    b1, b2, b3 = st.columns([1, 1, 1])
    with b1:
        if st.button("â¬…ï¸ ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.page = "landing"
            st.rerun()
    with b2:
        if st.button("ì¶”ì²œ ì›ë¬¸(JSON) ë³´ê¸°", use_container_width=True):
            if st.session_state.onboarding_raw:
                st.code(st.session_state.onboarding_raw, language="json")
            else:
                st.caption("ì¶”ì²œ ì›ë¬¸ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
    with b3:
        if st.button("ì½”ì¹­ ì‹œì‘í•˜ê¸°(ì‹¤í–‰í•˜ê¸°)", type="primary", use_container_width=True):
            st.session_state.q_index = 0
            st.session_state.questions = []
            st.session_state.answers = []
            st.session_state.probe_active = False
            st.session_state.probe_question = ""
            st.session_state.probe_for_index = None
            st.session_state.probe_mode = ""
            st.session_state.crosscheck_used_for = []
            st.session_state.final_report_json = None
            st.session_state.final_report_raw = None
            st.session_state.decision_matrix_df = None
            st.session_state.page = "questions"
            st.rerun()


def render_questions() -> None:
    st.title("ì§ˆë¬¸")
    st.caption("í•œ í™”ë©´ì— í•œ ì§ˆë¬¸. ë‹µë³€ì´ 10ì ë¯¸ë§Œì´ë©´ êµ¬ì²´í™” ì§ˆë¬¸, â€˜ë‚œê°(ì •ë³´ ë¶€ì¡±)â€™ì´ë©´ ì¬í”„ë ˆì´ë° ì§ˆë¬¸ì„ 1íšŒ ì œê³µí•©ë‹ˆë‹¤.")

    nq = int(st.session_state.num_questions)
    q_idx = int(st.session_state.q_index)
    q_idx = max(0, min(q_idx, nq - 1))

    # ê°ì • íŠ¸ë˜í‚¹: ì§ˆë¬¸ ì‹œì‘ ì „ì— í•œ ë²ˆë§Œ(ì²« ì§ˆë¬¸ì—ì„œë§Œ)
    if q_idx == 0 and st.session_state.emotion_pre is None:
        st.subheader("ì‹œì‘ ì „ ì…€í”„ ì²´í¬(1ì´ˆ)")
        st.caption("ì§€ê¸ˆ ë§ˆìŒì˜ ë¬´ê²Œ/ë¶ˆí¸í•¨/ê¸´ì¥ ì •ë„ë¥¼ 1~5ë¡œ ì°ì–´ì£¼ì„¸ìš”(ì •ë‹µ ì—†ìŒ).")
        st.session_state.emotion_pre = st.slider("í˜„ì¬ ê°ì • ê°•ë„", 1, 5, 3, key="emotion_pre_slider")
        st.divider()

    ensure_question(q_idx, nq)
    main_q = st.session_state.questions[q_idx]

    if st.session_state.probe_active and st.session_state.probe_for_index == q_idx:
        show_q = st.session_state.probe_question
        kind = "probe"
        badge = "ë„ì›€ ì§ˆë¬¸(ì¬í”„ë ˆì´ë°)" if st.session_state.probe_mode == "reframe" else "ì¶”ê°€ ì§ˆë¬¸(êµ¬ì²´í™”)"
    else:
        show_q = main_q
        kind = "main"
        badge = "ë©”ì¸ ì§ˆë¬¸"

    top_c1, top_c2, top_c3 = st.columns([1, 2, 1])
    with top_c1:
        if st.button("â¬…ï¸ ì´ì „ìœ¼ë¡œ", use_container_width=True, disabled=(q_idx == 0 and not st.session_state.answers)):
            handle_back()
            st.rerun()
    with top_c3:
        st.caption(f"ë©”ì¸ ë‹µë³€: {main_answer_count()} / {nq}")

    st.subheader(f"Q{q_idx + 1} / {nq}  Â·  {badge}")
    with st.container(border=True):
        st.markdown(f"**{show_q}**")

    with st.form(f"answer_form_{q_idx}_{kind}", clear_on_submit=True):
        ans = st.text_area("ë‹µë³€", placeholder="ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", height=150)
        submitted = st.form_submit_button("ë‹µë³€ ì €ì¥", use_container_width=True)

    if submitted:
        a = (ans or "").strip()
        if not a:
            st.warning("ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í•œ ì¤„ë§Œ ì…ë ¥í•´ë„ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            if kind == "probe":
                add_answer(show_q, a, kind="probe", main_index=q_idx, subkind=st.session_state.probe_mode or "")
                # probe ë -> ë‹¤ìŒ mainìœ¼ë¡œ
                st.session_state.probe_active = False
                st.session_state.probe_question = ""
                st.session_state.probe_for_index = None
                st.session_state.probe_mode = ""
                st.session_state.q_index = min(q_idx + 1, nq - 1)
                st.rerun()

            # main answer ì €ì¥
            add_answer(show_q, a, kind="main", main_index=q_idx, subkind="")

            # 1) ë‚œê°(í‚¤ì›Œë“œ+ì •ë³´ë¶€ì¡±) ë‹µë³€ì´ë©´: ì¬í”„ë ˆì´ë° ì§ˆë¬¸ 1íšŒ ì œê³µ(ë‹¤ìŒ ë‹¨ê³„ë¡œ ì•ˆ ë„˜ì–´ê°)
            if is_confused_answer(a):
                rq, err, dbg = generate_reframe_question(show_q, a)
                st.session_state.debug_log = dbg
                st.session_state.probe_active = True
                st.session_state.probe_question = rq
                st.session_state.probe_for_index = q_idx
                st.session_state.probe_mode = "reframe"
                st.rerun()

            # 2) ì§§ì€ ë‹µë³€ì´ë©´: êµ¬ì²´í™” ì§ˆë¬¸ 1íšŒ ì œê³µ
            if is_too_short_answer(a):
                pq, err, dbg = generate_probe_question(show_q, a)
                st.session_state.debug_log = dbg
                st.session_state.probe_active = True
                st.session_state.probe_question = pq
                st.session_state.probe_for_index = q_idx
                st.session_state.probe_mode = "short"
                st.rerun()

            # 3) ì •ìƒ ì§„í–‰
            if main_answer_count() >= nq:
                st.session_state.page = "report"
                st.session_state.report_just_entered = True
                st.session_state.q_index = nq - 1
            else:
                st.session_state.q_index = min(q_idx + 1, nq - 1)
            st.rerun()

    # í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ: ë‹µë³€ ê¸°ë¡ ìˆ¨ê¸°ê¸° í† ê¸€ ì§€ì›
    if not (st.session_state.privacy_mode and st.session_state.hide_history):
        with st.expander("ë‹µë³€ ê¸°ë¡"):
            grouped: Dict[int, List[Dict[str, Any]]] = {}
            for qa in st.session_state.answers:
                grouped.setdefault(int(qa.get("main_index", 0)), []).append(qa)

            for mi in sorted(grouped.keys()):
                st.markdown(f"### Q{mi + 1}")
                for qa in grouped[mi]:
                    tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
                    sub = qa.get("subkind", "")
                    tag2 = f"{tag}:{sub}" if sub else tag
                    st.markdown(f"**({tag2}) {qa['q']}**")
                    st.write(qa["a"])
                    st.caption(qa["ts"])
                    st.divider()
    else:
        st.caption("í”„ë¼ì´ë²„ì‹œ ëª¨ë“œ: ë‹µë³€ ê¸°ë¡ì´ ìˆ¨ê¹€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")


def render_emotion_delta_block() -> None:
    st.subheader("ê°ì • ë³€í™”(ì…€í”„ ì²´í¬)")
    pre = st.session_state.emotion_pre
    post = st.session_state.emotion_post
    if pre is None:
        st.caption("ì‹œì‘ ì „ ê°ì • ê°•ë„ê°€ ê¸°ë¡ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        return

    if post is None:
        st.caption("ëë‚œ ë’¤ ê°ì • ê°•ë„ë¥¼ ì•„ì§ ê¸°ë¡í•˜ì§€ ì•Šì•˜ì–´ìš”.")
        return

    delta = int(post) - int(pre)
    c1, c2, c3 = st.columns(3)
    c1.metric("ì‹œì‘", str(pre))
    c2.metric("ë", str(post))
    c3.metric("ë³€í™”(ë-ì‹œì‘)", f"{delta:+d}")
    st.caption("ì´ ê°’ì€ â€˜ì¢‹ê³  ë‚˜ì¨â€™ì´ ì•„ë‹ˆë¼, ì •ë¦¬ ì „/í›„ì˜ ì²´ê° ë³€í™”ë¥¼ ê´€ì°°í•˜ê¸° ìœ„í•œ ê¸°ë¡ì´ì—ìš”.")


def render_report() -> None:
    coach = coach_by_id(st.session_state.coach_id)
    nq = int(st.session_state.num_questions)

    st.title("ìµœì¢… ì •ë¦¬")
    st.caption("ì¶”ì²œ/ì •ë‹µ ì—†ì´, ê³ ë¯¼ì˜ í•µì‹¬ê³¼ ê¸°ì¤€ì„ â€˜ê±°ìš¸ ë¹„ì¶”ê¸°â€™ ë°©ì‹ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.")

    if st.session_state.report_just_entered:
        st.balloons()
        st.session_state.report_just_entered = False

    # ê°ì • íŠ¸ë˜í‚¹: ë¦¬í¬íŠ¸ì—ì„œ post ê¸°ë¡
    st.subheader("ëë‚œ ë’¤ ì…€í”„ ì²´í¬(1ì´ˆ)")
    st.caption("ì •ë¦¬ë¥¼ ë§ˆì¹œ ì§€ê¸ˆì˜ ê°ì • ê°•ë„ë¥¼ 1~5ë¡œ ì°ì–´ì£¼ì„¸ìš”(ì •ë‹µ ì—†ìŒ).")
    st.session_state.emotion_post = st.slider("í˜„ì¬ ê°ì • ê°•ë„", 1, 5, 3, key="emotion_post_slider")
    st.divider()

    if main_answer_count() < nq:
        st.warning("ì•„ì§ ëª¨ë“  ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì§ˆë¬¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ ë‹µë³€ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ ì´ë™", type="primary"):
            st.session_state.page = "questions"
            st.rerun()
        st.stop()

    colA, colB = st.columns([1, 1])
    with colA:
        gen = st.button("ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨", type="primary", use_container_width=True)
    with colB:
        if st.button("ìƒˆ ì„¸ì…˜ ì‹œì‘", use_container_width=True):
            reset_flow("landing", keep_problem=False)
            st.rerun()

    if gen or (st.session_state.final_report_json is None and st.session_state.final_report_raw is None):
        with st.spinner("ìµœì¢… ì •ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            data, err, dbg, raw = generate_final_report_json()
            st.session_state.debug_log = dbg
            if data is not None:
                st.session_state.final_report_json = data
                st.session_state.final_report_raw = raw
            else:
                st.session_state.final_report_json = None
                st.session_state.final_report_raw = raw
                st.error(err or "ì •ë¦¬ ìƒì„± ì‹¤íŒ¨")

    data = st.session_state.final_report_json
    if data:
        st.success("ìµœì¢… ì •ë¦¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

        render_emotion_delta_block()
        render_summary_block(data)

        # 1) ê¸°ì¤€
        criteria_names = render_criteria(data)

        # 2) ë§¤íŠ¸ë¦­ìŠ¤
        render_decision_matrix(criteria_names, data)

        # 3) ì½”ì¹˜ë³„ ë¸”ë¡
        if coach["id"] == "action":
            render_action_visualization(data)
        elif coach["id"] == "logic":
            render_key_points_logic(data)
        else:
            render_emotions_values(data)

        # 4) ëª¨ìˆœ/ê¸´ì¥ ì§€ë„(ì‹ ê·œ)
        render_tension_map(data)

        # 5) ì •ë³´ ë¶€ì¡± ì²´í¬ë¦¬ìŠ¤íŠ¸(ì‹ ê·œ)
        render_info_check_questions(data)

        # 6) mirroring ì‹œê°í™”(ê¸°ì¡´)
        render_mirroring_visual()

        # 7) ì½”ì¹­ ë©”ì‹œì§€ + ë‹¤ìŒ ì§ˆë¬¸
        render_coaching_message(data)
        render_next_question(data)

        # 8) ë‹¤ìŒ ì„¸ì…˜ ì—°ê²°(ì‹ ê·œ)
        st.subheader("ë‹¤ìŒ ì„¸ì…˜ìœ¼ë¡œ ì—°ê²°í•˜ê¸°")
        st.caption("ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•œ ë‚´ìš©ì„ â€˜ë‹¤ìŒ ì„¸ì…˜ì˜ ì‹œì‘ ê³ ë¯¼â€™ìœ¼ë¡œ ì‚¼ì„ ìˆ˜ ìˆì–´ìš”(ì¶”ì²œ ì•„ë‹˜).")
        nsq = str(data.get("next_self_question", "") or "").strip()
        if nsq:
            st.write(f"**ì§ˆë¬¸:** {nsq}")
        next_seed = st.text_area("ë‚´ ë‹µë³€(ë‹¤ìŒ ì„¸ì…˜ ì‹œì‘ìš©)", height=120, placeholder="ì˜ˆ: ë‚´ê°€ ë†“ì¹˜ê¸° ì‹«ì€ ê¸°ì¤€ì€ â€¦")
        colx, coly = st.columns([1, 1])
        with colx:
            if st.button("ì´ ë‹µë³€ìœ¼ë¡œ ìƒˆ ì„¸ì…˜ ì‹œì‘", use_container_width=True):
                if next_seed.strip():
                    st.session_state.user_problem = next_seed.strip()
                    reset_flow("setup_details", keep_problem=True)
                    st.session_state.page = "setup_details"
                    st.rerun()
                else:
                    st.warning("ë‹µë³€ì„ í•œ ì¤„ì´ë¼ë„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        with coly:
            if st.button("ê·¸ëƒ¥ ëœë”©ìœ¼ë¡œ", use_container_width=True):
                reset_flow("landing", keep_problem=False)
                st.rerun()

        # 9) ê³µìœ /ì €ì¥
        st.subheader("ê³µìœ /ì €ì¥")
        export_text = build_report_text_for_export(data)

        if st.session_state.privacy_mode and st.session_state.mask_export:
            export_text = mask_text_for_privacy(export_text)

        render_copy_to_clipboard_button(export_text, "ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ ë³µì‚¬")

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.download_button(
            "ë¦¬í¬íŠ¸ .txt ë‹¤ìš´ë¡œë“œ",
            data=export_text.encode("utf-8"),
            file_name=f"pebble_decision_report_{ts}.txt",
            mime="text/plain",
            use_container_width=True,
        )

        st.subheader("ê³µìœ ìš©(JSON)")
        json_text = json.dumps(data, ensure_ascii=False, indent=2)
        if st.session_state.privacy_mode and st.session_state.mask_export:
            json_text = mask_text_for_privacy(json_text)
        st.code(json_text, language="json")

        if contains_forbidden_recommendation(json.dumps(data, ensure_ascii=False)):
            st.warning("ë¦¬í¬íŠ¸ì— ì¶”ì²œ/ì§€ì‹œì²˜ëŸ¼ ë³´ì´ëŠ” í‘œí˜„ì´ ì„ì˜€ì„ ìˆ˜ ìˆì–´ìš”. í•„ìš”í•˜ë©´ â€˜ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨â€™ì„ ëˆŒëŸ¬ ë³´ì„¸ìš”.")

        valid_until = (datetime.now().date() + timedelta(days=7)).strftime("%Y-%m-%d")
        st.divider()
        st.caption(f"ì´ ì •ë¦¬ëŠ” **{valid_until}**ê¹Œì§€ ìœ íš¨í•©ë‹ˆë‹¤.")

    elif st.session_state.final_report_raw:
        st.warning("JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë¬¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.code(st.session_state.final_report_raw, language="text")


# =========================
# Router
# =========================
if st.session_state.page == "landing":
    render_landing()
elif st.session_state.page == "setup_details":
    render_setup_details()
elif st.session_state.page == "questions":
    render_questions()
else:
    render_report()

st.divider()
with st.expander("ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Streamlit Cloud)"):
    st.markdown(
        """
- Secrets ì„¤ì •: Settings â†’ Secretsì— `OPENAI_API_KEY = "sk-..."` ì¶”ê°€
- requirements.txt:
  - streamlit
  - openai
  - pandas
"""
    )

