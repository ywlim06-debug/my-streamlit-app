# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸª¨ ëŒë©©ì´ ê²°ì • ì½”ì¹˜ (Pebble Decision Coach) â€” Streamlit Cloud ì•ˆì • ë²„ì „
#
# âœ… ìˆ˜ì • í¬ì¸íŠ¸ (ì´ë²ˆ ì—ëŸ¬ í•´ê²°)
# - SVG ë°”ì´íŠ¸ë¥¼ st.image()ì— ì§ì ‘ ë„£ìœ¼ë©´ PILì´ ì—´ë ¤ë‹¤ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ
# - ë”°ë¼ì„œ SVGëŠ” base64ë¡œ ì¸ì½”ë”©í•´ì„œ <img src="data:image/svg+xml;base64,..."> ë¡œ ë Œë”ë§
#
# âœ… ê¸°ëŠ¥
# - ê³ ë¯¼ ë²”ìœ„ ì¢íˆê¸°(ì¹´í…Œê³ ë¦¬/ê²°ì •ìœ í˜•)
# - ì½”ì¹˜ 3ì¢… ì»¨ì…‰ ê°•í•˜ê²Œ êµ¬ë¶„(ë…¼ë¦¬/ê°€ì¹˜Â·ê°ì •/ì‹¤í–‰)
# - ì§ˆë¬¸ ë‹¨ê³„ë¶€í„° ëŒë©©ì´ UI ì ê·¹ í™œìš©(ë‹¨ê³„ ì§„í–‰, ë°˜ì§/ê´‘íƒ)
# - ì´ì „ ë‹µë³€ ê¸°ì–µí•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ì— ë°˜ì˜
# - ìµœì¢… ë¦¬í¬íŠ¸ ì½”ì¹˜ë³„ í˜•ì‹ ë‹¤ë¥´ê²Œ ì¶œë ¥
# - OpenAI: st.secrets["OPENAI_API_KEY"] ìš°ì„ , ì—†ìœ¼ë©´ ì‚¬ì´ë“œë°” ì…ë ¥
# - Responses API â†’ ChatCompletions fallback, ëª¨ë¸ fallback
#
# í•„ìš” íŒ¨í‚¤ì§€:
#   pip install streamlit openai
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import textwrap
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Page Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ ê²°ì • ì½”ì¹˜", page_icon="ğŸª¨", layout="wide")

MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” ë…¼ë¦¬ ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•´ì„œ ê²°ì •ì„ 'ëª…ë£Œ'í•˜ê²Œ ë§Œë“œëŠ” ì½”ì¹˜í•‘",
        "style": "ë…¼ë¦¬ì /ê°„ê²°/í”„ë ˆì„ì›Œí¬ ì¤‘ì‹¬",
        "method": [
            "í•µì‹¬ ìŸì Â·ì œì•½ì¡°ê±´ ì •ì˜",
            "ì˜µì…˜/ê¸°ì¤€/ê°€ì¤‘ì¹˜ ì •ë¦¬",
            "ì¥ë‹¨ì Â·ë¦¬ìŠ¤í¬Â·ê°€ì • ê²€ì¦",
            "ê²°ë¡  + ì„ íƒ ê·¼ê±°",
        ],
        "prompt_hint": "MECE, ì˜ì‚¬ê²°ì • ê¸°ì¤€í‘œ, ë¦¬ìŠ¤í¬/ê°€ì • ê²€ì¦ ì§ˆë¬¸ì„ ì˜ ì”€",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜/ê°ì • ì½”ì¹˜",
        "tagline": "ë‚´ê°€ 'ì™œ í”ë“¤ë¦¬ëŠ”ì§€'ë¥¼ ì°¾ì•„ ê¸°ì¤€ì„ ì„¸ì›Œì£¼ëŠ” ì½”ì¹˜í•‘",
        "style": "ê³µê°/ê°€ì¹˜ê´€/ê°ì • ëª…ë£Œí™”",
        "method": [
            "ê°ì •/ë‘ë ¤ì›€/ê¸°ëŒ€ ë¶„í•´",
            "ì§„ì§œ ì›í•˜ëŠ” ê²ƒ(ê°€ì¹˜) ë°œêµ´",
            "í›„íšŒ ìµœì†Œí™” ê´€ì (ë¯¸ë˜ì˜ ë‚˜) ì§ˆë¬¸",
            "ë‚˜ë‹µê²Œ ì„ íƒí•˜ëŠ” ë¬¸ì¥ ë§Œë“¤ê¸°",
        ],
        "prompt_hint": "ê°ì • ë¼ë²¨ë§, ê°€ì¹˜ ìš°ì„ ìˆœìœ„, í›„íšŒ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì„ ì˜ ì”€",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê²°ì •ì„ 'í–‰ë™'ìœ¼ë¡œ ë°”ê¾¸ëŠ” ì½”ì¹˜í•‘ (ì‹¤í—˜Â·ë‹¤ìŒ ìŠ¤í…)",
        "style": "êµ¬ì²´ì /ì‹¤í–‰/ì‘ì€ ì‹¤í—˜",
        "method": [
            "ì˜¤ëŠ˜~7ì¼ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ì‹¤í—˜ ì„¤ê³„",
            "ìµœì†Œ í–‰ë™(15ë¶„) + ì²´í¬ë¦¬ìŠ¤íŠ¸",
            "ì¥ì• ë¬¼/ëŒ€ì‘ê³„íš(If-Then)",
            "ì‹¤í–‰ í›„ ë¦¬ë·° ì§ˆë¬¸",
        ],
        "prompt_hint": "ì‘ì€ ì‹¤í—˜, ì¼ì •/ë£¨í‹´, ì¥ì• ë¬¼ ëŒ€ì‘ì„ ë§¤ìš° êµ¬ì²´í™”",
    },
]

STEPS = ["ì£¼ì œ ì„ íƒ", "ê³ ë¯¼ ì •ë¦¬(1)", "ê³ ë¯¼ ì •ë¦¬(2)", "ê¸°ì¤€Â·ì˜µì…˜", "ìµœì¢… ì •ë¦¬"]


# =========================
# Pebble (Rock) UI: SVG â†’ base64 HTML img
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    # ì €ì‘ê¶Œ ì´ìŠˆ ì—†ëŠ” ì˜¤ë¦¬ì§€ë„ SVG ë„í˜•
    return f"""
<svg width="160" height="120" viewBox="0 0 160 120" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="pebble">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="80%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M28 80
           C14 60, 20 30, 50 20
           C66 14, 96 12, 114 24
           C142 44, 150 68, 130 88
           C112 108, 54 110, 28 80 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M54 30 C68 22, 82 22, 94 30"
        fill="none" stroke="{shine}" stroke-width="7" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_svg_b64(progress_0_to_1: float, inactive: bool = False) -> str:
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    if inactive:
        fill = "#2f3136"
        shine = "#6b6f7a"
    else:
        # ì§„í–‰ë ìˆ˜ë¡ ë°ì•„ì§€ê¸°
        fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
        shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"

    svg = _pebble_svg(fill=fill, shine=shine)
    b64 = base64.b64encode(svg.encode("utf-8")).decode("ascii")
    return b64


def render_pebble_row(step_idx: int, total: int) -> None:
    cols = st.columns(total)
    for i in range(total):
        active = i <= step_idx
        p = (i + 1) / total
        b64 = pebble_svg_b64(p, inactive=not active)

        html = f"""
        <div style="text-align:center;">
          <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:150px;"/>
          <div style="font-size:12px; margin-top:4px; opacity:{1.0 if active else 0.55};">
            {STEPS[i]}
          </div>
        </div>
        """
        cols[i].markdown(html, unsafe_allow_html=True)


def render_hero_pebble(progress: float, label: str) -> None:
    b64 = pebble_svg_b64(progress, inactive=False)
    html = f"""
    <div style="text-align:center;">
      <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:240px;"/>
      <div style="margin-top:6px; font-size:14px;">
        {label}
      </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)


# =========================
# OpenAI Helpers (robust + debug)
# =========================
def get_api_key() -> str:
    # Streamlit Cloud: secrets ìš°ì„ 
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì•„ìš”. `pip install openai` í•´ì£¼ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.7) -> Tuple[Optional[str], Optional[str], List[str]]:
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•´ìš”. Secretsì— OPENAI_API_KEYë¥¼ ë„£ê±°ë‚˜ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ ì£¼ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    # 1) Responses API
    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    # 2) Chat Completions fallback
    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆì–´ìš”. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.", debug


# =========================
# State
# =========================
def init_state() -> None:
    if "step" not in st.session_state:
        st.session_state.step = 0
    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]
    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]
    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]

    if "answers" not in st.session_state:
        st.session_state.answers = []  # [{"q","a","ts"}]
    if "generated_questions" not in st.session_state:
        st.session_state.generated_questions = {}  # step->question

    if "final_report" not in st.session_state:
        st.session_state.final_report = None
    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []
    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""


def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def add_answer(q: str, a: str) -> None:
    st.session_state.answers.append({"q": q, "a": a, "ts": datetime.now().isoformat(timespec="seconds")})


def reset_flow() -> None:
    st.session_state.step = 0
    st.session_state.answers = []
    st.session_state.generated_questions = {}
    st.session_state.final_report = None
    st.session_state.debug_log = []


# =========================
# Prompting (Coach differentiation)
# =========================
def system_prompt_for(coach: Dict[str, Any]) -> str:
    if coach["id"] == "logic":
        return (
            "ë„ˆëŠ” 'ë…¼ë¦¬ ì½”ì¹˜'ì•¼. ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ ì˜ì‚¬ê²°ì • ë¬¸ì œë¡œ êµ¬ì¡°í™”í•˜ëŠ” ê²ƒ.\n"
            "- ë°˜ë“œì‹œ: ìŸì /ì˜µì…˜/ê¸°ì¤€/ì œì•½/ê°€ì •/ë¦¬ìŠ¤í¬ë¥¼ ë¶„ë¦¬í•´ì„œ ë‹¤ë£¨ê¸°\n"
            "- ì§ˆë¬¸ì€ ì§§ê³ , ë‹µë³€ì„ í‘œ/ëª©ë¡ìœ¼ë¡œ ë§Œë“¤ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë¬»ê¸°\n"
            "- ê°ì • ê³µê°ì€ ì§§ê²Œë§Œ, êµ¬ì¡°í™”ê°€ ìµœìš°ì„ \n"
            "- ë§íˆ¬ëŠ” ê¹”ë”í•˜ê³  ë‹¨í˜¸í•˜ì§€ë§Œ ê³µê²©ì ì´ì§€ ì•Šê²Œ\n"
        )
    if coach["id"] == "value":
        return (
            "ë„ˆëŠ” 'ê°€ì¹˜/ê°ì • ì½”ì¹˜'ì•¼. ëª©í‘œëŠ” ê°ì •ê³¼ ê°€ì¹˜ê´€ì„ ëª…ë£Œí™”í•´ì„œ 'ë‚˜ë‹¤ìš´ ì„ íƒ'ì„ ë•ëŠ” ê²ƒ.\n"
            "- ë°˜ë“œì‹œ: ê°ì • ë¼ë²¨ë§ + ê·¸ ê°ì •ì˜ ê·¼ì›(ìš•êµ¬/ë‘ë ¤ì›€)ì„ íƒìƒ‰\n"
            "- ê°€ì¹˜(ì¤‘ìš”í•œ ê²ƒ)ë¥¼ 3ê°œë¡œ ì¢íˆê³ , í›„íšŒ ìµœì†Œí™” ê´€ì  ì§ˆë¬¸ í¬í•¨\n"
            "- ë§íˆ¬ëŠ” ë”°ëœ»í•˜ê³  ê³µê°ì . ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ë§ë¡œ ì •ë¦¬í•˜ê²Œ ìœ ë„\n"
        )
    return (
        "ë„ˆëŠ” 'ì‹¤í–‰ ì½”ì¹˜'ì•¼. ëª©í‘œëŠ” ê²°ì •ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‹¤í—˜ê³¼ ë‹¤ìŒ í–‰ë™ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê²ƒ.\n"
        "- ë°˜ë“œì‹œ: 7ì¼ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ì‘ì€ ì‹¤í—˜ 1~2ê°œ ì„¤ê³„\n"
        "- ì¥ì• ë¬¼(ì‹œê°„/ëˆ/ì‹¬ë¦¬)ê³¼ If-Then ëŒ€ì‘ì„ ë¬»ê¸°\n"
        "- ë§íˆ¬ëŠ” ì—ë„ˆì§€ ìˆê³  êµ¬ì²´ì . ì²´í¬ë¦¬ìŠ¤íŠ¸/ì¼ì • í‘œí˜„ì„ ì˜ ì“°ê¸°\n"
    )


def build_context_block() -> str:
    cat = st.session_state.category
    dtype = st.session_state.decision_type
    answers = st.session_state.answers

    hist = ""
    for i, qa in enumerate(answers[-6:], start=1):
        hist += f"{i}) Q: {qa['q']}\n   A: {qa['a']}\n"

    return textwrap.dedent(f"""
    [ê³ ë¯¼ ì¹´í…Œê³ ë¦¬]
    {cat}

    [ê²°ì • ìœ í˜•]
    {dtype}

    [ì§€ê¸ˆê¹Œì§€ì˜ Q/A (ìµœê·¼ 6ê°œ)]
    {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
    """).strip()


def question_instruction(step_idx: int, coach: Dict[str, Any]) -> str:
    if step_idx == 1:
        return "ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ 'ìƒí™©' ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ê²Œ ë§Œë“œëŠ” 1ê°œì˜ ì§ˆë¬¸ì„ ë§Œë“¤ì–´."
    if step_idx == 2:
        return "ì‚¬ìš©ìì˜ 'ì›í•˜ëŠ” ê²°ê³¼/ë‘ë ¤ìš´ ê²°ê³¼/ê°€ì¥ ì¤‘ìš”í•œ ì œì•½'ì„ ë“œëŸ¬ë‚´ëŠ” 1ê°œì˜ ì§ˆë¬¸ì„ ë§Œë“¤ì–´."
    if step_idx == 3:
        if coach["id"] == "logic":
            return "ì˜µì…˜ì„ 2~4ê°œë¡œ ë‚˜ëˆ„ê³  í‰ê°€ ê¸°ì¤€ 3ê°œë¥¼ ë½‘ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´. ë‹µì€ í‘œë¡œ ë§Œë“¤ê¸° ì¢‹ê²Œ."
        if coach["id"] == "value":
            return "ê°€ì¹˜ ìš°ì„ ìˆœìœ„(ìƒìœ„ 3ê°œ)ì™€ í›„íšŒ í…ŒìŠ¤íŠ¸(1ë…„ ë’¤/5ë…„ ë’¤)ë¥¼ í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´."
        return "ì´ë²ˆ ì£¼ì— í•  ìˆ˜ ìˆëŠ” 'ì‘ì€ ì‹¤í—˜'ì„ ê³ ë¥´ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ë§Œë“¤ì–´. (ì˜ˆ: 15ë¶„ í–‰ë™/í•˜ë£¨ ì²´í¬)"
    if coach["id"] == "logic":
        return "ê²°ì •ì„ ë‚´ë¦¬ê¸° ì „ ë§ˆì§€ë§‰ í™•ì¸ ì§ˆë¬¸ 1ê°œ(ê°€ì • ê²€ì¦/ë¦¬ìŠ¤í¬ ëŒ€ë¹„)ë¥¼ ë§Œë“¤ì–´."
    if coach["id"] == "value":
        return "ê²°ì • ë¬¸ì¥ì„ í•œ ì¤„ë¡œ ë§Œë“¤ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(â€˜ë‚˜ëŠ” ___ë¥¼ ìœ„í•´ ___ì„ ì„ íƒí•œë‹¤â€™)ë¥¼ ë§Œë“¤ì–´."
    return "ì‹¤í–‰ ì•½ì†ì„ êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì–¸ì œ/ì–´ë””ì„œ/ë¬´ì—‡ì„/ë§‰íˆë©´ ì–´ë–»ê²Œ)ë¥¼ ë§Œë“¤ì–´."


def generate_next_question(step_idx: int) -> Tuple[Optional[str], Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for(coach)

    user = textwrap.dedent(f"""
    ë„ˆëŠ” ì‚¬ìš©ìì˜ ìƒê°ì„ ì •ë¦¬í•˜ê¸° ìœ„í•œ 'ë‹¨ í•˜ë‚˜ì˜ ì§ˆë¬¸'ì„ ë§Œë“ ë‹¤.

    ê·œì¹™:
    - ì§ˆë¬¸ì€ 1ê°œë§Œ ì¶œë ¥ (ì„¤ëª… ê¸ˆì§€)
    - ì§ˆë¬¸ì€ í•œêµ­ì–´
    - ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ì§€ ì•Šê²Œ, ì§€ê¸ˆ ë‹¨ê³„ ëª©ì ì— ë§ê²Œ êµ¬ì²´ì ìœ¼ë¡œ
    - ì‚¬ìš©ìê°€ ë‹µí•˜ê¸° ì‰½ê²Œ ì˜ˆì‹œ(ê´„í˜¸ 1ì¤„)ëŠ” í—ˆìš©

    {build_context_block()}

    [ì´ë²ˆ ë‹¨ê³„ ëª©ì ]
    {question_instruction(step_idx, coach)}

    ì´ì œ ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥í•´.
    """).strip()

    return call_openai_text(system=system, user=user, temperature=0.7)


def generate_final_report() -> Tuple[Optional[str], Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for(coach)

    if coach["id"] == "logic":
        format_spec = """
ì¶œë ¥ í˜•ì‹:
## í•œ ì¤„ ê²°ë¡ 
- ê²°ë¡ : ...

## ì˜ì‚¬ê²°ì • êµ¬ì¡°
- ìŸì :
- ì˜µì…˜(2~4):
- í‰ê°€ ê¸°ì¤€(3~5):
- ì œì•½/ê°€ì •:
- ë¦¬ìŠ¤í¬/ëŒ€ì‘:

## ì¶”ì²œì•ˆ (ê·¼ê±°)
- ì¶”ì²œ: ...
- ì´ìœ (3ì¤„):
- ë³´ì™„ì±…(ë¦¬ìŠ¤í¬ ì¤„ì´ê¸°):

## ë‹¤ìŒ í–‰ë™(24ì‹œê°„ ë‚´)
- ...
"""
    elif coach["id"] == "value":
        format_spec = """
ì¶œë ¥ í˜•ì‹:
## ì§€ê¸ˆì˜ ë§ˆìŒ ìš”ì•½
- ê°ì •(3ê°œ): ...
- ì§„ì§œ ìš•êµ¬/ë‘ë ¤ì›€: ...

## ë‚˜ì˜ ê¸°ì¤€(ê°€ì¹˜)
- ìƒìœ„ 3ê°€ì§€: ...
- ë²„ë¦´ ìˆ˜ ìˆëŠ” ê²ƒ 1ê°€ì§€: ...

## ë‚˜ë‹¤ìš´ ì„ íƒ ë¬¸ì¥
- â€œë‚˜ëŠ” ___ë¥¼ ìœ„í•´ ___ì„ ì„ íƒí•œë‹¤.â€

## í›„íšŒ ìµœì†Œí™” ì²´í¬
- 1ë…„ ë’¤ì˜ ë‚˜: ...
- 5ë…„ ë’¤ì˜ ë‚˜: ...

## ë‚´ì¼ì˜ ì‘ì€ ì•½ì†
- ...
"""
    else:
        format_spec = """
ì¶œë ¥ í˜•ì‹:
## ê²°ì •ì„ í–‰ë™ìœ¼ë¡œ ë°”ê¾¸ê¸°
- ì´ë²ˆ ì£¼ í•µì‹¬ ëª©í‘œ(1ê°œ): ...

## 7ì¼ ì‹¤í—˜(1~2ê°œ)
- ì‹¤í—˜1: (15ë¶„ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ)
- ì‹¤í—˜2(ì„ íƒ): ...

## If-Then ëŒ€ì‘í‘œ
- ë§Œì•½ ___ì´ë©´ â†’ ___í•œë‹¤ (3ê°œ)

## ì˜¤ëŠ˜(24ì‹œê°„ ë‚´) ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ...
- [ ] ...
- [ ] ...

## ë¦¬ë·° ì§ˆë¬¸(ì‹¤í—˜ í›„)
- ...
"""

    user = textwrap.dedent(f"""
ì•„ë˜ Q/Aë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì½”ì¹˜ ì—­í• ì— ë§ëŠ” 'ìµœì¢… ì •ë¦¬ ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•´.

ê·œì¹™:
- í•œêµ­ì–´
- ì‚¬ìš©ìì—ê²Œ ì„ íƒì„ ê°•ìš”í•˜ì§€ ë§ê³ , ê·¼ê±°ì™€ ë‹¤ìŒ ìŠ¤í…ì„ ëª…í™•íˆ
- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ 'ì¶”ê°€ í™•ì¸ ì§ˆë¬¸' 1ê°œë¥¼ ë§ˆì§€ë§‰ì— ì œì•ˆ
- ê¸¸ì´: 500~900ì

{build_context_block()}

{format_spec}

ë§ˆì§€ë§‰ ì¤„:
- ì¶”ê°€ í™•ì¸ ì§ˆë¬¸: ...
""").strip()

    return call_openai_text(system=system, user=user, temperature=0.65)


# =========================
# UI
# =========================
init_state()

with st.sidebar:
    st.header("ğŸª¨ ëŒë©©ì´ ì„¤ì •")
    st.text_input("OpenAI API Key (Secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()
    st.subheader("ğŸ§­ ê³ ë¯¼ ë²”ìœ„ ì¢íˆê¸°")
    st.selectbox("ê³ ë¯¼ ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")
    st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type")

    st.divider()
    st.subheader("ğŸ§‘â€ğŸ« ê²°ì • ì½”ì¹˜ ì„ íƒ")
    coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
    current_idx = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
    picked = st.radio("ì½”ì¹˜", coach_labels, index=current_idx)
    st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]

    coach = coach_by_id(st.session_state.coach_id)
    with st.expander("ì½”ì¹˜ê°€ ì–´ë–»ê²Œ ë„ì™€ì£¼í•‘?"):
        st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
        st.markdown("**ì§„í–‰ ë°©ì‹**")
        for m in coach["method"]:
            st.write(f"- {m}")
        st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.divider()
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ğŸ”„ ìƒˆ ê³ ë¯¼ ì‹œì‘", use_container_width=True):
            reset_flow()
            st.rerun()
    with c2:
        disabled_next = st.session_state.step >= (len(STEPS) - 1)
        if st.button("ğŸª¨ ë‹¤ìŒ ë‹¨ê³„", use_container_width=True, disabled=disabled_next):
            st.session_state.step += 1
            st.rerun()

st.title("ğŸª¨ ëŒë©©ì´ ê²°ì • ì½”ì¹˜")
st.caption("ì§ˆë¬¸ì„ ë”°ë¼ê°€ë©´ ê³ ë¯¼ì´ ì •ë¦¬ë˜ê³ , ëŒë©©ì´ê°€ ë°˜ì§ì¼ìˆ˜ë¡ ê²°ë¡ ì´ ë˜ë ·í•´ì ¸ìš” âœ¨")

# Step pebbles row (NO PIL)
render_pebble_row(st.session_state.step, len(STEPS))

# Hero pebble (NO PIL)
progress = st.session_state.step / (len(STEPS) - 1)
st.columns([1, 2, 1])[1].container()
with st.columns([1, 2, 1])[1]:
    render_hero_pebble(progress, f"í˜„ì¬ ë‹¨ê³„: **{STEPS[st.session_state.step]}** Â· ì§„í–‰ë„: **{int(progress*100)}%**")

st.divider()

coach = coach_by_id(st.session_state.coach_id)

# Step 0
if st.session_state.step == 0:
    st.subheader("ğŸ§­ ë¨¼ì € ê³ ë¯¼ì„ 'ì‘ê²Œ' ë§Œë“¤ê¸°")
    cat_desc = next((d for n, d in TOPIC_CATEGORIES if n == st.session_state.category), "")
    st.info(f"**ì¹´í…Œê³ ë¦¬:** {st.session_state.category}\n\n{cat_desc}")
    st.success("ì¢‹ì•„ìš”! ì‚¬ì´ë“œë°”ì—ì„œ **â€˜ë‹¤ìŒ ë‹¨ê³„â€™**ë¥¼ ëˆŒëŸ¬ ì§ˆë¬¸ì„ ì‹œì‘í•´ë´ìš” ğŸª¨")

else:
    step_idx = st.session_state.step

    # Generate question (cached)
    if step_idx not in st.session_state.generated_questions:
        q, err, dbg = generate_next_question(step_idx)
        st.session_state.debug_log = dbg
        if q:
            st.session_state.generated_questions[step_idx] = q
        else:
            st.error(err or "ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨")
            with st.expander("ğŸ”§ ë””ë²„ê·¸ ë¡œê·¸"):
                st.write(dbg)
            st.stop()

    question = st.session_state.generated_questions[step_idx]

    with st.container(border=True):
        st.markdown(f"### ğŸª¨ ì§ˆë¬¸ {step_idx} (ì½”ì¹˜: {coach['name']})")
        st.markdown(f"**Q. {question}**")
        st.caption("ì§§ê²Œ ì ì–´ë„ ê´œì°®ì•„ìš”. í•µì‹¬ë§Œ ì ì–´ë„ ëŒë©©ì´ê°€ ë‹¤ë“¬ì–´ì ¸ìš” ğŸª¨")

    # Answer form (clear_on_submit=True)
    with st.form(f"answer_form_{step_idx}", clear_on_submit=True):
        hint = ""
        if st.session_state.answers:
            last_a = st.session_state.answers[-1]["a"]
            hint = f"ì´ì „ ë‹µ ì°¸ê³ : {last_a[:90]}{'â€¦' if len(last_a) > 90 else ''}"
        answer = st.text_area("ğŸ“ ë‚´ ë‹µë³€", placeholder=hint or "ì˜ˆ) ìƒí™©/ì›í•˜ëŠ” ê²°ê³¼/ì œì•½ì„ ì ì–´ì¤˜ìš”", height=140)
        submitted = st.form_submit_button("âœ… ë‹µë³€ ì €ì¥í•˜ê³  ë‹¤ìŒìœ¼ë¡œ", use_container_width=True)

    if submitted:
        if not answer.strip():
            st.warning("ë‹µë³€ì´ ë¹„ì–´ìˆì–´ìš”. í•œ ì¤„ë§Œ ì ì–´ë„ ê´œì°®ì•„ìš”í•‘!")
        else:
            add_answer(question, answer.strip())
            st.success("ì €ì¥ ì™„ë£Œ! ëŒë©©ì´ê°€ ë” ë°˜ì§ì˜€ì–´ìš” âœ¨")
            if st.session_state.step < len(STEPS) - 1:
                st.session_state.step += 1
            st.rerun()

    st.subheader("ğŸ“š ì§€ê¸ˆê¹Œì§€ì˜ ë‹µë³€(ê¸°ì–µí•˜ê³  ìˆì–´ìš”)")
    if not st.session_state.answers:
        st.caption("ì•„ì§ ë‹µë³€ì´ ì—†ì–´ìš”.")
    else:
        for i, qa in enumerate(st.session_state.answers, start=1):
            with st.expander(f"ğŸª¨ Q{i}. {qa['q']}"):
                st.write(qa["a"])
                st.caption(qa["ts"])

    # Final step report
    if st.session_state.step == len(STEPS) - 1:
        st.divider()
        st.subheader("ğŸ§¾ ìµœì¢… ì •ë¦¬ ë¦¬í¬íŠ¸(ëŒë©©ì´ ìœ¤ë‚´ê¸°)")

        gen = st.button("âœ¨ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±", type="primary", use_container_width=True)
        if gen:
            with st.spinner("ëŒë©©ì´ì— ìœ¤ì„ ë‚´ëŠ” ì¤‘â€¦(ë¦¬í¬íŠ¸ ìƒì„±)"):
                report, err, dbg = generate_final_report()
                st.session_state.debug_log = dbg
                if report:
                    st.session_state.final_report = report
                else:
                    st.session_state.final_report = None
                    st.error(err or "ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")

        if st.session_state.final_report:
            st.success("ì™„ë£Œ! ëŒë©©ì´ê°€ ë°˜ì§ë°˜ì§ ìœ¤ì´ ë‚¬ì–´ìš” âœ¨")
            st.markdown(st.session_state.final_report)

            st.markdown("### ğŸ“Œ ê³µìœ ìš© ìš”ì•½(JSON)")
            share = {
                "category": st.session_state.category,
                "decision_type": st.session_state.decision_type,
                "coach": coach["name"],
                "answers": st.session_state.answers,
                "final_report": st.session_state.final_report,
            }
            st.code(json.dumps(share, ensure_ascii=False, indent=2), language="json")

    with st.expander("ğŸ”§ ë””ë²„ê·¸ ë¡œê·¸ (ë¬¸ì œ ìƒê¸°ë©´ ë³µì‚¬í•´ì„œ ë³´ë‚´ì¤˜ìš”)"):
        st.write(st.session_state.debug_log)

st.divider()
with st.expander("âœ… Streamlit Cloud ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸"):
    st.markdown(
        """
- **Secrets ì„¤ì •**: Streamlit Cloud â†’ Settings â†’ Secretsì— ì•„ë˜ ì¶”ê°€  
  - `OPENAI_API_KEY = "sk-..."`

- **requirements.txt** ì˜ˆì‹œ
  - `streamlit`
  - `openai`

- ëª¨ë¸ ê¶Œí•œ ë¬¸ì œë©´ ì•±ì´ **gpt-4o-minië¡œ ìë™ ì¬ì‹œë„**í•´ìš”.
"""
    )

