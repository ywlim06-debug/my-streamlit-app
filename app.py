# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ (Pebble Decision Coach)
#
# ì›ì¹™(ìœ ì§€):
# - ì •ë‹µ/ê²°ë¡ /ì¶”ì²œ ì œê³µ ê¸ˆì§€ (ê°•ì œ)
# - í•œ í™”ë©´ì— í•œ ì§ˆë¬¸ì”©
# - ì´ì „ ë‹µë³€ ë°˜ì˜ ë™ì  ì§ˆë¬¸ ìƒì„±
# - ë§ˆì§€ë§‰: ê³ ë¯¼ì˜ í•µì‹¬ / ì„ íƒ ê¸°ì¤€ / ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°, ì¶”ì²œ ê¸ˆì§€)
#
# ìœ ì§€ë˜ëŠ” ê¸°ëŠ¥(ì´ì „ ë²„ì „ í¬í•¨):
# - Logic Cross-Check(ë‹µë³€ ê°„ ì¶©ëŒ ê°ì§€ â†’ ì¶©ëŒì„ ì§šëŠ” ì§ˆë¬¸ ìš°ì„  ìƒì„±)
# - Probing(ë‹µë³€ 10ì ë¯¸ë§Œì´ë©´ 1íšŒ êµ¬ì²´í™” ì§ˆë¬¸)
# - Action Coach ê°•í™”: If-Then íŠ¸ë¦¬ê±° + Pre-mortem ì§ˆë¬¸ í¬í•¨
# - Back ë²„íŠ¼
# - ê²°ì • ìœ í˜•ë³„ í…œí”Œë¦¿(2ë‹¨ê³„ì—ì„œ ìƒí™©ì„¤ëª… ê°€ì´ë“œ ì‚½ì… ë²„íŠ¼ ì œê³µ)
# - ë¦¬í¬íŠ¸: ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(st.data_editor), Mirroring ì‹œê°í™”, ë³µì‚¬/ë‹¤ìš´ë¡œë“œ, ìœ íš¨ê¸°ê°„, balloons
#
# ì´ë²ˆ ë³€ê²½(ì˜¨ë³´ë”© ì „ë©´ ìˆ˜ì •):
# - ì‚¬ì´ë“œë°” ì„¤ì • ì œê±° â†’ ë©”ì¸ í™”ë©´ ë‹¨ê³„ë³„ Onboarding Flow
#   landing(ê³ ë¯¼ ì‘ì„±) -> setup_details(AI ë¶„ì„/ì¶”ì²œ + ìˆ˜ì •) -> questions -> report
# - ì‚¬ì´ë“œë°”ëŠ” ë³´ì¡° ê¸°ëŠ¥(ì²˜ìŒë¶€í„°, ë””ë²„ê·¸ ë¡œê·¸)ë§Œ
# - ì§„í–‰ë°”(render_pebble_bridge)ì— landing/setup ë‹¨ê³„ ë°˜ì˜
#
# í•„ìš”:
#   pip install streamlit openai pandas
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import random
import re
import textwrap
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ AI ê²°ì • ì½”ì¹­", page_icon="ğŸª¨", layout="wide")

MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

DECISION_TEMPLATES: Dict[str, str] = {
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] A vs B ì„ íƒ ì •ë¦¬
        1) Aì™€ Bë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í•´ë³´ì„¸ìš”(ë¬´ì—‡ì´ ë‹¤ë¥¸ê°€?)
        2) Aì˜ ì¥ì /ë‹¨ì , Bì˜ ì¥ì /ë‹¨ì ì„ ê°ê° 2~3ê°œì”© ì ì–´ë³´ì„¸ìš”
        3) 'ë‚´ê²Œ ì¤‘ìš”í•œ ê¸°ì¤€' 3ê°œë¥¼ ì ê³ , ê° ê¸°ì¤€ì—ì„œ A/Bê°€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì¨ë³´ì„¸ìš”
        4) ìµœì•…ì˜ ê²½ìš°(ë¦¬ìŠ¤í¬)ì™€ ê°ë‹¹ ê°€ëŠ¥í•œ ì •ë„ë¥¼ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì—¬ëŸ¬ ì˜µì…˜ ë¹„êµ
        1) í›„ë³´ ì˜µì…˜ì„ ëª¨ë‘ ë‚˜ì—´í•´ë³´ì„¸ìš”(ìµœì†Œ 3ê°œ)
        2) ë¹„êµ ê¸°ì¤€ 3~5ê°œ(ë¹„ìš©/ì‹œê°„/ì„±ì¥/ìŠ¤íŠ¸ë ˆìŠ¤/ê´€ê³„ ë“±)ë¥¼ ì ì–´ë³´ì„¸ìš”
        3) ê° ì˜µì…˜ì´ ê¸°ì¤€ë³„ë¡œ ì–´ë–¤ ëŠë‚Œì¸ì§€(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)ë¶€í„° ëŒ€ëµ ì ì–´ë³´ì„¸ìš”
        4) 'ì§€ê¸ˆì˜ ë‚˜'ì—ê²Œ ì¤‘ìš”í•œ ê²ƒê³¼ '1ë…„ ë’¤ì˜ ë‚˜'ì—ê²Œ ì¤‘ìš”í•œ ê²ƒì„ êµ¬ë¶„í•´ë³´ì„¸ìš”
        """
    ).strip(),
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)
        1) 'í•œë‹¤'ì˜ ì˜ë¯¸ë¥¼ êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ìˆ˜ì¤€ìœ¼ë¡œ?)
        2) í•œë‹¤ë©´ ì–»ëŠ” ê²ƒ/ìƒëŠ” ê²ƒ, ì•ˆ í•œë‹¤ë©´ ì–»ëŠ” ê²ƒ/ìƒëŠ” ê²ƒì„ ê°ê° ì ì–´ë³´ì„¸ìš”
        3) ê²°ì •ì´ ë¯¸ë¤„ì§ˆ ë•Œ ìƒê¸°ëŠ” ë¹„ìš©(ë¶ˆì•ˆ/ê¸°íšŒ/ê´€ê³„ ë“±)ì„ ì ì–´ë³´ì„¸ìš”
        4) ì§€ê¸ˆ ë‹¹ì¥ í•„ìš”í•œ ì¶”ê°€ ì •ë³´ 1~2ê°œê°€ ë¬´ì—‡ì¸ì§€ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì „ëµ/ì‹œì  ê²°ì •
        1) ì„±ê³µì˜ ì •ì˜ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ(ì¸¡ì • ê°€ëŠ¥í•˜ê²Œ)
        2) ì„ íƒ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ 2~3ê°œ(ë¹ ë¥´ê²Œ/ì²œì²œíˆ/ë¶€ë¶„ ì ìš© ë“±) ë‚˜ì—´
        3) ê° ì‹œë‚˜ë¦¬ì˜¤ì˜ ë¦¬ìŠ¤í¬ì™€ ì™„ì¶©ì¥ì¹˜(ë³´í—˜)ë¥¼ ì ì–´ë³´ì„¸ìš”
        4) 'ì‹œì‘ íŠ¸ë¦¬ê±°(If) â†’ í–‰ë™(Then)' í˜•íƒœë¡œ ì‹¤í–‰ ì¡°ê±´ì„ ì„¤ê³„í•´ë³´ì„¸ìš”
        """
    ).strip(),
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ê°ˆë“±/ëŒ€í™” ë°©í–¥ ì •ë¦¬
        1) ì§€ê¸ˆ ê°ˆë“±ì˜ ìŸì ì„ 'ì‚¬ì‹¤/í•´ì„/ê°ì •/ìš”êµ¬'ë¡œ ë‚˜ëˆ  ì ì–´ë³´ì„¸ìš”
        2) ë‚´ê°€ ì›í•˜ëŠ” ë³€í™”(ìš”êµ¬) 1~2ê°œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”
        3) ìƒëŒ€ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸¸ ë§Œí•œ ê²ƒì„ ì¶”ì¸¡í•´ ì ì–´ë³´ì„¸ìš”(í™•ì • ì•„ë‹˜)
        4) ëŒ€í™”ì—ì„œ ì§€í‚¤ê³  ì‹¶ì€ ì›ì¹™(í†¤/íƒ€ì´ë°/í•œê³„ì„ )ì„ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
}

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” êµ¬ì¡° ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê³ , ê°€ì •ì„ í”ë“œëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì •ë¦¬ë¥¼ ë•ìŠµë‹ˆë‹¤",
        "style": "MECE/ê¸°ì¤€/ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ)",
        "method": [
            "ìƒí™©Â·ì œì•½Â·ì˜µì…˜ì„ ë¶„ë¦¬í•´ì„œ ì ê²Œ í•˜ê¸°",
            "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ì•„ ìš°ì„ ìˆœìœ„ë¥¼ í™•ì¸í•˜ê¸°",
            "â€˜ë‚´ê°€ ë‹¹ì—°í•˜ë‹¤ê³  ë¯¿ëŠ” ê°€ì •â€™ì„ ë°˜ëŒ€ë¡œ ë’¤ì§‘ì–´ ë³´ê¸°",
        ],
        "prompt_hint": "MECE, ê¸°ì¤€ ëª©ë¡, ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°)",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜ ì½”ì¹˜",
        "tagline": "ê°ì •ê³¼ ê°€ì¹˜ë¥¼ ë¶„ë¦¬í•´, í›„íšŒê°€ ì ì€ ê¸°ì¤€ì„ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤",
        "style": "ê°ì • ë¼ë²¨ë§/ê°€ì¹˜ ë¶„ë¦¬/í›„íšŒ ìµœì†Œí™”",
        "method": [
            "ê°ì • ë¼ë²¨ë§(ì§€ê¸ˆ ëŠë¼ëŠ” ê²ƒ) â†’ ì´ìœ ",
            "ê·¸ ê°ì •ì´ â€˜ì¼ì‹œì  í¸ì•ˆí•¨â€™ì¸ì§€ â€˜ì¥ê¸° ê°€ì¹˜â€™ì¸ì§€ ë¶„ë¦¬",
            "ê°€ì¹˜ Top3 ë„ì¶œ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸",
        ],
        "prompt_hint": "ê°ì •-ê°€ì¹˜ ë¶„ë¦¬, ê°€ì¹˜ Top3, ë¯¸ë˜ì˜ ë‚˜ ì§ˆë¬¸",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê³„íšì„ â€˜ì •ë¦¬â€™í•˜ê³ , ì˜¤ëŠ˜ 5ë¶„ Quick Winê¹Œì§€ ìŠ¤ìŠ¤ë¡œ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤(ì¶”ì²œ ê¸ˆì§€)",
        "style": "ìš°ì„ ìˆœìœ„/If-Then/í”„ë¦¬ëª¨í…œ/Quick Win",
        "method": [
            "ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°: íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ Top1~3 ì •ë¦¬",
            "ì‹¤í–‰ì„ â€˜ì–¸ì œâ€™ê°€ ì•„ë‹ˆë¼ â€˜If-Then íŠ¸ë¦¬ê±°â€™ë¡œ ì„¤ê³„",
            "ì‹¤íŒ¨ë¥¼ ë¯¸ë¦¬ ê°€ì •(í”„ë¦¬ëª¨í…œ)í•´ ë°©í•´ ìš”ì¸ì„ ë“œëŸ¬ë‚´ê¸°",
            "ë§ˆì§€ë§‰ì— â€˜ì˜¤ëŠ˜ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ ë„ì¶œ",
        ],
        "prompt_hint": "ìš°ì„ ìˆœìœ„, If-Then, í”„ë¦¬ëª¨í…œ, Quick Win",
    },
]

# Probing ê¸°ì¤€: 10ì ë¯¸ë§Œì´ë©´ 1íšŒ ì¶”ê°€ ì§ˆë¬¸
MIN_ANSWER_CHARS = 10
SHORT_ANSWER_PATTERNS = [
    r"^ëª¨ë¥´ê² ",
    r"^ì˜\s*ëª¨ë¥´",
    r"^ê·¸ëƒ¥",
    r"^ì—†ì–´",
    r"^ëª¨ë¦„$",
    r"^ã„´ã„´$",
    r"^ëª°ë¼$",
]


# =========================
# Pebble SVG (no PIL)
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    return f"""
<svg width="160" height="120" viewBox="0 0 160 120" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="pebble">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="80%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M28 80
           C14 60, 20 30, 50 20
           C66 14, 96 12, 114 24
           C142 44, 150 68, 130 88
           C112 108, 54 110, 28 80 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M54 30 C68 22, 82 22, 94 30"
        fill="none" stroke="{shine}" stroke-width="7" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_svg_b64(progress_0_to_1: float, inactive: bool = False) -> str:
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    if inactive:
        fill, shine = "#2f3136", "#6b6f7a"
    else:
        fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
        shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"
    svg = _pebble_svg(fill=fill, shine=shine)
    return base64.b64encode(svg.encode("utf-8")).decode("ascii")


def render_pebble_bridge(current_idx: int, total: int, labels: List[str]) -> None:
    total = max(2, int(total))
    current_idx = max(0, min(int(current_idx), total - 1))
    left_pct = ((current_idx + 0.5) / total) * 100.0

    pebble_imgs = []
    for i in range(total):
        active = i <= current_idx
        p = (i + 1) / total
        b64 = pebble_svg_b64(p, inactive=not active)
        pebble_imgs.append(b64)

    html = """
<style>
.pebble-bridge-wrap{
  position: relative;
  width: 100%;
  margin: 6px 0 2px 0;
  padding: 16px 4px 0 4px;
}
.pebble-row{
  display: flex;
  gap: 10px;
  align-items: flex-end;
  justify-content: space-between;
}
.pebble-cell{
  flex: 1;
  min-width: 0;
  text-align: center;
}
.pebble-img{
  width: 100%;
  max-width: 120px;
  height: auto;
  display: inline-block;
}
.pebble-label{
  font-size: 12px;
  margin-top: 4px;
  opacity: 0.85;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

/* ì‚¬ëŒ(ğŸš¶) í¬ê²Œ + ë°©í–¥ ë°˜ëŒ€ë¡œ */
.walker{
  position: absolute;
  top: -10px;
  left: VAR_LEFT%;
  transform: translateX(-50%) scaleX(-1);
  font-size: 40px;
  line-height: 1;
  transition: left 520ms cubic-bezier(.2,.9,.2,1);
  filter: drop-shadow(0px 2px 2px rgba(0,0,0,0.25));
  animation: bob 800ms ease-in-out infinite;
  user-select: none;
}
@keyframes bob{
  0%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
  50%{ transform: translateX(-50%) translateY(-3px) scaleX(-1); }
  100%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
}
</style>
<div class="pebble-bridge-wrap">
  <div class="walker">ğŸš¶</div>
  <div class="pebble-row">
    VAR_PEBBLES
  </div>
</div>
""".strip()

    pebble_cells = []
    for i in range(total):
        opacity = "1.0" if i <= current_idx else "0.55"
        cell = f"""
<div class="pebble-cell" style="opacity:{opacity}">
  <img class="pebble-img" src="data:image/svg+xml;base64,{pebble_imgs[i]}" />
  <div class="pebble-label">{labels[i] if i < len(labels) else ""}</div>
</div>
""".strip()
        pebble_cells.append(cell)

    html = html.replace("VAR_LEFT", f"{left_pct:.3f}")
    html = html.replace("VAR_PEBBLES", "\n".join(pebble_cells))
    st.markdown(html, unsafe_allow_html=True)


def render_hero_pebble(progress: float, label: str) -> None:
    b64 = pebble_svg_b64(progress, inactive=False)
    st.markdown(
        f"""
<div style="text-align:center;">
  <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:240px;"/>
  <div style="margin-top:6px; font-size:14px;">{label}</div>
</div>
""",
        unsafe_allow_html=True,
    )


# =========================
# OpenAI
# =========================
def get_api_key() -> str:
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install openai`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.6) -> Tuple[Optional[str], Optional[str], List[str]]:
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. Secretsì— OPENAI_API_KEYë¥¼ ë„£ê±°ë‚˜ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.", debug


# =========================
# State + routing
# =========================
def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def init_state() -> None:
    # pages: landing -> setup_details -> questions -> report
    if "page" not in st.session_state:
        st.session_state.page = "landing"

    # user "freeform ê³ ë¯¼" (1ë‹¨ê³„)
    if "user_problem" not in st.session_state:
        st.session_state.user_problem = ""

    # ë¶„ì„ ê²°ê³¼(2ë‹¨ê³„) + ì‚¬ìš©ìê°€ ìˆ˜ì • ê°€ëŠ¥í•œ ì„¤ì •ë“¤
    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]
    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]
    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]
    if "goal" not in st.session_state:
        st.session_state.goal = ""
    if "options" not in st.session_state:
        st.session_state.options = ""
    if "situation" not in st.session_state:
        st.session_state.situation = ""  # 2ë‹¨ê³„ì—ì„œ "ìƒí™© ì„¤ëª…" í¸ì§‘ìš©(ê¸°ë³¸ì€ user_problemì„ ë³µì‚¬)

    if "num_questions" not in st.session_state:
        st.session_state.num_questions = 5

    # ì§ˆë¬¸ ì§„í–‰ ìƒíƒœ
    if "q_index" not in st.session_state:
        st.session_state.q_index = 0
    if "questions" not in st.session_state:
        st.session_state.questions = []
    if "answers" not in st.session_state:
        st.session_state.answers = []

    # probe ìƒíƒœ
    if "probe_active" not in st.session_state:
        st.session_state.probe_active = False
    if "probe_question" not in st.session_state:
        st.session_state.probe_question = ""
    if "probe_for_index" not in st.session_state:
        st.session_state.probe_for_index = None  # type: ignore

    # cross-check ì‚¬ìš© ê¸°ë¡
    if "crosscheck_used_for" not in st.session_state:
        st.session_state.crosscheck_used_for = set()  # type: ignore

    # ë¦¬í¬íŠ¸ ìƒíƒœ
    if "final_report_json" not in st.session_state:
        st.session_state.final_report_json = None
    if "final_report_raw" not in st.session_state:
        st.session_state.final_report_raw = None
    if "report_just_entered" not in st.session_state:
        st.session_state.report_just_entered = False

    # ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤
    if "decision_matrix_df" not in st.session_state:
        st.session_state.decision_matrix_df = None

    # ë””ë²„ê·¸
    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []
    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""


def reset_flow(to_page: str = "landing", keep_problem: bool = False) -> None:
    """
    keep_problem=Trueë©´ user_problemì€ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ íë¦„ì„ ì´ˆê¸°í™”(ì‚¬ìš©ì ìœ ì‹¤ ë°©ì§€ ì˜µì…˜)
    """
    st.session_state.page = to_page

    if not keep_problem:
        st.session_state.user_problem = ""

    # setup details
    st.session_state.category = TOPIC_CATEGORIES[0][0]
    st.session_state.decision_type = DECISION_TYPES[0]
    st.session_state.coach_id = COACHES[0]["id"]
    st.session_state.goal = ""
    st.session_state.options = ""
    st.session_state.situation = st.session_state.user_problem or ""

    st.session_state.num_questions = int(st.session_state.get("num_questions", 5))

    # q flow
    st.session_state.q_index = 0
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.crosscheck_used_for = set()

    # report
    st.session_state.final_report_json = None
    st.session_state.final_report_raw = None
    st.session_state.decision_matrix_df = None
    st.session_state.report_just_entered = False
    st.session_state.debug_log = []


def add_answer(q: str, a: str, kind: str, main_index: int) -> None:
    st.session_state.answers.append(
        {"q": q, "a": a, "ts": datetime.now().isoformat(timespec="seconds"), "kind": kind, "main_index": main_index}
    )


def main_answer_count() -> int:
    return sum(1 for x in st.session_state.answers if x.get("kind") == "main")


# =========================
# Helpers
# =========================
def normalize(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


def token_overlap(a: str, b: str) -> float:
    def toks(s: str) -> set:
        s = re.sub(r"[^\wê°€-í£ ]", " ", s)
        s = re.sub(r"\s+", " ", s).strip().lower()
        return set([t for t in s.split(" ") if len(t) >= 2])

    ta, tb = toks(a), toks(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    denom = max(1, min(len(ta), len(tb)))
    return inter / denom


def is_similar(a: str, b: str) -> bool:
    a0, b0 = normalize(a), normalize(b)
    if not a0 or not b0:
        return False
    if a0 == b0:
        return True
    if a0 in b0 or b0 in a0:
        return True
    return token_overlap(a0, b0) >= 0.75


def is_too_short_answer(ans: str) -> bool:
    a = (ans or "").strip()
    if len(a) < MIN_ANSWER_CHARS:
        return True
    for pat in SHORT_ANSWER_PATTERNS:
        if re.search(pat, a):
            return True
    return False


def parse_options() -> List[str]:
    return [o.strip() for o in (st.session_state.options or "").split(",") if o.strip()]


# =========================
# Onboarding: AI ë¶„ì„/ì¶”ì²œ(2ë‹¨ê³„)
# =========================
def system_prompt_for_onboarding() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì˜¨ë³´ë”© ë¶„ì„ê¸°ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìì˜ ê³ ë¯¼ í…ìŠ¤íŠ¸ë¥¼ ì½ê³ , ì•„ë˜ í•­ëª©ì„ 'ì¶”ì²œ'í•˜ë˜, ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì¶”ì²œì€ 'ë¶„ë¥˜/ì´ˆì•ˆ ì œì•ˆ' ìˆ˜ì¤€ì´ë©° ì‚¬ìš©ìê°€ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ(ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€).\n"
    )


def user_prompt_for_onboarding(problem_text: str) -> str:
    cats = [c[0] for c in TOPIC_CATEGORIES]
    coaches = [{"id": c["id"], "name": c["name"], "tagline": c["tagline"]} for c in COACHES]
    dtypes = DECISION_TYPES

    return textwrap.dedent(
        f"""
        [ì‚¬ìš©ì ê³ ë¯¼]
        {problem_text}

        [ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬]
        {cats}

        [ê°€ëŠ¥í•œ ê²°ì • ìœ í˜•]
        {dtypes}

        [ê°€ëŠ¥í•œ ì½”ì¹˜]
        {coaches}

        ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:
        {{
          "recommended_category": "string (cats ì¤‘ í•˜ë‚˜)",
          "recommended_decision_type": "string (dtypes ì¤‘ í•˜ë‚˜)",
          "recommended_coach_id": "string (logic|value|action)",
          "coach_reason": "string (ì§§ê²Œ, ì™œ ì´ ì½”ì¹˜ê°€ ë§ëŠ”ì§€)",
          "goal_draft": "string (ì‚¬ìš©ìê°€ ì–»ê³  ì‹¶ì–´ í•  ë²•í•œ 'ì›í•˜ëŠ” ëª©í‘œ' ì´ˆì•ˆ, ì§€ì‹œ/ì¶”ì²œ ê¸ˆì§€ í‘œí˜„)",
          "options_hint": "string (ì˜µì…˜ì´ ìˆì„ ìˆ˜ë„ ìˆìŒì„ ìƒê¸°ì‹œí‚¤ëŠ” ì§§ì€ ì§ˆë¬¸í˜• íŒíŠ¸. ì—†ë‹¤ë©´ ë¹ˆ ë¬¸ìì—´ ê°€ëŠ¥)"
        }}

        ê·œì¹™:
        - ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ/ê°•ìš” ê¸ˆì§€
        - goal_draftëŠ” 'ì‚¬ìš©ìê°€ ë°”ê¿€ ìˆ˜ ìˆëŠ” ì´ˆì•ˆ'ì„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚˜ê²Œ
        """
    ).strip()


def generate_onboarding_recommendation(problem_text: str) -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    system = system_prompt_for_onboarding()
    user = user_prompt_for_onboarding(problem_text)
    txt, err, dbg = call_openai_text(system=system, user=user, temperature=0.2)
    if not txt:
        return None, err, dbg, None

    data = safe_json_parse(txt)
    if not data:
        return None, "ì˜¨ë³´ë”© ì¶”ì²œ JSON íŒŒì‹± ì‹¤íŒ¨", dbg, txt

    return data, None, dbg, txt


# =========================
# Question generation (ê¸°ì¡´ ìœ ì§€)
# =========================
def system_prompt_for_questions(coach: Dict[str, Any]) -> str:
    base = (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì •ë‹µ/í•´ê²°ì±…/ì¶”ì²œì„ ì£¼ì§€ ë§ê³ , ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ì§ˆë¬¸ë§Œ ë˜ì§€ì„¸ìš”.\n"
        "ê¸ˆì§€: ê²°ë¡ , ì¶”ì²œ, ì„ íƒ ê°•ìš”, íŒë‹¨ë¬¸(ì˜ˆ: Aê°€ ë‚«ë‹¤), ì§€ì‹œë¬¸(í•´ì•¼ í•œë‹¤/í•˜ì).\n"
        "ì¶œë ¥: ì§ˆë¬¸ 1ê°œë§Œ. (ì„¤ëª…/ë²ˆí˜¸/ë¨¸ë¦¬ë§ ê¸ˆì§€)\n"
    )
    if coach["id"] == "logic":
        return base + "ìŠ¤íƒ€ì¼: êµ¬ì¡°í™”/ê¸°ì¤€/ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°) ì§ˆë¬¸.\n"
    if coach["id"] == "value":
        return base + "ìŠ¤íƒ€ì¼: ê°ì • ë¼ë²¨ë§ + ê°ì •/ê°€ì¹˜ ë¶„ë¦¬ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸.\n"
    return base + "ìŠ¤íƒ€ì¼: If-Then íŠ¸ë¦¬ê±°/í”„ë¦¬ëª¨í…œ/ìš°ì„ ìˆœìœ„/Quick Winì„ ëª¨ë‘ ì§ˆë¬¸ìœ¼ë¡œë§Œ ìœ ë„.\n"


def build_context_block() -> str:
    hist = ""
    tail = st.session_state.answers[-6:]
    for i, qa in enumerate(tail, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        hist += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"

    opts = parse_options()
    opts_txt = "\n".join([f"- {o}" for o in opts]) if opts else "(ë¯¸ì…ë ¥)"

    return textwrap.dedent(
        f"""
        [ì„¸ì…˜ ì‹œì‘ ì •ë³´]
        - ì¹´í…Œê³ ë¦¬: {st.session_state.category}
        - ê²°ì • ìœ í˜•: {st.session_state.decision_type}
        - ìƒí™© ì„¤ëª…: {st.session_state.situation or "(ë¯¸ì…ë ¥)"}
        - ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal or "(ë¯¸ì…ë ¥)"}
        - ê³ ë ¤ ì˜µì…˜(ìˆë‹¤ë©´): {opts_txt}

        [ìµœê·¼ Q/A]
        {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
        """
    ).strip()


def probing_instruction(last_q: str, last_a: str) -> str:
    return textwrap.dedent(
        f"""
        ì‚¬ìš©ìì˜ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª¨í˜¸í•©ë‹ˆë‹¤.
        ì•„ë˜ì˜ ì§ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ êµ¬ì²´í™”í•  ìˆ˜ ìˆë„ë¡ ë”± 1ê°œì˜ ì¶”ê°€ ì§ˆë¬¸(Probe)ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

        - ì§ì „ ì§ˆë¬¸: {last_q}
        - ì§ì „ ë‹µë³€: {last_a}

        ìš”êµ¬ì‚¬í•­:
        - 'êµ¬ì²´í™”'ë¥¼ ë•ëŠ” ì§ˆë¬¸(ì˜ˆ: ì˜ˆì‹œ/ìƒí™©/ê¸°ì¤€/ì´ìœ /ë²”ìœ„/ê¸°ê°„/ìš°ì„ ìˆœìœ„ ì¤‘ í•˜ë‚˜ë¥¼ ë” ë¬»ê¸°)
        - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ ê¸ˆì§€
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
        """
    ).strip()


def crosscheck_system_prompt() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ë…¼ë¦¬ ì¶©ëŒ ê°ì§€ê¸°ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìì˜ ì´ì „ ë‹µë³€ë“¤ ì‚¬ì´ì— 'ìš°ì„ ìˆœìœ„/ê¸°ì¤€/ëª©í‘œ'ê°€ ì„œë¡œ ì¶©ëŒí•˜ëŠ”ì§€ ì ê²€í•˜ì„¸ìš”.\n"
        "ì¤‘ìš”: ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”. ì§ˆë¬¸ì„ ë§Œë“¤ ë•Œë„ ê°•ìš”/íŒë‹¨ ê¸ˆì§€.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ. (ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€)\n"
    )


def crosscheck_user_prompt(current_main_index: int) -> str:
    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    tail = mains[-6:]
    qa = ""
    for i, x in enumerate(tail, start=1):
        qa += f"{i}) Q: {x['q']}\n   A: {x['a']}\n"

    return textwrap.dedent(
        f"""
        ì•„ë˜ëŠ” ì‚¬ìš©ì ë‹µë³€ ì¼ë¶€ì…ë‹ˆë‹¤. ë‹µë³€ë“¤ ì‚¬ì´ì— ë…¼ë¦¬ì  ì¶©ëŒ(ê¸°ì¤€/ìš°ì„ ìˆœìœ„ì˜ ìƒì¶©)ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.
        ì¶©ëŒì´ ìˆë‹¤ë©´, ê·¸ ì¶©ëŒì„ ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ 'ì •ë¦¬'í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì œì•ˆí•˜ì„¸ìš”.
        ì¶©ëŒì´ ì—†ë‹¤ë©´ has_conflict=falseë¡œ ë‘ì„¸ìš”.

        [ë‹µë³€ë“¤]
        {qa if qa.strip() else "(ë‹µë³€ ì—†ìŒ)"}

        [ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]
        {{
          "has_conflict": true/false,
          "conflict_summary": "string (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
          "question": "string (has_conflict=trueì¼ ë•Œë§Œ, ì§ˆë¬¸ 1ê°œ)"
        }}

        ì¶”ê°€ ê·œì¹™:
        - questionì€ ì§ˆë¬¸ 1ê°œë§Œ(ë¬¼ìŒí‘œ í¬í•¨ ê¶Œì¥)
        - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ/ì„ íƒ ê°•ìš” ê¸ˆì§€
        - ê°™ì€ ë‚´ìš©ì„ ë°˜ë³µí•˜ì§€ ì•Šê²Œ ê°„ê²°í•˜ê²Œ
        - current_main_index={current_main_index}
        """
    ).strip()


def safe_json_parse(text: str) -> Optional[Dict[str, Any]]:
    if not text:
        return None
    t = text.strip()
    if not t.startswith("{"):
        m = re.search(r"\{.*\}", t, flags=re.S)
        if m:
            t = m.group(0).strip()
    try:
        return json.loads(t)
    except Exception:
        return None


def try_logic_crosscheck_question(main_index: int) -> Tuple[Optional[str], List[str]]:
    dbg: List[str] = []
    if main_index in st.session_state.crosscheck_used_for:
        return None, dbg

    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    if len(mains) < 2:
        return None, dbg

    system = crosscheck_system_prompt()
    user = crosscheck_user_prompt(main_index)
    txt, err, d = call_openai_text(system=system, user=user, temperature=0.2)
    dbg.extend(d)
    if not txt:
        if err:
            dbg.append(f"Crosscheck error: {err}")
        return None, dbg

    data = safe_json_parse(txt)
    if not data:
        dbg.append("Crosscheck JSON parse failed.")
        return None, dbg

    has_conflict = bool(data.get("has_conflict", False))
    q = normalize(str(data.get("question", "") or ""))

    st.session_state.crosscheck_used_for.add(main_index)

    if has_conflict and q:
        dbg.append("Crosscheck conflict detected -> using conflict question.")
        return q, dbg

    dbg.append("Crosscheck: no conflict (or no question).")
    return None, dbg


def instruction_for_question(i: int, n: int, coach_id: str) -> str:
    if i == 0:
        return "ìƒí™©ì˜ í•µì‹¬ì„ ë” êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
    if i == 1:
        return "ì›í•˜ëŠ” ëª©í‘œë¥¼ ì¸¡ì • ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "action":
        if i == n - 1:
            return "â€˜ì§€ê¸ˆ ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ì„ ìŠ¤ìŠ¤ë¡œ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ(Quick Win, ì¶”ì²œ ê¸ˆì§€)"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ í¼ì¹˜ê³  Top1~3 ìš°ì„ ìˆœìœ„ë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸(íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ì„ ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œ)"
        if n >= 6 and i == 3:
            return "Top1ì„ â€˜1ë…„â†’ì´ë²ˆ ë‹¬â†’ì´ë²ˆ ì£¼â€™ë¡œ ìª¼ê°œ ì‚¬ìš©ìê°€ ê³„íšì„ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ(ì§€ì‹œ ê¸ˆì§€)"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return (
                "í”„ë¦¬ëª¨í…œ(Pre-mortem) + If-Then íŠ¸ë¦¬ê±° ì„¤ê³„ ì§ˆë¬¸ 1ê°œ. "
                "ì˜ˆ: â€˜2ì£¼ ë’¤ ì‹¤íŒ¨í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ 3ê°€ì§€ëŠ”?â€™ "
                "ê·¸ë¦¬ê³  ê° ì›ì¸ì— ëŒ€í•´ â€˜ë§Œì•½ (If) ~ ìƒí™©ì´ë©´ â†’ (Then) ~ í–‰ë™â€™ìœ¼ë¡œ ëŒ€ì‘ì„ ì ê²Œ í•˜ê¸°"
            )
        if n >= 6 and i == 4:
            return "ì‹¤í–‰ì„ â€˜ì–¸ì œâ€™ê°€ ì•„ë‹ˆë¼ â€˜If(ì–´ë–¤ ìƒí™©) â†’ Then(ì–´ë–¤ í–‰ë™)â€™ìœ¼ë¡œ ì„¤ê³„í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(íŠ¸ë¦¬ê±° 2~3ê°œ)"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ì¡°ê±´ì—ì„œ)í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "logic":
        if n >= 5 and i == n - 2:
            return "ì—­ë°œìƒ/ë°˜ëŒ€ ìƒí™© ê°€ì • ì§ˆë¬¸ 1ê°œ."
        if i == 2:
            return "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        if i == n - 2 and n < 5:
            return "ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì¶”ê°€ë¡œ í™•ì¸í•  ì •ë³´ 1~2ê°œë¥¼ ë“œëŸ¬ë‚´ëŠ” ì§ˆë¬¸ 1ê°œ"
        return "ì˜µì…˜/ì •ë³´/ì œì•½ì„ ë” ë¶„ë¦¬í•´ ëª…ë£Œí™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    if coach_id == "value":
        if i == 2:
            return "ì§€ê¸ˆ ê°ì •(2~3ê°œ)ê³¼ ê·¸ ê°ì •ì˜ ì´ìœ ë¥¼ ë§í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == 3 and n >= 5:
            return "ê°ì •ê³¼ ê°€ì¹˜ì˜ ë¶„ë¦¬ ì§ˆë¬¸ 1ê°œ."
        if i == n - 2:
            return "í›„íšŒ ìµœì†Œí™” ê´€ì (1ë…„/5ë…„ í›„)ì„ ì ê²€í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ â€˜ë‚´ ê¸°ì¤€â€™ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        return "ê°€ì¹˜ Top3(ë‚´ê²Œ ì¤‘ìš”í•œ ê²ƒ)ì™€ ë‚´ë ¤ë†“ì„ ê²ƒ 1ê°œë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    return "ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œ"


def fallback_question(coach_id: str, i: int, n: int) -> str:
    if i == 0:
        return "ì§€ê¸ˆ ê³ ë¯¼ì—ì„œ â€˜ê°€ì¥ í•µì‹¬ì ì¸ ìŸì â€™ì€ ë¬´ì—‡ì¸ê°€ìš”? (í•œ ë¬¸ì¥)"
    if i == 1:
        return "ì´ë²ˆ ê²°ì •ìœ¼ë¡œ ì–»ê³  ì‹¶ì€ ëª©í‘œë¥¼ â€˜ì¸¡ì • ê°€ëŠ¥í•˜ê²Œâ€™ ë°”ê¾¸ë©´ ì–´ë–»ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‚˜ìš”? (ì–¸ì œê¹Œì§€/ì–´ëŠ ì •ë„)"

    if coach_id == "action":
        if i == n - 1:
            return "ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” â€˜ê°€ì¥ ì‘ì€ í–‰ë™â€™ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ ì ê³ , íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return "2ì£¼ ë’¤ ì‹¤íŒ¨í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ 3ê°€ì§€ëŠ” ë¬´ì—‡ì´ê³  ê°ê° â€˜ë§Œì•½ ~ì´ë©´ â†’ ~í•œë‹¤â€™ë¡œ ëŒ€ì‘ì„ ì ì–´ë³¼ ìˆ˜ ìˆë‚˜ìš”?"
        if n >= 6 and i == 3:
            return "Top1ì„ â€˜1ë…„ ëª©í‘œ â†’ ì´ë²ˆ ë‹¬ ëª©í‘œ â†’ ì´ë²ˆ ì£¼ ê³„íš(3ê°œ)â€™ë¡œ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if n >= 6 and i == 4:
            return "ì‹¤í–‰ì„ â€˜ë§Œì•½(If) ~ ìƒí™©ì´ë©´ â†’ ê·¸ëŸ¬ë©´(Then) ~ í–‰ë™â€™ìœ¼ë¡œ íŠ¸ë¦¬ê±° 2~3ê°œë¥¼ ë§Œë“¤ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”í•˜ë©´(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ì¡°ê±´ì—ì„œ) ì–´ë–»ê²Œ ì ì„ ìˆ˜ ìˆë‚˜ìš”?"

    if coach_id == "logic":
        if n >= 5 and i == n - 2:
            return "ë§Œì•½ ë‹¹ì‹ ì´ ì„¸ìš´ ê¸°ì¤€ì´ ì™„ì „íˆ í‹€ë ¸ë‹¤ë©´ ì–´ë–¤ ìƒí™©ì´ ë²Œì–´ì§ˆê¹Œìš”?"
        if i == 2:
            return "ì´ ì„ íƒì„ í‰ê°€í•  ê¸°ì¤€ 3~5ê°œë¥¼ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 1:
            return "ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 2 and n < 5:
            return "ì§€ê¸ˆ ê²°ì •ì„ ì–´ë µê²Œ ë§Œë“œëŠ” â€˜ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì •ë³´â€™ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        return "ì˜µì…˜/ì œì•½/ì •ë³´ë¥¼ ë¶„ë¦¬í•´ì„œ ì§€ê¸ˆ ë¶€ì¡±í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ì§€ ì ì–´ë³¼ê¹Œìš”?"

    if i == 2:
        return "ì§€ê¸ˆ ê°ì •ì„ 2~3ê°œ ë‹¨ì–´ë¡œ ì ê³ , ê° ê°ì •ì´ ìƒê¸´ ì´ìœ ë¥¼ í•œ ì¤„ì”© ì¨ë³¼ê¹Œìš”?"
    if i == 3 and n >= 5:
        return "ê·¸ ê°ì •ì€ â€˜ì§€ê¸ˆ ë‹¹ì¥ì˜ í¸ì•ˆí•¨â€™ ë•Œë¬¸ì¸ê°€ìš”, â€˜ë¯¸ë˜ì˜ ë‚˜ë¥¼ ìœ„í•œ ê°€ì¹˜â€™ ë•Œë¬¸ì¸ê°€ìš”?"
    if i == n - 2:
        return "1ë…„/5ë…„ ë’¤ì˜ ë‚´ê°€ ì§€ê¸ˆì˜ ë‚˜ì—ê²Œ ë­ë¼ê³  ë§í•´ì¤„ ê²ƒ ê°™ë‚˜ìš”?"
    return "ì´ ê³ ë¯¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°€ì¹˜ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"


def generate_question(i: int, n: int) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    prev_qs = st.session_state.questions[:]

    cross_q, cross_dbg = try_logic_crosscheck_question(i)
    if cross_q and not any(is_similar(cross_q, pq) for pq in prev_qs):
        return cross_q, None, cross_dbg

    dbg_acc: List[str] = cross_dbg[:]

    def prompt(nonce: int) -> str:
        prev_txt = "\n".join([f"- {q}" for q in prev_qs]) if prev_qs else "(ì—†ìŒ)"
        return textwrap.dedent(
            f"""
            [ì´ì „ ì§ˆë¬¸ ëª©ë¡]
            {prev_txt}

            {build_context_block()}

            [ì´ë²ˆ ì§ˆë¬¸ ëª©ì ]
            {instruction_for_question(i, n, coach["id"])}

            ê·œì¹™:
            - ê²°ë¡ /ì¶”ì²œ/ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
            - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
            - ì´ì „ ì§ˆë¬¸ê³¼ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ í”¼í•˜ê¸°

            (nonce={nonce})
            """
        ).strip()

    q1, err, dbg = call_openai_text(system=system, user=prompt(random.randint(1000, 9999)), temperature=0.7)
    dbg_acc.extend(dbg)
    if not q1:
        return fallback_question(coach["id"], i, n), err, dbg_acc

    q1 = normalize(q1)
    if not any(is_similar(q1, pq) for pq in prev_qs):
        return q1, None, dbg_acc

    dbg_acc.append("Similar question detected. Regenerating once.")
    q2, err2, dbg2 = call_openai_text(system=system, user=prompt(random.randint(10000, 99999)), temperature=0.85)
    dbg_acc.extend(dbg2)
    if q2:
        q2 = normalize(q2)
        if not any(is_similar(q2, pq) for pq in prev_qs):
            return q2, None, dbg_acc

    dbg_acc.append("Still similar after retry. Using fallback.")
    return fallback_question(coach["id"], i, n), err2, dbg_acc


def ensure_question(index: int, total: int) -> None:
    while len(st.session_state.questions) <= index:
        i = len(st.session_state.questions)
        q, err, dbg = generate_question(i, total)
        st.session_state.debug_log = dbg
        st.session_state.questions.append(q)


def generate_probe_question(last_q: str, last_a: str) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    user = probing_instruction(last_q, last_a)
    q, err, dbg = call_openai_text(system=system, user=user, temperature=0.6)
    if not q:
        return "ë°©ê¸ˆ ë‹µë³€ì—ì„œ â€˜ì˜ˆì‹œ 1ê°œâ€™ë§Œ ë“¤ì–´ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì„¤ëª…í•´ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?", err, dbg
    return normalize(q), None, dbg


# =========================
# Report generation (ê¸°ì¡´ ìœ ì§€)
# =========================
FORBIDDEN_RECOMMEND_PATTERNS = [
    r"ì¶”ì²œ",
    r"~?í•˜ëŠ” ê²ƒì´ ì¢‹",
    r"í•´ì•¼ í•©ë‹ˆë‹¤",
    r"í•˜ì‹œê¸¸",
    r"í•˜ëŠ” ê²Œ ë‚«",
    r"Aë¥¼ ì„ íƒ",
    r"Bë¥¼ ì„ íƒ",
    r"ì •ë‹µ",
    r"ê²°ë¡ ",
]


def contains_forbidden_recommendation(text: str) -> bool:
    t = text or ""
    for pat in FORBIDDEN_RECOMMEND_PATTERNS:
        if re.search(pat, t):
            return True
    return False


def report_schema_hint(coach_id: str) -> str:
    base = """
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”(ì½”ë“œë¸”ë¡/ì„¤ëª… ê¸ˆì§€).
ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.
coaching_messageëŠ” ë°˜ë“œì‹œ "ê±°ìš¸ ë¹„ì¶”ê¸°(Mirroring)" í™”ë²•ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
ê¸ˆì§€ í‘œí˜„: "ì¶”ì²œ", "ì¢‹ê² ìŠµë‹ˆë‹¤", "í•´ì•¼ í•©ë‹ˆë‹¤", "í•˜ì", "ì •ë‹µ", "ê²°ë¡ ", "Aë¥¼ ì„ íƒ".
"""
    if coach_id == "action":
        return textwrap.dedent(
            base
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue": "string",
    "goal": "string",
    "constraints": ["string"],
    "options_mentioned": ["string"]
  },
  "criteria": [
    {"name":"string","priority":1-5,"why":"string"}
  ],
  "plan_visualization": {
    "year": "string",
    "month": "string",
    "week": ["string","string","string"]
  },
  "weekly_table": {
    "Mon": ["string"], "Tue": ["string"], "Wed": ["string"], "Thu": ["string"],
    "Fri": ["string"], "Sat": ["string"], "Sun": ["string"]
  },
  "coaching_message": ["string","string"],
  "next_self_question": "string"
}
"""
        ).strip()

    if coach_id == "logic":
        return textwrap.dedent(
            base
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "key_points": {"uncertainties":["string"], "tradeoffs":["string"]},
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
        ).strip()

    return textwrap.dedent(
        base
        + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "emotions_values": {"emotions":["string","string"], "top_values":["string","string","string"]},
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
    ).strip()


def system_prompt_for_report() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ìµœì¢… ìš”ì•½ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì˜¤ì§ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬/ê¸°ì¤€/ê¸´ì¥/ë¶ˆí™•ì‹¤ì„±ì„ ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)í•˜ì„¸ìš”.\n"
        "coaching_messageëŠ” ë°˜ë“œì‹œ ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.\n"
    )


def build_qa_text_for_report() -> str:
    qa_text = ""
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        qa_text += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"
    return qa_text


def generate_final_report_json() -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_report()

    qa_text = build_qa_text_for_report()
    opts = parse_options()

    user = textwrap.dedent(
        f"""
{report_schema_hint(coach["id"])}

[ì„¸ì…˜ ì‹œì‘ ì •ë³´]
- ì¹´í…Œê³ ë¦¬: {st.session_state.category}
- ê²°ì • ìœ í˜•: {st.session_state.decision_type}
- ìƒí™© ì„¤ëª…: {st.session_state.situation}
- ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal}
- ì˜µì…˜(ìˆë‹¤ë©´): {opts if opts else "(ì—†ìŒ)"}

[Q/A]
{qa_text}

ì¤‘ìš”:
- ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
- coaching_messageëŠ” ê±°ìš¸ ë¹„ì¶”ê¸°ë§Œ
- ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ê³„íšì„ â€˜ì§€ì–´ë‚´ì§€â€™ ë§ˆì„¸ìš”
"""
    ).strip()

    text, err, dbg = call_openai_text(system=system, user=user, temperature=0.25)
    if not text:
        return None, err, dbg, None

    data = safe_json_parse(text)
    if data is None:
        return None, "ë¦¬í¬íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨(ëª¨ë¸ì´ JSONë§Œ ì¶œë ¥í•˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ)", dbg, text

    combined = json.dumps(data, ensure_ascii=False)
    if contains_forbidden_recommendation(combined):
        dbg.append("Forbidden recommendation-like phrasing detected. Regenerating once with stricter warning.")
        stricter_user = user + "\n\n[ê²½ê³ ] ì´ì „ ì¶œë ¥ì— ì¶”ì²œ/ì§€ì‹œ í‘œí˜„ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ê³  ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
        text2, err2, dbg2 = call_openai_text(system=system, user=stricter_user, temperature=0.1)
        dbg.extend(dbg2)
        if text2:
            data2 = safe_json_parse(text2)
            if data2 is not None and not contains_forbidden_recommendation(json.dumps(data2, ensure_ascii=False)):
                return data2, None, dbg, text2
        dbg.append("Regeneration did not fully remove forbidden phrasing.")
        return data, None, dbg, text

    return data, None, dbg, text


# =========================
# Report rendering + matrix + mirroring + export (ê¸°ì¡´ ìœ ì§€)
# =========================
def render_summary_block(data: Dict[str, Any]) -> None:
    s = data.get("summary", {}) or {}
    st.subheader("ê³ ë¯¼ì˜ í•µì‹¬ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.write(f"**í•µì‹¬ ê³ ë¯¼:** {s.get('core_issue','')}")
        st.write(f"**ëª©í‘œ:** {s.get('goal','')}")
    with c2:
        cons = s.get("constraints", []) or []
        opts = s.get("options_mentioned", []) or []
        st.write("**ì œì•½/ì¡°ê±´:**")
        if cons:
            for x in cons:
                st.write(f"- {x}")
        else:
            st.caption("ì œì•½ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        st.write("**ì–¸ê¸‰ëœ ì˜µì…˜:**")
        if opts:
            for x in opts:
                st.write(f"- {x}")
        else:
            st.caption("ì˜µì…˜ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")


def render_criteria(data: Dict[str, Any]) -> List[str]:
    st.subheader("ì„ íƒ ê¸°ì¤€ ì •ë¦¬(ìš°ì„ ìˆœìœ„ í¬í•¨)")
    crit = data.get("criteria", []) or []
    if not crit:
        st.caption("ì„ íƒ ê¸°ì¤€ì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
        return []
    rows = []
    names: List[str] = []
    for c in crit:
        nm = str(c.get("name", "") or "").strip()
        if nm:
            names.append(nm)
        rows.append({"ê¸°ì¤€": nm, "ìš°ì„ ìˆœìœ„(1~5)": c.get("priority", ""), "ì™œ ì¤‘ìš”í•œê°€": c.get("why", "")})
    st.dataframe(rows, use_container_width=True, hide_index=True)
    return names


def render_action_visualization(data: Dict[str, Any]) -> None:
    st.subheader("ê³„íš ì •ë¦¬(ë…„ â†’ ë‹¬ â†’ ì£¼) â€” ì‚¬ìš©ì ë‹µë³€ ê¸°ë°˜")
    pv = data.get("plan_visualization", {}) or {}
    c1, c2, c3 = st.columns(3)
    c1.metric("ë…„", pv.get("year", "") or "-")
    c2.metric("ë‹¬", pv.get("month", "") or "-")
    c3.metric("ì£¼(í•µì‹¬ 3ê°œ)", " ")

    week = pv.get("week", []) or []
    if week:
        for x in week:
            st.write(f"- {x}")
    else:
        st.caption("ì‚¬ìš©ì ë‹µë³€ì—ì„œ ì£¼ ë‹¨ìœ„ ê³„íšì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")

    st.subheader("ì£¼ê°„ í…Œì´ë¸”(ì •ë¦¬ìš©)")
    cal = data.get("weekly_table", {}) or {}
    days = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
    table = [{"Day": d, "Tasks": "\n".join(cal.get(d, []) or [])} for d in days]
    st.dataframe(table, use_container_width=True, hide_index=True)


def render_key_points_logic(data: Dict[str, Any]) -> None:
    kp = data.get("key_points", {}) or {}
    st.subheader("ì •ë¦¬ í¬ì¸íŠ¸")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„(ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ê²ƒ)**")
        for x in kp.get("uncertainties", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**íŠ¸ë ˆì´ë“œì˜¤í”„(ì–»ëŠ” ê²ƒ vs ìƒëŠ” ê²ƒ)**")
        for x in kp.get("tradeoffs", []) or []:
            st.write(f"- {x}")


def render_emotions_values(data: Dict[str, Any]) -> None:
    ev = data.get("emotions_values", {}) or {}
    st.subheader("ê°ì •/ê°€ì¹˜ ì •ë¦¬")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ê°ì •**")
        for x in ev.get("emotions", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**ê°€ì¹˜ Top3**")
        for x in ev.get("top_values", []) or []:
            st.write(f"- {x}")


def render_coaching_message(data: Dict[str, Any]) -> None:
    st.subheader("ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    msgs = data.get("coaching_message", []) or []
    for m in msgs:
        st.write(f"- {m}")


def render_next_question(data: Dict[str, Any]) -> None:
    st.subheader("ë‹¤ìŒì— ìŠ¤ìŠ¤ë¡œì—ê²Œ ë˜ì§ˆ ì§ˆë¬¸(1ê°œ)")
    st.write(f"**{data.get('next_self_question','')}**")


STOPWORDS = {
    "ê·¸ëƒ¥",
    "ë„ˆë¬´",
    "ì§„ì§œ",
    "ê·¼ë°",
    "ê·¸ë¦¬ê³ ",
    "ê·¸ë˜ì„œ",
    "í•˜ì§€ë§Œ",
    "ì œê°€",
    "ì €ëŠ”",
    "ë‚˜ëŠ”",
    "ë‚´ê°€",
    "ì´ê²Œ",
    "ê·¸ê²Œ",
    "ì €",
    "ê²ƒ",
    "ìˆ˜",
    "ì¢€",
    "ì•½ê°„",
    "ë•Œë¬¸",
    "ë•Œë¬¸ì—",
    "ê°™ì•„ìš”",
    "ê°™ì€",
    "í•˜ëŠ”",
    "í•´ì•¼",
    "í•˜ê³ ",
    "ìˆëŠ”",
    "ìˆë‹¤",
    "ì—†ë‹¤",
    "ì—†ì–´ìš”",
    "ëª¨ë¥´ê² ",
    "ëª¨ë¥´ê² ì–´ìš”",
}

EMOTION_WORDS = [
    "ë¶ˆì•ˆ",
    "ë‘ë ¤ì›€",
    "ê±±ì •",
    "ê¸´ì¥",
    "ë‹µë‹µ",
    "í›„íšŒ",
    "ì£„ì±…ê°",
    "ë¶€ë‹´",
    "ìŠ¤íŠ¸ë ˆìŠ¤",
    "ìš°ìš¸",
    "ì§œì¦",
    "í™”",
    "ë¶„ë…¸",
    "ì„¤ë ˜",
    "ê¸°ëŒ€",
    "ì•ˆë„",
    "í¸ì•ˆ",
    "í–‰ë³µ",
    "ì˜ìš•",
    "ì§€ì¹¨",
    "ë²ˆì•„ì›ƒ",
]


def analyze_mirroring_from_answers() -> Tuple[pd.DataFrame, pd.DataFrame]:
    text = " ".join([str(x.get("a", "")) for x in st.session_state.answers if x.get("a")])
    clean = re.sub(r"[^\wê°€-í£ ]", " ", text)
    clean = re.sub(r"\s+", " ", clean).strip().lower()

    toks = [t for t in clean.split(" ") if len(t) >= 2 and t not in STOPWORDS]
    freq: Dict[str, int] = {}
    for t in toks:
        freq[t] = freq.get(t, 0) + 1
    kw = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:10]
    kw_df = pd.DataFrame(kw, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„"])

    emo_freq: Dict[str, int] = {}
    for ew in EMOTION_WORDS:
        c = len(re.findall(re.escape(ew), text))
        if c > 0:
            emo_freq[ew] = c
    emo = sorted(emo_freq.items(), key=lambda x: x[1], reverse=True)[:10]
    emo_df = pd.DataFrame(emo, columns=["ê°ì •ì–´", "ë¹ˆë„"])
    return kw_df, emo_df


def render_mirroring_visual() -> None:
    st.subheader("ë‚´ë©´ì˜ ëª©ì†Œë¦¬(Mirroring) â€” ë‹µë³€ì—ì„œ ë§ì´ ë“±ì¥í•œ í‘œí˜„")
    kw_df, emo_df = analyze_mirroring_from_answers()

    c1, c2 = st.columns(2)
    with c1:
        st.write("**ìì£¼ ë“±ì¥í•œ í‚¤ì›Œë“œ(Top 10)**")
        if len(kw_df) == 0:
            st.caption("í‚¤ì›Œë“œê°€ ì¶©ë¶„íˆ ì¡íˆì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(kw_df, use_container_width=True, hide_index=True)
            st.bar_chart(kw_df.set_index("í‚¤ì›Œë“œ")["ë¹ˆë„"])
    with c2:
        st.write("**ê°ì •ì–´(Top 10)**")
        if len(emo_df) == 0:
            st.caption("ëšœë ·í•œ ê°ì •ì–´ê°€ ë§ì´ ë“±ì¥í•˜ì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(emo_df, use_container_width=True, hide_index=True)
            st.bar_chart(emo_df.set_index("ê°ì •ì–´")["ë¹ˆë„"])

    st.caption("ì´ ê²°ê³¼ëŠ” â€˜ì •ë‹µâ€™ì´ ì•„ë‹ˆë¼, ë‹¹ì‹ ì˜ ë‹µë³€ì— ë‚˜íƒ€ë‚œ ë°˜ë³µ í‘œí˜„ì„ ìš”ì•½í•œ ê±°ìš¸ì…ë‹ˆë‹¤.")


def build_decision_matrix(options: List[str], criteria_names: List[str]) -> pd.DataFrame:
    if not options:
        options = ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]
    if not criteria_names:
        criteria_names = ["ê¸°ì¤€ 1", "ê¸°ì¤€ 2", "ê¸°ì¤€ 3"]

    cols = ["ì˜µì…˜"] + criteria_names + ["ë©”ëª¨"]
    rows = []
    for opt in options:
        r = {"ì˜µì…˜": opt, "ë©”ëª¨": ""}
        for c in criteria_names:
            r[c] = 3
        rows.append(r)
    return pd.DataFrame(rows, columns=cols)


def render_decision_matrix(criteria_names: List[str], data: Dict[str, Any]) -> None:
    st.subheader("ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(ì§ì ‘ ì ìˆ˜ ë§¤ê¸°ê¸°)")
    st.caption("ê° ì˜µì…˜ì´ â€˜ë‚´ ê¸°ì¤€â€™ì—ì„œ ì–´ëŠ ì •ë„ì¸ì§€ 1~5ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”. ì ìˆ˜ëŠ” ê²°ë¡ ì´ ì•„ë‹ˆë¼ ìƒê°ì„ êº¼ë‚´ëŠ” ë„êµ¬ì˜ˆìš”.")

    user_opts = parse_options()
    report_opts = (data.get("summary", {}) or {}).get("options_mentioned", []) or []
    opts = user_opts or [str(x) for x in report_opts if str(x).strip()] or ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]

    if st.session_state.decision_matrix_df is None:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)

    df: pd.DataFrame = st.session_state.decision_matrix_df

    existing_opts = [str(x) for x in df["ì˜µì…˜"].tolist()] if "ì˜µì…˜" in df.columns else []
    if set(existing_opts) != set(opts):
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    desired_cols = ["ì˜µì…˜"] + (criteria_names or []) + ["ë©”ëª¨"]
    if list(df.columns) != desired_cols:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    col_cfg: Dict[str, Any] = {}
    for c in criteria_names:
        col_cfg[c] = st.column_config.NumberColumn(c, min_value=1, max_value=5, step=1, format="%d")

    edited = st.data_editor(
        df,
        use_container_width=True,
        hide_index=True,
        column_config=col_cfg,
        num_rows="fixed",
    )
    st.session_state.decision_matrix_df = edited

    if criteria_names:
        try:
            totals = edited[criteria_names].sum(axis=1)
            show = edited.copy()
            show["ì´ì (ì°¸ê³ )"] = totals
            st.write("**ì´ì (ì°¸ê³ ìš©)**")
            st.dataframe(show[["ì˜µì…˜", "ì´ì (ì°¸ê³ )"]], use_container_width=True, hide_index=True)
            st.caption("ì´ì ì€ â€˜ê²°ë¡ â€™ì´ ì•„ë‹ˆë¼, ì–´ë–¤ ì˜µì…˜ì´ ì–´ë–¤ ê¸°ì¤€ì—ì„œ ê°•/ì•½í•œì§€ ë‹¤ì‹œ ë³´ê²Œ í•˜ëŠ” ì°¸ê³ ì¹˜ì˜ˆìš”.")
        except Exception:
            pass


def render_copy_to_clipboard_button(text: str, button_label: str = "í´ë¦½ë³´ë“œì— ë³µì‚¬") -> None:
    safe = text.replace("\\", "\\\\").replace("`", "\\`").replace("${", "\\${")
    html = f"""
    <div style="display:flex; gap:8px; align-items:center;">
      <button
        onclick="navigator.clipboard.writeText(`{safe}`).then(()=>{{const el=document.getElementById('cpmsg'); el.innerText='ë³µì‚¬ë¨'; setTimeout(()=>el.innerText='',1200);}});"
        style="padding:8px 12px; border-radius:10px; border:1px solid #444; background:#111; color:#fff; cursor:pointer;">
        {button_label}
      </button>
      <span id="cpmsg" style="font-size:12px; opacity:0.8;"></span>
    </div>
    """
    st.components.v1.html(html, height=55)


def build_report_text_for_export(data: Dict[str, Any]) -> str:
    lines: List[str] = []
    lines.append("ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ â€” ìµœì¢… ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    lines.append(f"- ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("[ì„¸ì…˜ ì •ë³´]")
    lines.append(f"- ì¹´í…Œê³ ë¦¬: {st.session_state.category}")
    lines.append(f"- ê²°ì • ìœ í˜•: {st.session_state.decision_type}")
    lines.append(f"- ìƒí™© ì„¤ëª…: {st.session_state.situation}")
    lines.append(f"- ëª©í‘œ: {st.session_state.goal}")
    lines.append(f"- ì˜µì…˜: {st.session_state.options or '(ì—†ìŒ)'}")
    lines.append("")
    lines.append("[ë¦¬í¬íŠ¸ JSON]")
    lines.append(json.dumps(data, ensure_ascii=False, indent=2))
    lines.append("")
    lines.append("[Q/A]")
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        lines.append(f"{i}. ({tag}) Q: {qa['q']}")
        lines.append(f"   A: {qa['a']}")
        lines.append(f"   ts: {qa['ts']}")
        lines.append("")
    return "\n".join(lines).strip()


# =========================
# Back ë²„íŠ¼ ë¡œì§(ê¸°ì¡´ ìœ ì§€)
# =========================
def handle_back() -> None:
    if not st.session_state.answers:
        st.session_state.q_index = max(0, int(st.session_state.q_index) - 1)
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        return

    last = st.session_state.answers.pop()

    if last.get("kind") == "probe":
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        st.session_state.q_index = int(last.get("main_index", st.session_state.q_index))
        return

    mi = int(last.get("main_index", 0))
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.q_index = max(0, mi)


# =========================
# Sidebar (ë³´ì¡° ê¸°ëŠ¥ë§Œ)
# =========================
init_state()

with st.sidebar:
    st.header("ë³´ì¡° ë©”ë‰´")
    st.text_input("OpenAI API Key (Secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()
    if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸°", use_container_width=True):
        reset_flow("landing", keep_problem=False)
        st.rerun()

    if st.session_state.page in ("setup_details", "questions", "report"):
        if st.button("ê³ ë¯¼ë§Œ ìœ ì§€í•˜ê³  ë‹¤ì‹œ ì„¤ì •", use_container_width=True):
            reset_flow("landing", keep_problem=True)
            st.rerun()

    st.divider()
    with st.expander("ë””ë²„ê·¸ ë¡œê·¸"):
        st.write(st.session_state.debug_log)

    st.caption("ì‚¬ì´ë“œë°”ëŠ” ë³´ì¡° ê¸°ëŠ¥ë§Œ ì œê³µí•©ë‹ˆë‹¤.")


# =========================
# Progress Bar indexing (landing/setup í¬í•¨)
# =========================
nq = int(st.session_state.num_questions)

# labels: Landing, Setup, Q1..Qn, Report
labels = ["ê³ ë¯¼", "ì„¤ì •"] + [f"Q{i}" for i in range(1, nq + 1)] + ["ìš”ì•½"]

if st.session_state.page == "landing":
    idx = 0
elif st.session_state.page == "setup_details":
    idx = 1
elif st.session_state.page == "questions":
    idx = 2 + int(st.session_state.q_index)  # Q1 ìœ„ì¹˜ê°€ 2
else:
    idx = 2 + nq  # report

render_pebble_bridge(idx, len(labels), labels)
progress = idx / max(1, (len(labels) - 1))
with st.columns([1, 2, 1])[1]:
    render_hero_pebble(progress, f"ì§„í–‰ë„: {int(progress * 100)}%")

st.divider()


# =========================
# Pages
# =========================
def render_landing() -> None:
    st.title("ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­")
    st.caption("ì •ë‹µì„ ì£¼ê¸°ë³´ë‹¤, ì§ˆë¬¸ìœ¼ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.")

    cols = st.columns([1, 3, 1])
    with cols[1]:
        st.subheader("1ë‹¨ê³„ Â· ê³ ë¯¼ ì‘ì„±")
        st.caption("ì§€ê¸ˆ ê³ ë¯¼ ì¤‘ì¸ ìƒí™©ì„ ììœ ë¡­ê²Œ ì ì–´ì£¼ì„¸ìš”. (ì§§ì•„ë„ ê´œì°®ì•„ìš”)")

        with st.container(border=True):
            st.text_area(
                "ê³ ë¯¼ ë‚´ìš©",
                key="user_problem",
                height=220,
                placeholder="ì˜ˆ: ì´ì§ ì œì•ˆì„ ë°›ì•˜ëŠ”ë° ì•ˆì •ì„±ê³¼ ì„±ì¥ ì‚¬ì´ì—ì„œ ê³ ë¯¼ë¼ìš”. ì§€ê¸ˆ íŒ€ë„ ì¢‹ì§€ë§Œâ€¦",
                label_visibility="collapsed",
            )

        c1, c2 = st.columns([2, 1])
        with c1:
            st.session_state.num_questions = st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions))
        with c2:
            if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ", type="primary", use_container_width=True):
                txt = (st.session_state.user_problem or "").strip()
                if not txt:
                    st.warning("ê³ ë¯¼ ë‚´ìš©ì„ ë¨¼ì € í•œ ì¤„ì´ë¼ë„ ì ì–´ì£¼ì„¸ìš”.")
                else:
                    # 2ë‹¨ê³„ì—ì„œ í¸ì§‘ìš© situation ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì‚¬(ìœ ì‹¤ ë°©ì§€)
                    if not (st.session_state.situation or "").strip():
                        st.session_state.situation = txt
                    st.session_state.page = "setup_details"
                    st.rerun()


def render_setup_details() -> None:
    st.title("2ë‹¨ê³„ Â· AI ë¶„ì„ ë° ì¶”ì²œ")
    st.caption("ì•„ë˜ ê°’ë“¤ì€ â€˜ì¶”ì²œ/ì´ˆì•ˆâ€™ì…ë‹ˆë‹¤. ë§ˆìŒì— ë“¤ì§€ ì•Šìœ¼ë©´ ì§ì ‘ ë°”ê¿”ë„ ê´œì°®ì•„ìš”.")

    problem_text = (st.session_state.user_problem or "").strip()

    # AI ì¶”ì²œ ìƒì„± ë²„íŠ¼(ìë™ 1íšŒ)
    if "onboarding_reco" not in st.session_state:
        st.session_state.onboarding_reco = None
    if "onboarding_raw" not in st.session_state:
        st.session_state.onboarding_raw = None

    auto_generate = st.session_state.onboarding_reco is None and problem_text
    if auto_generate:
        with st.spinner("AIê°€ ê³ ë¯¼ì„ ì½ê³  ì¶”ì²œì„ ë§Œë“œëŠ” ì¤‘..."):
            reco, err, dbg, raw = generate_onboarding_recommendation(problem_text)
            st.session_state.debug_log = dbg
            st.session_state.onboarding_reco = reco
            st.session_state.onboarding_raw = raw
            if err:
                st.warning(err)

    top = st.columns([2, 1])
    with top[0]:
        st.subheader("ë‚´ê°€ ì ì€ ê³ ë¯¼")
    with top[1]:
        if st.button("ì¶”ì²œ ë‹¤ì‹œ ìƒì„±", use_container_width=True):
            with st.spinner("ì¶”ì²œì„ ë‹¤ì‹œ ìƒì„±í•˜ëŠ” ì¤‘..."):
                reco, err, dbg, raw = generate_onboarding_recommendation(problem_text)
                st.session_state.debug_log = dbg
                st.session_state.onboarding_reco = reco
                st.session_state.onboarding_raw = raw
                if err:
                    st.warning(err)
            st.rerun()

    with st.container(border=True):
        st.write(problem_text)

    reco = st.session_state.onboarding_reco or {}
    # ì¶”ì²œê°’ ë°˜ì˜(ì´ˆê¸° 1íšŒ: ì‚¬ìš©ìê°€ ì´ë¯¸ ìˆ˜ì •í–ˆë‹¤ë©´ ë®ì–´ì“°ì§€ ì•Šë„ë¡)
    if "onboarding_applied" not in st.session_state:
        st.session_state.onboarding_applied = False

    if reco and not st.session_state.onboarding_applied:
        # category
        rec_cat = reco.get("recommended_category", "")
        if rec_cat in [c[0] for c in TOPIC_CATEGORIES]:
            st.session_state.category = rec_cat

        rec_dt = reco.get("recommended_decision_type", "")
        if rec_dt in DECISION_TYPES:
            st.session_state.decision_type = rec_dt

        rec_coach = reco.get("recommended_coach_id", "")
        if rec_coach in [c["id"] for c in COACHES]:
            st.session_state.coach_id = rec_coach

        goal_draft = str(reco.get("goal_draft", "") or "").strip()
        if goal_draft and not (st.session_state.goal or "").strip():
            st.session_state.goal = goal_draft

        st.session_state.onboarding_applied = True

    st.divider()
    st.subheader("ì¶”ì²œê°’ í™•ì¸/ìˆ˜ì •")

    c1, c2 = st.columns(2)
    with c1:
        st.selectbox("ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")
        st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type")
        st.text_input("ì›í•˜ëŠ” ëª©í‘œ(ì´ˆì•ˆ)", key="goal", placeholder="ì˜ˆ: ë‚´ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê¸°ì¤€ì„ ì„ ëª…í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ë‹¤")
        st.text_input("ì˜µì…˜(ì‰¼í‘œë¡œ êµ¬ë¶„, ì„ íƒ)", key="options", placeholder="ì˜ˆ: A, B, C")
        st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions), key="num_questions")
    with c2:
        coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
        cur = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
        picked = st.radio("ì½”ì¹˜ ì„ íƒ", coach_labels, index=cur)
        st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]
        coach = coach_by_id(st.session_state.coach_id)

        reason = str(reco.get("coach_reason", "") or "").strip()
        if reason:
            st.info(f"**AIê°€ ì´ ì½”ì¹˜ë¥¼ ì¶”ì²œí•œ ì´ìœ (ì°¸ê³ ):** {reason}")
        with st.expander("ì½”ì¹˜ ì§„í–‰ ë°©ì‹"):
            st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
            for m in coach["method"]:
                st.write(f"- {m}")
            st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.subheader("ìƒí™© ì„¤ëª…(í¸ì§‘ ê°€ëŠ¥)")
    st.caption("ê¸°ë³¸ê°’ì€ 1ë‹¨ê³„ì—ì„œ ì ì€ ê³ ë¯¼ì…ë‹ˆë‹¤. í•„ìš”í•˜ë©´ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”.")
    st.text_area("ìƒí™© ì„¤ëª…", key="situation", height=180)

    # ê²°ì • ìœ í˜• í…œí”Œë¦¿(ì›í•˜ë©´ ì‚½ì…)
    with st.expander("ê²°ì • ìœ í˜• ê°€ì´ë“œ(í…œí”Œë¦¿)"):
        st.caption("í•„ìš”í•˜ë©´ ì•„ë˜ ê°€ì´ë“œë¥¼ ìƒí™© ì„¤ëª…ì— ì‚½ì…í•  ìˆ˜ ìˆì–´ìš”.")
        tmpl = DECISION_TEMPLATES.get(st.session_state.decision_type, "")
        if tmpl:
            st.code(tmpl, language="text")
            if st.button("ê°€ì´ë“œ ì‚½ì…(ìƒí™© ì„¤ëª…ì— ì¶”ê°€)", use_container_width=True):
                cur_txt = (st.session_state.situation or "").strip()
                if not cur_txt:
                    st.session_state.situation = tmpl
                else:
                    st.session_state.situation = cur_txt + "\n\n" + tmpl
                st.rerun()

    st.divider()
    b1, b2, b3 = st.columns([1, 1, 1])
    with b1:
        if st.button("â¬…ï¸ ì´ì „ ë‹¨ê³„", use_container_width=True):
            st.session_state.page = "landing"
            st.rerun()
    with b2:
        if st.button("ì¶”ì²œ ì›ë¬¸(JSON) ë³´ê¸°", use_container_width=True):
            if st.session_state.onboarding_raw:
                st.code(st.session_state.onboarding_raw, language="json")
            else:
                st.caption("ì¶”ì²œ ì›ë¬¸ì´ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")
    with b3:
        if st.button("ì½”ì¹­ ì‹œì‘í•˜ê¸°(ì‹¤í–‰í•˜ê¸°)", type="primary", use_container_width=True):
            # ì§ˆë¬¸ ì„¸ì…˜ ì‹œì‘: ê¸°ì¡´ íë¦„ ì´ˆê¸°í™”(ê³ ë¯¼ ë‚´ìš©ì€ ìœ ì§€)
            st.session_state.q_index = 0
            st.session_state.questions = []
            st.session_state.answers = []
            st.session_state.probe_active = False
            st.session_state.probe_question = ""
            st.session_state.probe_for_index = None
            st.session_state.crosscheck_used_for = set()
            st.session_state.final_report_json = None
            st.session_state.final_report_raw = None
            st.session_state.decision_matrix_df = None
            st.session_state.page = "questions"
            st.rerun()


def render_questions() -> None:
    st.title("ì§ˆë¬¸")
    st.caption("í•œ í™”ë©´ì— í•œ ì§ˆë¬¸. ë‹µë³€ì´ 10ì ë¯¸ë§Œì´ë©´ 1íšŒ êµ¬ì²´í™” ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤.")

    nq = int(st.session_state.num_questions)
    q_idx = int(st.session_state.q_index)
    q_idx = max(0, min(q_idx, nq - 1))

    ensure_question(q_idx, nq)
    main_q = st.session_state.questions[q_idx]

    if st.session_state.probe_active and st.session_state.probe_for_index == q_idx:
        show_q = st.session_state.probe_question
        kind = "probe"
        badge = "ì¶”ê°€ ì§ˆë¬¸(êµ¬ì²´í™”)"
    else:
        show_q = main_q
        kind = "main"
        badge = "ë©”ì¸ ì§ˆë¬¸"

    top_c1, top_c2, top_c3 = st.columns([1, 2, 1])
    with top_c1:
        if st.button("â¬…ï¸ ì´ì „ìœ¼ë¡œ", use_container_width=True, disabled=(q_idx == 0 and not st.session_state.answers)):
            handle_back()
            st.rerun()
    with top_c3:
        st.caption(f"ë©”ì¸ ë‹µë³€: {main_answer_count()} / {nq}")

    st.subheader(f"Q{q_idx + 1} / {nq}  Â·  {badge}")
    with st.container(border=True):
        st.markdown(f"**{show_q}**")

    with st.form(f"answer_form_{q_idx}_{kind}", clear_on_submit=True):
        hint = ""
        if st.session_state.answers:
            last_a = st.session_state.answers[-1]["a"]
            hint = f"ì´ì „ ë‹µ ìš”ì•½: {last_a[:90]}{'â€¦' if len(last_a) > 90 else ''}"
        ans = st.text_area("ë‹µë³€", placeholder=hint or "ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", height=150)
        submitted = st.form_submit_button("ë‹µë³€ ì €ì¥", use_container_width=True)

    if submitted:
        a = (ans or "").strip()
        if not a:
            st.warning("ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í•œ ì¤„ë§Œ ì…ë ¥í•´ë„ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            add_answer(show_q, a, kind=kind, main_index=q_idx)

            if kind == "probe":
                st.session_state.probe_active = False
                st.session_state.probe_question = ""
                st.session_state.probe_for_index = None
                st.session_state.q_index = min(q_idx + 1, nq - 1)
            else:
                if is_too_short_answer(a):
                    pq, err, dbg = generate_probe_question(show_q, a)
                    st.session_state.debug_log = dbg
                    st.session_state.probe_active = True
                    st.session_state.probe_question = pq
                    st.session_state.probe_for_index = q_idx
                else:
                    if main_answer_count() >= nq:
                        st.session_state.page = "report"
                        st.session_state.report_just_entered = True
                        st.session_state.q_index = nq - 1
                    else:
                        st.session_state.q_index = min(q_idx + 1, nq - 1)
            st.rerun()

    with st.expander("ë‹µë³€ ê¸°ë¡"):
        grouped: Dict[int, List[Dict[str, Any]]] = {}
        for qa in st.session_state.answers:
            grouped.setdefault(int(qa.get("main_index", 0)), []).append(qa)

        for mi in sorted(grouped.keys()):
            st.markdown(f"### Q{mi + 1}")
            for qa in grouped[mi]:
                tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
                st.markdown(f"**({tag}) {qa['q']}**")
                st.write(qa["a"])
                st.caption(qa["ts"])
                st.divider()


def render_report() -> None:
    coach = coach_by_id(st.session_state.coach_id)
    nq = int(st.session_state.num_questions)

    st.title("ìµœì¢… ì •ë¦¬")
    st.caption("ì¶”ì²œ/ì •ë‹µ ì—†ì´, ê³ ë¯¼ì˜ í•µì‹¬ê³¼ ê¸°ì¤€ì„ â€˜ê±°ìš¸ ë¹„ì¶”ê¸°â€™ ë°©ì‹ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.")

    if st.session_state.report_just_entered:
        st.balloons()
        st.session_state.report_just_entered = False

    if main_answer_count() < nq:
        st.warning("ì•„ì§ ëª¨ë“  ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì§ˆë¬¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ ë‹µë³€ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ ì´ë™", type="primary"):
            st.session_state.page = "questions"
            st.rerun()
        st.stop()

    colA, colB = st.columns([1, 1])
    with colA:
        gen = st.button("ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨", type="primary", use_container_width=True)
    with colB:
        if st.button("ìƒˆ ì„¸ì…˜ ì‹œì‘", use_container_width=True):
            reset_flow("landing", keep_problem=False)
            st.rerun()

    if gen or (st.session_state.final_report_json is None and st.session_state.final_report_raw is None):
        with st.spinner("ìµœì¢… ì •ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            data, err, dbg, raw = generate_final_report_json()
            st.session_state.debug_log = dbg
            if data is not None:
                st.session_state.final_report_json = data
                st.session_state.final_report_raw = raw
            else:
                st.session_state.final_report_json = None
                st.session_state.final_report_raw = raw
                st.error(err or "ì •ë¦¬ ìƒì„± ì‹¤íŒ¨")

    data = st.session_state.final_report_json
    if data:
        st.success("ìµœì¢… ì •ë¦¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

        render_summary_block(data)
        criteria_names = render_criteria(data)
        render_decision_matrix(criteria_names, data)

        if coach["id"] == "action":
            render_action_visualization(data)
        elif coach["id"] == "logic":
            render_key_points_logic(data)
        else:
            render_emotions_values(data)

        render_mirroring_visual()
        render_coaching_message(data)
        render_next_question(data)

        st.subheader("ê³µìœ /ì €ì¥")
        export_text = build_report_text_for_export(data)
        render_copy_to_clipboard_button(export_text, "ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ ë³µì‚¬")

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.download_button(
            "ë¦¬í¬íŠ¸ .txt ë‹¤ìš´ë¡œë“œ",
            data=export_text.encode("utf-8"),
            file_name=f"pebble_decision_report_{ts}.txt",
            mime="text/plain",
            use_container_width=True,
        )

        st.subheader("ê³µìœ ìš©(JSON)")
        st.code(json.dumps(data, ensure_ascii=False, indent=2), language="json")

        if contains_forbidden_recommendation(json.dumps(data, ensure_ascii=False)):
            st.warning("ë¦¬í¬íŠ¸ì— ì¶”ì²œ/ì§€ì‹œì²˜ëŸ¼ ë³´ì´ëŠ” í‘œí˜„ì´ ì„ì˜€ì„ ìˆ˜ ìˆì–´ìš”. í•„ìš”í•˜ë©´ â€˜ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨â€™ì„ ëˆŒëŸ¬ ë³´ì„¸ìš”.")

        valid_until = (datetime.now().date() + timedelta(days=7)).strftime("%Y-%m-%d")
        st.divider()
        st.caption(f"ì´ ì •ë¦¬ëŠ” **{valid_until}**ê¹Œì§€ ìœ íš¨í•©ë‹ˆë‹¤.")

    elif st.session_state.final_report_raw:
        st.warning("JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë¬¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.code(st.session_state.final_report_raw, language="text")


# =========================
# Router
# =========================
if st.session_state.page == "landing":
    render_landing()
elif st.session_state.page == "setup_details":
    render_setup_details()
elif st.session_state.page == "questions":
    render_questions()
else:
    render_report()

st.divider()
with st.expander("ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Streamlit Cloud)"):
    st.markdown(
        """
- Secrets ì„¤ì •: Settings â†’ Secretsì— `OPENAI_API_KEY = "sk-..."` ì¶”ê°€
- requirements.txt:
  - streamlit
  - openai
  - pandas
"""
    )

