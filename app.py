# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ (Pebble Decision Coach)
#
# ì›ì¹™(ìœ ì§€):
# - ì •ë‹µ/ê²°ë¡ /ì¶”ì²œ ì œê³µ ê¸ˆì§€ (ê°•ì œ)
# - í•œ í™”ë©´ì— í•œ ì§ˆë¬¸ì”©
# - ì´ì „ ë‹µë³€ ë°˜ì˜ ë™ì  ì§ˆë¬¸ ìƒì„±
# - ë§ˆì§€ë§‰: ê³ ë¯¼ì˜ í•µì‹¬ / ì„ íƒ ê¸°ì¤€ / ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°, ì¶”ì²œ ê¸ˆì§€)
#
# ì´ë²ˆ ê³ ë„í™” ë°˜ì˜:
# 1) ì§ˆë¬¸ ìƒì„± ê³ ë„í™”
#   - Logic Cross-Check(ë‹µë³€ ê°„ ë…¼ë¦¬ ì¶©ëŒ ê°ì§€ â†’ ì¶©ëŒì„ ì§šëŠ” ì§ˆë¬¸ ìš°ì„  ìƒì„±)
#   - Probing(ë‹µë³€ 10ì ë¯¸ë§Œì´ë©´ 1íšŒ êµ¬ì²´í™” ì§ˆë¬¸)
#   - Action Coach ê°•í™”: If-Then íŠ¸ë¦¬ê±° + Pre-mortem ì§ˆë¬¸ í¬í•¨
#
# 2) UI/UX
#   - ì´ì „ìœ¼ë¡œ(Back) ë²„íŠ¼: q_index ê°ì†Œ + answers ë§ˆì§€ë§‰ ë‹µë³€ ì œê±°(+probe ìƒíƒœ ì •ë¦¬)
#   - ê²°ì • ìœ í˜•ë³„ í…œí”Œë¦¿: ê²°ì • ìœ í˜• ì„ íƒ ì‹œ ìƒí™© ì„¤ëª…ì— ê°€ì´ë“œ ìë™ ì…ë ¥(ìƒí™©ì´ ë¹„ì–´ìˆê±°ë‚˜ ê°€ì´ë“œ ë¬¸êµ¬ì¼ ë•Œ)
#   - ë¦¬í¬íŠ¸ ì§„ì… ì‹œ st.balloons()
#
# 3) ë¦¬í¬íŠ¸/ê³µìœ 
#   - ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(st.data_editor): ì˜µì…˜ x ê¸°ì¤€ ì ìˆ˜(1~5)
#   - ë‚´ë©´ì˜ ëª©ì†Œë¦¬(Mirroring): ë‹µë³€ í‚¤ì›Œë“œ/ê°ì •ì–´ ë¹ˆë„ ì‹œê° ìš”ì•½
#   - ì €ì¥: í´ë¦½ë³´ë“œ ë³µì‚¬ ë²„íŠ¼ + íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì¼ëª… .txt ë‹¤ìš´ë¡œë“œ
#   - ê²°ì • ìœ íš¨ê¸°ê°„: ì˜¤ëŠ˜ë¡œë¶€í„° 7ì¼ ë’¤ê¹Œì§€
#
# í•„ìš”:
#   pip install streamlit openai pandas
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import random
import re
import textwrap
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ AI ê²°ì • ì½”ì¹­", page_icon="ğŸª¨", layout="wide")

MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

DECISION_TEMPLATES: Dict[str, str] = {
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] A vs B ì„ íƒ ì •ë¦¬
        1) Aì™€ Bë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í•´ë³´ì„¸ìš”(ë¬´ì—‡ì´ ë‹¤ë¥¸ê°€?)
        2) Aì˜ ì¥ì /ë‹¨ì , Bì˜ ì¥ì /ë‹¨ì ì„ ê°ê° 2~3ê°œì”© ì ì–´ë³´ì„¸ìš”
        3) 'ë‚´ê²Œ ì¤‘ìš”í•œ ê¸°ì¤€' 3ê°œë¥¼ ì ê³ , ê° ê¸°ì¤€ì—ì„œ A/Bê°€ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ì¨ë³´ì„¸ìš”
        4) ìµœì•…ì˜ ê²½ìš°(ë¦¬ìŠ¤í¬)ì™€ ê°ë‹¹ ê°€ëŠ¥í•œ ì •ë„ë¥¼ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì—¬ëŸ¬ ì˜µì…˜ ë¹„êµ
        1) í›„ë³´ ì˜µì…˜ì„ ëª¨ë‘ ë‚˜ì—´í•´ë³´ì„¸ìš”(ìµœì†Œ 3ê°œ)
        2) ë¹„êµ ê¸°ì¤€ 3~5ê°œ(ë¹„ìš©/ì‹œê°„/ì„±ì¥/ìŠ¤íŠ¸ë ˆìŠ¤/ê´€ê³„ ë“±)ë¥¼ ì ì–´ë³´ì„¸ìš”
        3) ê° ì˜µì…˜ì´ ê¸°ì¤€ë³„ë¡œ ì–´ë–¤ ëŠë‚Œì¸ì§€(ì¢‹ìŒ/ë³´í†µ/ë‚˜ì¨)ë¶€í„° ëŒ€ëµ ì ì–´ë³´ì„¸ìš”
        4) 'ì§€ê¸ˆì˜ ë‚˜'ì—ê²Œ ì¤‘ìš”í•œ ê²ƒê³¼ '1ë…„ ë’¤ì˜ ë‚˜'ì—ê²Œ ì¤‘ìš”í•œ ê²ƒì„ êµ¬ë¶„í•´ë³´ì„¸ìš”
        """
    ).strip(),
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)
        1) 'í•œë‹¤'ì˜ ì˜ë¯¸ë¥¼ êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ìˆ˜ì¤€ìœ¼ë¡œ?)
        2) í•œë‹¤ë©´ ì–»ëŠ” ê²ƒ/ìƒëŠ” ê²ƒ, ì•ˆ í•œë‹¤ë©´ ì–»ëŠ” ê²ƒ/ìƒëŠ” ê²ƒì„ ê°ê° ì ì–´ë³´ì„¸ìš”
        3) ê²°ì •ì´ ë¯¸ë¤„ì§ˆ ë•Œ ìƒê¸°ëŠ” ë¹„ìš©(ë¶ˆì•ˆ/ê¸°íšŒ/ê´€ê³„ ë“±)ì„ ì ì–´ë³´ì„¸ìš”
        4) ì§€ê¸ˆ ë‹¹ì¥ í•„ìš”í•œ ì¶”ê°€ ì •ë³´ 1~2ê°œê°€ ë¬´ì—‡ì¸ì§€ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ì „ëµ/ì‹œì  ê²°ì •
        1) ì„±ê³µì˜ ì •ì˜ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ(ì¸¡ì • ê°€ëŠ¥í•˜ê²Œ)
        2) ì„ íƒ ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤ 2~3ê°œ(ë¹ ë¥´ê²Œ/ì²œì²œíˆ/ë¶€ë¶„ ì ìš© ë“±) ë‚˜ì—´
        3) ê° ì‹œë‚˜ë¦¬ì˜¤ì˜ ë¦¬ìŠ¤í¬ì™€ ì™„ì¶©ì¥ì¹˜(ë³´í—˜)ë¥¼ ì ì–´ë³´ì„¸ìš”
        4) 'ì‹œì‘ íŠ¸ë¦¬ê±°(If) â†’ í–‰ë™(Then)' í˜•íƒœë¡œ ì‹¤í–‰ ì¡°ê±´ì„ ì„¤ê³„í•´ë³´ì„¸ìš”
        """
    ).strip(),
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥": textwrap.dedent(
        """\
        [ê°€ì´ë“œ] ê°ˆë“±/ëŒ€í™” ë°©í–¥ ì •ë¦¬
        1) ì§€ê¸ˆ ê°ˆë“±ì˜ ìŸì ì„ 'ì‚¬ì‹¤/í•´ì„/ê°ì •/ìš”êµ¬'ë¡œ ë‚˜ëˆ  ì ì–´ë³´ì„¸ìš”
        2) ë‚´ê°€ ì›í•˜ëŠ” ë³€í™”(ìš”êµ¬) 1~2ê°œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”
        3) ìƒëŒ€ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸¸ ë§Œí•œ ê²ƒì„ ì¶”ì¸¡í•´ ì ì–´ë³´ì„¸ìš”(í™•ì • ì•„ë‹˜)
        4) ëŒ€í™”ì—ì„œ ì§€í‚¤ê³  ì‹¶ì€ ì›ì¹™(í†¤/íƒ€ì´ë°/í•œê³„ì„ )ì„ ì ì–´ë³´ì„¸ìš”
        """
    ).strip(),
}

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” êµ¬ì¡° ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ê³ , ê°€ì •ì„ í”ë“œëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì •ë¦¬ë¥¼ ë•ìŠµë‹ˆë‹¤",
        "style": "MECE/ê¸°ì¤€/ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ)",
        "method": [
            "ìƒí™©Â·ì œì•½Â·ì˜µì…˜ì„ ë¶„ë¦¬í•´ì„œ ì ê²Œ í•˜ê¸°",
            "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ì•„ ìš°ì„ ìˆœìœ„ë¥¼ í™•ì¸í•˜ê¸°",
            "â€˜ë‚´ê°€ ë‹¹ì—°í•˜ë‹¤ê³  ë¯¿ëŠ” ê°€ì •â€™ì„ ë°˜ëŒ€ë¡œ ë’¤ì§‘ì–´ ë³´ê¸°",
        ],
        "prompt_hint": "MECE, ê¸°ì¤€ ëª©ë¡, ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°)",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜ ì½”ì¹˜",
        "tagline": "ê°ì •ê³¼ ê°€ì¹˜ë¥¼ ë¶„ë¦¬í•´, í›„íšŒê°€ ì ì€ ê¸°ì¤€ì„ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤",
        "style": "ê°ì • ë¼ë²¨ë§/ê°€ì¹˜ ë¶„ë¦¬/í›„íšŒ ìµœì†Œí™”",
        "method": [
            "ê°ì • ë¼ë²¨ë§(ì§€ê¸ˆ ëŠë¼ëŠ” ê²ƒ) â†’ ì´ìœ ",
            "ê·¸ ê°ì •ì´ â€˜ì¼ì‹œì  í¸ì•ˆí•¨â€™ì¸ì§€ â€˜ì¥ê¸° ê°€ì¹˜â€™ì¸ì§€ ë¶„ë¦¬",
            "ê°€ì¹˜ Top3 ë„ì¶œ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸",
        ],
        "prompt_hint": "ê°ì •-ê°€ì¹˜ ë¶„ë¦¬, ê°€ì¹˜ Top3, ë¯¸ë˜ì˜ ë‚˜ ì§ˆë¬¸",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê³„íšì„ â€˜ì •ë¦¬â€™í•˜ê³ , ì˜¤ëŠ˜ 5ë¶„ Quick Winê¹Œì§€ ìŠ¤ìŠ¤ë¡œ ì°¾ê²Œ ë•ìŠµë‹ˆë‹¤(ì¶”ì²œ ê¸ˆì§€)",
        "style": "ìš°ì„ ìˆœìœ„/If-Then/í”„ë¦¬ëª¨í…œ/Quick Win",
        "method": [
            "ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°: íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ Top1~3 ì •ë¦¬",
            "ì‹¤í–‰ì„ â€˜ì–¸ì œâ€™ê°€ ì•„ë‹ˆë¼ â€˜If-Then íŠ¸ë¦¬ê±°â€™ë¡œ ì„¤ê³„",
            "ì‹¤íŒ¨ë¥¼ ë¯¸ë¦¬ ê°€ì •(í”„ë¦¬ëª¨í…œ)í•´ ë°©í•´ ìš”ì¸ì„ ë“œëŸ¬ë‚´ê¸°",
            "ë§ˆì§€ë§‰ì— â€˜ì˜¤ëŠ˜ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ ë„ì¶œ",
        ],
        "prompt_hint": "ìš°ì„ ìˆœìœ„, If-Then, í”„ë¦¬ëª¨í…œ, Quick Win",
    },
]

# Probing ê¸°ì¤€: "10ì ë¯¸ë§Œ"ì´ë©´ 1íšŒ ì¶”ê°€ ì§ˆë¬¸ (ìš”êµ¬ì‚¬í•­ ë°˜ì˜)
MIN_ANSWER_CHARS = 10
SHORT_ANSWER_PATTERNS = [
    r"^ëª¨ë¥´ê² ",
    r"^ì˜\s*ëª¨ë¥´",
    r"^ê·¸ëƒ¥",
    r"^ì—†ì–´",
    r"^ëª¨ë¦„$",
    r"^ã„´ã„´$",
    r"^ëª°ë¼$",
]


# =========================
# Pebble SVG (no PIL)
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    return f"""
<svg width="160" height="120" viewBox="0 0 160 120" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="pebble">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="80%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M28 80
           C14 60, 20 30, 50 20
           C66 14, 96 12, 114 24
           C142 44, 150 68, 130 88
           C112 108, 54 110, 28 80 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M54 30 C68 22, 82 22, 94 30"
        fill="none" stroke="{shine}" stroke-width="7" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_svg_b64(progress_0_to_1: float, inactive: bool = False) -> str:
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    if inactive:
        fill, shine = "#2f3136", "#6b6f7a"
    else:
        fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
        shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"
    svg = _pebble_svg(fill=fill, shine=shine)
    return base64.b64encode(svg.encode("utf-8")).decode("ascii")


def render_pebble_bridge(current_idx: int, total: int, labels: List[str]) -> None:
    total = max(2, int(total))
    current_idx = max(0, min(int(current_idx), total - 1))

    left_pct = ((current_idx + 0.5) / total) * 100.0

    pebble_imgs = []
    for i in range(total):
        active = i <= current_idx
        p = (i + 1) / total
        b64 = pebble_svg_b64(p, inactive=not active)
        pebble_imgs.append(b64)

    html = """
<style>
.pebble-bridge-wrap{
  position: relative;
  width: 100%;
  margin: 6px 0 2px 0;
  padding: 16px 4px 0 4px;
}
.pebble-row{
  display: flex;
  gap: 10px;
  align-items: flex-end;
  justify-content: space-between;
}
.pebble-cell{
  flex: 1;
  min-width: 0;
  text-align: center;
}
.pebble-img{
  width: 100%;
  max-width: 120px;
  height: auto;
  display: inline-block;
}
.pebble-label{
  font-size: 12px;
  margin-top: 4px;
  opacity: 0.85;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
}

/* ì‚¬ëŒ(ğŸš¶) í¬ê²Œ + ë°©í–¥ ë°˜ëŒ€ë¡œ */
.walker{
  position: absolute;
  top: -10px;
  left: VAR_LEFT%;
  transform: translateX(-50%) scaleX(-1);
  font-size: 40px;
  line-height: 1;
  transition: left 520ms cubic-bezier(.2,.9,.2,1);
  filter: drop-shadow(0px 2px 2px rgba(0,0,0,0.25));
  animation: bob 800ms ease-in-out infinite;
  user-select: none;
}
@keyframes bob{
  0%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
  50%{ transform: translateX(-50%) translateY(-3px) scaleX(-1); }
  100%{ transform: translateX(-50%) translateY(0px) scaleX(-1); }
}
</style>
<div class="pebble-bridge-wrap">
  <div class="walker">ğŸš¶</div>
  <div class="pebble-row">
    VAR_PEBBLES
  </div>
</div>
""".strip()

    pebble_cells = []
    for i in range(total):
        opacity = "1.0" if i <= current_idx else "0.55"
        cell = f"""
<div class="pebble-cell" style="opacity:{opacity}">
  <img class="pebble-img" src="data:image/svg+xml;base64,{pebble_imgs[i]}" />
  <div class="pebble-label">{labels[i] if i < len(labels) else ""}</div>
</div>
""".strip()
        pebble_cells.append(cell)

    html = html.replace("VAR_LEFT", f"{left_pct:.3f}")
    html = html.replace("VAR_PEBBLES", "\n".join(pebble_cells))
    st.markdown(html, unsafe_allow_html=True)


def render_hero_pebble(progress: float, label: str) -> None:
    b64 = pebble_svg_b64(progress, inactive=False)
    st.markdown(
        f"""
<div style="text-align:center;">
  <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:240px;"/>
  <div style="margin-top:6px; font-size:14px;">{label}</div>
</div>
""",
        unsafe_allow_html=True,
    )


# =========================
# OpenAI
# =========================
def get_api_key() -> str:
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install openai`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.6) -> Tuple[Optional[str], Optional[str], List[str]]:
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. Secretsì— OPENAI_API_KEYë¥¼ ë„£ê±°ë‚˜ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    # Responses API ìš°ì„ 
    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    # Chat Completions fallback
    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.", debug


# =========================
# State + routing
# =========================
def init_state() -> None:
    if "page" not in st.session_state:
        st.session_state.page = "setup"  # setup | questions | report

    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]
    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]
    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]

    if "situation" not in st.session_state:
        st.session_state.situation = ""
    if "goal" not in st.session_state:
        st.session_state.goal = ""
    if "options" not in st.session_state:
        st.session_state.options = ""

    if "num_questions" not in st.session_state:
        st.session_state.num_questions = 5

    # main question index (0..n-1)
    if "q_index" not in st.session_state:
        st.session_state.q_index = 0

    # ì§ˆë¬¸ ëª©ë¡ì€ "main ì§ˆë¬¸"ë§Œ ì €ì¥
    if "questions" not in st.session_state:
        st.session_state.questions = []

    # answers: {"q":..., "a":..., "ts":..., "kind":"main"|"probe", "main_index":int}
    if "answers" not in st.session_state:
        st.session_state.answers = []

    # probe ëª¨ë“œ
    if "probe_active" not in st.session_state:
        st.session_state.probe_active = False
    if "probe_question" not in st.session_state:
        st.session_state.probe_question = ""
    if "probe_for_index" not in st.session_state:
        st.session_state.probe_for_index = None  # type: ignore

    # logic cross-check(ì¶©ëŒ ì§ˆë¬¸) ìƒì„± ì—¬ë¶€: main_indexë³„ 1íšŒ
    if "crosscheck_used_for" not in st.session_state:
        st.session_state.crosscheck_used_for = set()  # type: ignore

    if "final_report_json" not in st.session_state:
        st.session_state.final_report_json = None
    if "final_report_raw" not in st.session_state:
        st.session_state.final_report_raw = None

    # ë¦¬í¬íŠ¸ ì§„ì… íš¨ê³¼
    if "report_just_entered" not in st.session_state:
        st.session_state.report_just_entered = False

    # ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤ ìƒíƒœ
    if "decision_matrix_df" not in st.session_state:
        st.session_state.decision_matrix_df = None

    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []
    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""

    # ê²°ì • ìœ í˜• í…œí”Œë¦¿ ìë™ ì…ë ¥ì„ ìœ„í•œ last ê¸°ì–µ
    if "last_decision_type" not in st.session_state:
        st.session_state.last_decision_type = st.session_state.decision_type


def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def reset_flow(to_page: str = "setup") -> None:
    st.session_state.page = to_page
    st.session_state.q_index = 0
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.crosscheck_used_for = set()
    st.session_state.final_report_json = None
    st.session_state.final_report_raw = None
    st.session_state.decision_matrix_df = None
    st.session_state.report_just_entered = False
    st.session_state.debug_log = []


def add_answer(q: str, a: str, kind: str, main_index: int) -> None:
    st.session_state.answers.append(
        {"q": q, "a": a, "ts": datetime.now().isoformat(timespec="seconds"), "kind": kind, "main_index": main_index}
    )


def main_answer_count() -> int:
    return sum(1 for x in st.session_state.answers if x.get("kind") == "main")


# =========================
# Helpers
# =========================
def normalize(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


def token_overlap(a: str, b: str) -> float:
    def toks(s: str) -> set:
        s = re.sub(r"[^\wê°€-í£ ]", " ", s)
        s = re.sub(r"\s+", " ", s).strip().lower()
        return set([t for t in s.split(" ") if len(t) >= 2])

    ta, tb = toks(a), toks(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    denom = max(1, min(len(ta), len(tb)))
    return inter / denom


def is_similar(a: str, b: str) -> bool:
    a0, b0 = normalize(a), normalize(b)
    if not a0 or not b0:
        return False
    if a0 == b0:
        return True
    if a0 in b0 or b0 in a0:
        return True
    return token_overlap(a0, b0) >= 0.75


def is_too_short_answer(ans: str) -> bool:
    a = (ans or "").strip()
    if len(a) < MIN_ANSWER_CHARS:
        return True
    for pat in SHORT_ANSWER_PATTERNS:
        if re.search(pat, a):
            return True
    return False


def parse_options() -> List[str]:
    return [o.strip() for o in (st.session_state.options or "").split(",") if o.strip()]


# =========================
# Question generation
# =========================
def system_prompt_for_questions(coach: Dict[str, Any]) -> str:
    base = (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ì§ˆë¬¸ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì •ë‹µ/í•´ê²°ì±…/ì¶”ì²œì„ ì£¼ì§€ ë§ê³ , ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ì§ˆë¬¸ë§Œ ë˜ì§€ì„¸ìš”.\n"
        "ê¸ˆì§€: ê²°ë¡ , ì¶”ì²œ, ì„ íƒ ê°•ìš”, íŒë‹¨ë¬¸(ì˜ˆ: Aê°€ ë‚«ë‹¤), ì§€ì‹œë¬¸(í•´ì•¼ í•œë‹¤/í•˜ì).\n"
        "ì¶œë ¥: ì§ˆë¬¸ 1ê°œë§Œ. (ì„¤ëª…/ë²ˆí˜¸/ë¨¸ë¦¬ë§ ê¸ˆì§€)\n"
    )
    if coach["id"] == "logic":
        return base + "ìŠ¤íƒ€ì¼: êµ¬ì¡°í™”/ê¸°ì¤€/ì—­ë°œìƒ(ê°€ì • ê¹¨ê¸°) ì§ˆë¬¸.\n"
    if coach["id"] == "value":
        return base + "ìŠ¤íƒ€ì¼: ê°ì • ë¼ë²¨ë§ + ê°ì •/ê°€ì¹˜ ë¶„ë¦¬ + í›„íšŒ ìµœì†Œí™” ì§ˆë¬¸.\n"
    return base + "ìŠ¤íƒ€ì¼: If-Then íŠ¸ë¦¬ê±°/í”„ë¦¬ëª¨í…œ/ìš°ì„ ìˆœìœ„/Quick Winì„ ëª¨ë‘ ì§ˆë¬¸ìœ¼ë¡œë§Œ ìœ ë„.\n"


def build_context_block() -> str:
    # ìµœê·¼ main/probe í¬í•¨ ìµœëŒ€ 6ê°œ
    hist = ""
    tail = st.session_state.answers[-6:]
    for i, qa in enumerate(tail, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        hist += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"

    opts = parse_options()
    opts_txt = "\n".join([f"- {o}" for o in opts]) if opts else "(ë¯¸ì…ë ¥)"

    return textwrap.dedent(
        f"""
        [ì„¸ì…˜ ì‹œì‘ ì •ë³´]
        - ì¹´í…Œê³ ë¦¬: {st.session_state.category}
        - ê²°ì • ìœ í˜•: {st.session_state.decision_type}
        - ìƒí™© ì„¤ëª…: {st.session_state.situation or "(ë¯¸ì…ë ¥)"}
        - ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal or "(ë¯¸ì…ë ¥)"}
        - ê³ ë ¤ ì˜µì…˜(ìˆë‹¤ë©´): {opts_txt}

        [ìµœê·¼ Q/A]
        {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
        """
    ).strip()


def probing_instruction(last_q: str, last_a: str) -> str:
    return textwrap.dedent(
        f"""
        ì‚¬ìš©ìì˜ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ëª¨í˜¸í•©ë‹ˆë‹¤.
        ì•„ë˜ì˜ ì§ì „ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ êµ¬ì²´í™”í•  ìˆ˜ ìˆë„ë¡ ë”± 1ê°œì˜ ì¶”ê°€ ì§ˆë¬¸(Probe)ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

        - ì§ì „ ì§ˆë¬¸: {last_q}
        - ì§ì „ ë‹µë³€: {last_a}

        ìš”êµ¬ì‚¬í•­:
        - 'êµ¬ì²´í™”'ë¥¼ ë•ëŠ” ì§ˆë¬¸(ì˜ˆ: ì˜ˆì‹œ/ìƒí™©/ê¸°ì¤€/ì´ìœ /ë²”ìœ„/ê¸°ê°„/ìš°ì„ ìˆœìœ„ ì¤‘ í•˜ë‚˜ë¥¼ ë” ë¬»ê¸°)
        - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ ê¸ˆì§€
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
        """
    ).strip()


def crosscheck_system_prompt() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ë…¼ë¦¬ ì¶©ëŒ ê°ì§€ê¸°ì…ë‹ˆë‹¤.\n"
        "ì‚¬ìš©ìì˜ ì´ì „ ë‹µë³€ë“¤ ì‚¬ì´ì— 'ìš°ì„ ìˆœìœ„/ê¸°ì¤€/ëª©í‘œ'ê°€ ì„œë¡œ ì¶©ëŒí•˜ëŠ”ì§€ ì ê²€í•˜ì„¸ìš”.\n"
        "ì¤‘ìš”: ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”. ì§ˆë¬¸ì„ ë§Œë“¤ ë•Œë„ ê°•ìš”/íŒë‹¨ ê¸ˆì§€.\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ. (ì„¤ëª…/ì½”ë“œë¸”ë¡ ê¸ˆì§€)\n"
    )


def crosscheck_user_prompt(current_main_index: int) -> str:
    # main ë‹µë³€ë§Œ ëŒ€ìƒìœ¼ë¡œ ìµœê·¼ 6ê°œ ì •ë„ë¡œ êµì°¨ ê²€ì¦
    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    tail = mains[-6:]
    qa = ""
    for i, x in enumerate(tail, start=1):
        qa += f"{i}) Q: {x['q']}\n   A: {x['a']}\n"

    return textwrap.dedent(
        f"""
        ì•„ë˜ëŠ” ì‚¬ìš©ì ë‹µë³€ ì¼ë¶€ì…ë‹ˆë‹¤. ë‹µë³€ë“¤ ì‚¬ì´ì— ë…¼ë¦¬ì  ì¶©ëŒ(ê¸°ì¤€/ìš°ì„ ìˆœìœ„ì˜ ìƒì¶©)ì´ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.
        ì¶©ëŒì´ ìˆë‹¤ë©´, ê·¸ ì¶©ëŒì„ ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ 'ì •ë¦¬'í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì œì•ˆí•˜ì„¸ìš”.
        ì¶©ëŒì´ ì—†ë‹¤ë©´ has_conflict=falseë¡œ ë‘ì„¸ìš”.

        [ë‹µë³€ë“¤]
        {qa if qa.strip() else "(ë‹µë³€ ì—†ìŒ)"}

        [ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]
        {{
          "has_conflict": true/false,
          "conflict_summary": "string (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
          "question": "string (has_conflict=trueì¼ ë•Œë§Œ, ì§ˆë¬¸ 1ê°œ)"
        }}

        ì¶”ê°€ ê·œì¹™:
        - questionì€ ì§ˆë¬¸ 1ê°œë§Œ(ë¬¼ìŒí‘œ í¬í•¨ ê¶Œì¥)
        - íŒë‹¨/ì¶”ì²œ/ì§€ì‹œ/ì„ íƒ ê°•ìš” ê¸ˆì§€
        - ê°™ì€ ë‚´ìš©ì„ ë°˜ë³µí•˜ì§€ ì•Šê²Œ ê°„ê²°í•˜ê²Œ
        - current_main_index={current_main_index}
        """
    ).strip()


def safe_json_parse(text: str) -> Optional[Dict[str, Any]]:
    if not text:
        return None
    t = text.strip()
    if not t.startswith("{"):
        m = re.search(r"\{.*\}", t, flags=re.S)
        if m:
            t = m.group(0).strip()
    try:
        return json.loads(t)
    except Exception:
        return None


def try_logic_crosscheck_question(main_index: int) -> Tuple[Optional[str], List[str]]:
    """
    main ì§ˆë¬¸ ìƒì„± ì§ì „ì— 1íšŒ:
    - ì´ì „ main ë‹µë³€ë“¤ ê°„ ì¶©ëŒì´ ìˆìœ¼ë©´, ê·¸ ì¶©ëŒì„ ì§šëŠ” ì§ˆë¬¸ì„ ìš°ì„  ë°˜í™˜
    - main_indexë³„ 1íšŒë§Œ ì‚¬ìš©
    """
    dbg: List[str] = []
    if main_index in st.session_state.crosscheck_used_for:
        return None, dbg

    # ë‹µë³€ì´ ì¶©ë¶„íˆ ìŒ“ì˜€ì„ ë•Œë§Œ(ìµœì†Œ 2ê°œ main)
    mains = [x for x in st.session_state.answers if x.get("kind") == "main"]
    if len(mains) < 2:
        return None, dbg

    system = crosscheck_system_prompt()
    user = crosscheck_user_prompt(main_index)
    txt, err, d = call_openai_text(system=system, user=user, temperature=0.2)
    dbg.extend(d)
    if not txt:
        if err:
            dbg.append(f"Crosscheck error: {err}")
        return None, dbg

    data = safe_json_parse(txt)
    if not data:
        dbg.append("Crosscheck JSON parse failed.")
        return None, dbg

    has_conflict = bool(data.get("has_conflict", False))
    q = normalize(str(data.get("question", "") or ""))

    if has_conflict and q:
        st.session_state.crosscheck_used_for.add(main_index)
        dbg.append("Crosscheck conflict detected -> using conflict question.")
        return q, dbg

    st.session_state.crosscheck_used_for.add(main_index)
    dbg.append("Crosscheck: no conflict (or no question).")
    return None, dbg


def instruction_for_question(i: int, n: int, coach_id: str) -> str:
    """
    ê³ ì • ë¡œì§:
    - logic: ê°€ì • ê¹¨ê¸°(ì—­ë°œìƒ) ê³ ì • ì§ˆë¬¸ í¬í•¨
    - value: ê°ì • í›„ 'ê°ì • vs ê°€ì¹˜ ë¶„ë¦¬' ê³ ì •
    - action: If-Then íŠ¸ë¦¬ê±° + Pre-mortem í¬í•¨ + ë§ˆì§€ë§‰ Quick Win
    """
    if i == 0:
        return "ìƒí™©ì˜ í•µì‹¬ì„ ë” êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
    if i == 1:
        return "ì›í•˜ëŠ” ëª©í‘œë¥¼ ì¸¡ì • ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    # ì‹¤í–‰ ì½”ì¹˜
    if coach_id == "action":
        if i == n - 1:
            return (
                "â€˜ì§€ê¸ˆ ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì‘ì€ í–‰ë™â€™ì„ "
                "ìŠ¤ìŠ¤ë¡œ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ(Quick Win, ì¶”ì²œ ê¸ˆì§€)"
            )

        # n í¬ê¸°ì— ë”°ë¼ êµ¬ì„±
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ í¼ì¹˜ê³  Top1~3 ìš°ì„ ìˆœìœ„ë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸(íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ì„ ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œ)"
        if n >= 6 and i == 3:
            return "Top1ì„ â€˜1ë…„â†’ì´ë²ˆ ë‹¬â†’ì´ë²ˆ ì£¼â€™ë¡œ ìª¼ê°œ ì‚¬ìš©ìê°€ ê³„íšì„ ì ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ 1ê°œ(ì§€ì‹œ ê¸ˆì§€)"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return (
                "í”„ë¦¬ëª¨í…œ(Pre-mortem) + If-Then íŠ¸ë¦¬ê±° ì„¤ê³„ ì§ˆë¬¸ 1ê°œ. "
                "ì˜ˆ: â€˜2ì£¼ ë’¤ ì‹¤íŒ¨í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ 3ê°€ì§€ëŠ”?â€™ "
                "ê·¸ë¦¬ê³  ê° ì›ì¸ì— ëŒ€í•´ â€˜ë§Œì•½ (If) ~ ìƒí™©ì´ë©´ â†’ (Then) ~ í–‰ë™â€™ìœ¼ë¡œ ëŒ€ì‘ì„ ì ê²Œ í•˜ê¸°"
            )
        # ì¤‘ê°„ ë‹¨ê³„: If-Then íŠ¸ë¦¬ê±°ë¥¼ ë” ëª…í™•íˆ
        if n >= 6 and i == 4:
            return "ì‹¤í–‰ì„ â€˜ì–¸ì œâ€™ê°€ ì•„ë‹ˆë¼ â€˜If(ì–´ë–¤ ìƒí™©) â†’ Then(ì–´ë–¤ í–‰ë™)â€™ìœ¼ë¡œ ì„¤ê³„í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(íŠ¸ë¦¬ê±° 2~3ê°œ)"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ì¡°ê±´ì—ì„œ)í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    # êµ¬ì¡° ì½”ì¹˜
    if coach_id == "logic":
        if n >= 5 and i == n - 2:
            return (
                "ì—­ë°œìƒ/ë°˜ëŒ€ ìƒí™© ê°€ì • ì§ˆë¬¸ 1ê°œ. "
                "ì˜ˆ: â€˜ë§Œì•½ ë‹¹ì‹ ì´ ì„¸ìš´ ê¸°ì¤€ì´ ì™„ì „íˆ í‹€ë ¸ë‹¤ë©´ ì–´ë–¤ ìƒí™©ì´ ë²Œì–´ì§ˆê¹Œìš”?â€™ "
                "ë˜ëŠ” â€˜ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë‚®ë‹¤ê³  ìƒê°í•˜ëŠ” ì˜µì…˜ì´ ìœ ë¦¬í•´ì§€ëŠ” ì‹œë‚˜ë¦¬ì˜¤ëŠ”?â€™"
            )
        if i == 2:
            return "ì„ íƒ ê¸°ì¤€(3~5)ì„ ë½‘ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        if i == n - 2 and n < 5:
            return "ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì¶”ê°€ë¡œ í™•ì¸í•  ì •ë³´ 1~2ê°œë¥¼ ë“œëŸ¬ë‚´ëŠ” ì§ˆë¬¸ 1ê°œ"
        return "ì˜µì…˜/ì •ë³´/ì œì•½ì„ ë” ë¶„ë¦¬í•´ ëª…ë£Œí™”í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    # ê°€ì¹˜ ì½”ì¹˜
    if coach_id == "value":
        if i == 2:
            return "ì§€ê¸ˆ ê°ì •(2~3ê°œ)ê³¼ ê·¸ ê°ì •ì˜ ì´ìœ ë¥¼ ë§í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == 3 and n >= 5:
            return (
                "ê°ì •ê³¼ ê°€ì¹˜ì˜ ë¶„ë¦¬ ì§ˆë¬¸ 1ê°œ. "
                "ì˜ˆ: â€˜ì§€ê¸ˆì˜ ë¶ˆì•ˆì´ í•µì‹¬ ê°€ì¹˜ë¥¼ ì¹¨í•´í•´ì„œ ìƒê¸´ ê±´ê°€ìš”, ì•„ë‹ˆë©´ ë‚¯ì„  ë³€í™”ì— ëŒ€í•œ ë³¸ëŠ¥ì  ê±°ë¶€ê°ì¸ê°€ìš”?â€™"
            )
        if i == n - 2:
            return "í›„íšŒ ìµœì†Œí™” ê´€ì (1ë…„/5ë…„ í›„)ì„ ì ê²€í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"
        if i == n - 1:
            return "ë§ˆì§€ë§‰ìœ¼ë¡œ â€˜ë‚´ ê¸°ì¤€â€™ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì¶”ì²œ ê¸ˆì§€)"
        return "ê°€ì¹˜ Top3(ë‚´ê²Œ ì¤‘ìš”í•œ ê²ƒ)ì™€ ë‚´ë ¤ë†“ì„ ê²ƒ 1ê°œë¥¼ ì •ë¦¬í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ"

    return "ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ì •ë¦¬í•˜ë„ë¡ ë•ëŠ” ì§ˆë¬¸ 1ê°œ"


def fallback_question(coach_id: str, i: int, n: int) -> str:
    if i == 0:
        return "ì§€ê¸ˆ ê³ ë¯¼ì—ì„œ â€˜ê°€ì¥ í•µì‹¬ì ì¸ ìŸì â€™ì€ ë¬´ì—‡ì¸ê°€ìš”? (í•œ ë¬¸ì¥)"
    if i == 1:
        return "ì´ë²ˆ ê²°ì •ìœ¼ë¡œ ì–»ê³  ì‹¶ì€ ëª©í‘œë¥¼ â€˜ì¸¡ì • ê°€ëŠ¥í•˜ê²Œâ€™ ë°”ê¾¸ë©´ ì–´ë–»ê²Œ í‘œí˜„í•  ìˆ˜ ìˆë‚˜ìš”? (ì–¸ì œê¹Œì§€/ì–´ëŠ ì •ë„)"

    if coach_id == "action":
        if i == n - 1:
            return "ì•±ì„ ë„ê³  ë‚˜ì„œ 5ë¶„ ì•ˆì— í•  ìˆ˜ ìˆëŠ” â€˜ê°€ì¥ ì‘ì€ í–‰ë™â€™ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == 2:
            return "ì˜µì…˜/í•´ì•¼ í•  ì¼ 3~6ê°œë¥¼ ì ê³ , íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        if (n == 5 and i == 3) or (n >= 6 and i == n - 2):
            return "2ì£¼ ë’¤ ì‹¤íŒ¨í–ˆë‹¤ê³  ê°€ì •í•˜ë©´, ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì›ì¸ 3ê°€ì§€ëŠ” ë¬´ì—‡ì´ê³  ê°ê° â€˜ë§Œì•½ ~ì´ë©´ â†’ ~í•œë‹¤â€™ë¡œ ëŒ€ì‘ì„ ì ì–´ë³¼ ìˆ˜ ìˆë‚˜ìš”?"
        if n >= 6 and i == 3:
            return "Top1ì„ â€˜1ë…„ ëª©í‘œ â†’ ì´ë²ˆ ë‹¬ ëª©í‘œ â†’ ì´ë²ˆ ì£¼ ê³„íš(3ê°œ)â€™ë¡œ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if n >= 6 and i == 4:
            return "ì‹¤í–‰ì„ â€˜ì–¸ì œâ€™ê°€ ì•„ë‹ˆë¼ â€˜ë§Œì•½(If) ~ ìƒí™©ì´ë©´ â†’ ê·¸ëŸ¬ë©´(Then) ~ í–‰ë™â€™ìœ¼ë¡œ íŠ¸ë¦¬ê±° 2~3ê°œë¥¼ ë§Œë“¤ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        return "ë‹¤ìŒ í–‰ë™ì„ ë” êµ¬ì²´í™”í•˜ë©´(ë¬´ì—‡ì„/ì–¼ë§ˆë‚˜/ì–´ë–¤ ì¡°ê±´ì—ì„œ) ì–´ë–»ê²Œ ì ì„ ìˆ˜ ìˆë‚˜ìš”?"

    if coach_id == "logic":
        if n >= 5 and i == n - 2:
            return "ë§Œì•½ ë‹¹ì‹ ì´ ì„¸ìš´ ê¸°ì¤€ì´ ì™„ì „íˆ í‹€ë ¸ë‹¤ë©´ ì–´ë–¤ ìƒí™©ì´ ë²Œì–´ì§ˆê¹Œìš”?"
        if i == 2:
            return "ì´ ì„ íƒì„ í‰ê°€í•  ê¸°ì¤€ 3~5ê°œë¥¼ ì ì–´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 1:
            return "ì„ íƒ ê¸°ì¤€ì˜ ìš°ì„ ìˆœìœ„ë¥¼ 1~3ìœ„ë¡œ ì •ë¦¬í•˜ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 2 and n < 5:
            return "ì§€ê¸ˆ ê²°ì •ì„ ì–´ë µê²Œ ë§Œë“œëŠ” â€˜ë¶ˆí™•ì‹¤í•œ ê°€ì •/ì •ë³´â€™ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        return "ì˜µì…˜/ì œì•½/ì •ë³´ë¥¼ ë¶„ë¦¬í•´ì„œ ì§€ê¸ˆ ë¶€ì¡±í•œ ì •ë³´ëŠ” ë¬´ì—‡ì¸ì§€ ì ì–´ë³¼ê¹Œìš”?"

    # value
    if i == 2:
        return "ì§€ê¸ˆ ê°ì •ì„ 2~3ê°œ ë‹¨ì–´ë¡œ ì ê³ , ê° ê°ì •ì´ ìƒê¸´ ì´ìœ ë¥¼ í•œ ì¤„ì”© ì¨ë³¼ê¹Œìš”?"
    if i == 3 and n >= 5:
        return "ê·¸ ê°ì •ì€ â€˜ì§€ê¸ˆ ë‹¹ì¥ì˜ í¸ì•ˆí•¨â€™ ë•Œë¬¸ì¸ê°€ìš”, â€˜ë¯¸ë˜ì˜ ë‚˜ë¥¼ ìœ„í•œ ê°€ì¹˜â€™ ë•Œë¬¸ì¸ê°€ìš”?"
    if i == n - 2:
        return "1ë…„/5ë…„ ë’¤ì˜ ë‚´ê°€ ì§€ê¸ˆì˜ ë‚˜ì—ê²Œ ë­ë¼ê³  ë§í•´ì¤„ ê²ƒ ê°™ë‚˜ìš”?"
    return "ì´ ê³ ë¯¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°€ì¹˜ Top3ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"


def generate_question(i: int, n: int) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    prev_qs = st.session_state.questions[:]

    # 1) Logic Cross-Check: ì¶©ëŒ ì§ˆë¬¸ ìš°ì„  ìƒì„±(ê°€ëŠ¥í•˜ë©´)
    cross_q, cross_dbg = try_logic_crosscheck_question(i)
    if cross_q:
        # ì¤‘ë³µ ë°©ì§€ ì²´í¬ëŠ” ì•„ë˜ ê³µí†µ ë¡œì§ì—ì„œ ì²˜ë¦¬(ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ fallback)
        if not any(is_similar(cross_q, pq) for pq in prev_qs):
            return cross_q, None, cross_dbg
        cross_dbg.append("Crosscheck question was similar to previous. Falling back to normal generation.")
        # ì´ì–´ì„œ ì¼ë°˜ ìƒì„± ì§„í–‰
    dbg_acc: List[str] = cross_dbg[:]

    def prompt(nonce: int) -> str:
        prev_txt = "\n".join([f"- {q}" for q in prev_qs]) if prev_qs else "(ì—†ìŒ)"
        return textwrap.dedent(
            f"""
            [ì´ì „ ì§ˆë¬¸ ëª©ë¡]
            {prev_txt}

            {build_context_block()}

            [ì´ë²ˆ ì§ˆë¬¸ ëª©ì ]
            {instruction_for_question(i, n, coach["id"])}

            ê·œì¹™:
            - ê²°ë¡ /ì¶”ì²œ/ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
            - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥
            - ì´ì „ ì§ˆë¬¸ê³¼ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ í”¼í•˜ê¸°

            (nonce={nonce})
            """
        ).strip()

    q1, err, dbg = call_openai_text(system=system, user=prompt(random.randint(1000, 9999)), temperature=0.7)
    dbg_acc.extend(dbg)
    if not q1:
        return fallback_question(coach["id"], i, n), err, dbg_acc

    q1 = normalize(q1)
    if not any(is_similar(q1, pq) for pq in prev_qs):
        return q1, None, dbg_acc

    dbg_acc.append("Similar question detected. Regenerating once.")
    q2, err2, dbg2 = call_openai_text(system=system, user=prompt(random.randint(10000, 99999)), temperature=0.85)
    dbg_acc.extend(dbg2)
    if q2:
        q2 = normalize(q2)
        if not any(is_similar(q2, pq) for pq in prev_qs):
            return q2, None, dbg_acc

    dbg_acc.append("Still similar after retry. Using fallback.")
    return fallback_question(coach["id"], i, n), err2, dbg_acc


def ensure_question(index: int, total: int) -> None:
    while len(st.session_state.questions) <= index:
        i = len(st.session_state.questions)
        q, err, dbg = generate_question(i, total)
        st.session_state.debug_log = dbg
        st.session_state.questions.append(q)


def generate_probe_question(last_q: str, last_a: str) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_questions(coach)
    user = probing_instruction(last_q, last_a)
    q, err, dbg = call_openai_text(system=system, user=user, temperature=0.6)
    if not q:
        return "ë°©ê¸ˆ ë‹µë³€ì—ì„œ â€˜ì˜ˆì‹œ 1ê°œâ€™ë§Œ ë“¤ì–´ì„œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì„¤ëª…í•´ì¤„ ìˆ˜ ìˆì„ê¹Œìš”?", err, dbg
    return normalize(q), None, dbg


# =========================
# Final report (Mirroring only)
# =========================
FORBIDDEN_RECOMMEND_PATTERNS = [
    r"ì¶”ì²œ",
    r"~?í•˜ëŠ” ê²ƒì´ ì¢‹",
    r"í•´ì•¼ í•©ë‹ˆë‹¤",
    r"í•˜ì‹œê¸¸",
    r"í•˜ëŠ” ê²Œ ë‚«",
    r"Aë¥¼ ì„ íƒ",
    r"Bë¥¼ ì„ íƒ",
    r"ì •ë‹µ",
    r"ê²°ë¡ ",
]


def contains_forbidden_recommendation(text: str) -> bool:
    t = text or ""
    for pat in FORBIDDEN_RECOMMEND_PATTERNS:
        if re.search(pat, t):
            return True
    return False


def report_schema_hint(coach_id: str) -> str:
    base = """
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”(ì½”ë“œë¸”ë¡/ì„¤ëª… ê¸ˆì§€).
ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ í•˜ì§€ ë§ˆì„¸ìš”.
coaching_messageëŠ” ë°˜ë“œì‹œ "ê±°ìš¸ ë¹„ì¶”ê¸°(Mirroring)" í™”ë²•ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
- ì˜ˆ: "ë‹¹ì‹ ì€ ___ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤"
- ì˜ˆ: "ë‹¹ì‹ ì˜ ë‹µë³€ì—ì„œ ___ì™€ ___ ì‚¬ì´ì˜ ê¸´ì¥ì´ ë“œëŸ¬ë‚©ë‹ˆë‹¤"
ê¸ˆì§€ í‘œí˜„: "ì¶”ì²œ", "ì¢‹ê² ìŠµë‹ˆë‹¤", "í•´ì•¼ í•©ë‹ˆë‹¤", "í•˜ì", "ì •ë‹µ", "ê²°ë¡ ", "Aë¥¼ ì„ íƒ".
"""
    if coach_id == "action":
        return textwrap.dedent(
            base
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue": "string",
    "goal": "string",
    "constraints": ["string"],
    "options_mentioned": ["string"]
  },
  "criteria": [
    {"name":"string","priority":1-5,"why":"string"}
  ],
  "plan_visualization": {
    "year": "string",
    "month": "string",
    "week": ["string","string","string"]
  },
  "weekly_table": {
    "Mon": ["string"], "Tue": ["string"], "Wed": ["string"], "Thu": ["string"],
    "Fri": ["string"], "Sat": ["string"], "Sun": ["string"]
  },
  "coaching_message": ["string","string"],
  "next_self_question": "string"
}
"""
        ).strip()

    if coach_id == "logic":
        return textwrap.dedent(
            base
            + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "key_points": {"uncertainties":["string"], "tradeoffs":["string"]},
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
        ).strip()

    return textwrap.dedent(
        base
        + """
JSON ìŠ¤í‚¤ë§ˆ:
{
  "summary": {
    "core_issue":"string",
    "goal":"string",
    "constraints":["string"],
    "options_mentioned":["string"]
  },
  "criteria": [{"name":"string","priority":1-5,"why":"string"}],
  "emotions_values": {"emotions":["string","string"], "top_values":["string","string","string"]},
  "coaching_message":["string","string"],
  "next_self_question":"string"
}
"""
    ).strip()


def system_prompt_for_report() -> str:
    return (
        "ë‹¹ì‹ ì€ 'AI ê²°ì • ì½”ì¹­ ì•±'ì˜ ìµœì¢… ìš”ì•½ ìƒì„±ê¸°ì…ë‹ˆë‹¤.\n"
        "ì ˆëŒ€ ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œë¥¼ ì œì‹œí•˜ì§€ ë§ˆì„¸ìš”.\n"
        "ì˜¤ì§ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬/ê¸°ì¤€/ê¸´ì¥/ë¶ˆí™•ì‹¤ì„±ì„ ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)í•˜ì„¸ìš”.\n"
        "coaching_messageëŠ” ë°˜ë“œì‹œ ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ(â€˜ë‹¹ì‹ ì€ ~ë¡œ ë³´ì…ë‹ˆë‹¤â€™).\n"
        "ì¶œë ¥ì€ ë°˜ë“œì‹œ JSONë§Œ.\n"
    )


def build_qa_text_for_report() -> str:
    qa_text = ""
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        qa_text += f"{i}) ({tag}) Q: {qa['q']}\n   A: {qa['a']}\n"
    return qa_text


def generate_final_report_json() -> Tuple[Optional[Dict[str, Any]], Optional[str], List[str], Optional[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for_report()

    qa_text = build_qa_text_for_report()
    opts = parse_options()

    user = textwrap.dedent(
        f"""
{report_schema_hint(coach["id"])}

[ì„¸ì…˜ ì‹œì‘ ì •ë³´]
- ì¹´í…Œê³ ë¦¬: {st.session_state.category}
- ê²°ì • ìœ í˜•: {st.session_state.decision_type}
- ìƒí™© ì„¤ëª…: {st.session_state.situation}
- ì›í•˜ëŠ” ëª©í‘œ: {st.session_state.goal}
- ì˜µì…˜(ìˆë‹¤ë©´): {opts if opts else "(ì—†ìŒ)"}

[Q/A]
{qa_text}

ì¤‘ìš”:
- ì¶”ì²œ/ê²°ë¡ /ì •ë‹µ/ì§€ì‹œ ê¸ˆì§€
- coaching_messageëŠ” ê±°ìš¸ ë¹„ì¶”ê¸°ë§Œ
- ì‚¬ìš©ìê°€ ë§í•˜ì§€ ì•Šì€ ê³„íšì„ â€˜ì§€ì–´ë‚´ì§€â€™ ë§ˆì„¸ìš”
"""
    ).strip()

    text, err, dbg = call_openai_text(system=system, user=user, temperature=0.25)
    if not text:
        return None, err, dbg, None

    data = safe_json_parse(text)
    if data is None:
        return None, "ë¦¬í¬íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨(ëª¨ë¸ì´ JSONë§Œ ì¶œë ¥í•˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ)", dbg, text

    combined = json.dumps(data, ensure_ascii=False)
    if contains_forbidden_recommendation(combined):
        dbg.append("Forbidden recommendation-like phrasing detected. Regenerating once with stricter warning.")
        stricter_user = user + "\n\n[ê²½ê³ ] ì´ì „ ì¶œë ¥ì— ì¶”ì²œ/ì§€ì‹œ í‘œí˜„ì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ê³  ê±°ìš¸ ë¹„ì¶”ê¸° ë¬¸ì¥ë§Œ ì‚¬ìš©í•˜ì„¸ìš”."
        text2, err2, dbg2 = call_openai_text(system=system, user=stricter_user, temperature=0.1)
        dbg.extend(dbg2)
        if text2:
            data2 = safe_json_parse(text2)
            if data2 is not None and not contains_forbidden_recommendation(json.dumps(data2, ensure_ascii=False)):
                return data2, None, dbg, text2
        dbg.append("Regeneration did not fully remove forbidden phrasing.")
        return data, None, dbg, text

    return data, None, dbg, text


# =========================
# Report rendering
# =========================
def render_summary_block(data: Dict[str, Any]) -> None:
    s = data.get("summary", {}) or {}
    st.subheader("ê³ ë¯¼ì˜ í•µì‹¬ ìš”ì•½")
    c1, c2 = st.columns(2)
    with c1:
        st.write(f"**í•µì‹¬ ê³ ë¯¼:** {s.get('core_issue','')}")
        st.write(f"**ëª©í‘œ:** {s.get('goal','')}")
    with c2:
        cons = s.get("constraints", []) or []
        opts = s.get("options_mentioned", []) or []
        st.write("**ì œì•½/ì¡°ê±´:**")
        if cons:
            for x in cons:
                st.write(f"- {x}")
        else:
            st.caption("ì œì•½ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")
        st.write("**ì–¸ê¸‰ëœ ì˜µì…˜:**")
        if opts:
            for x in opts:
                st.write(f"- {x}")
        else:
            st.caption("ì˜µì…˜ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ì–´ìš”.")


def render_criteria(data: Dict[str, Any]) -> List[str]:
    st.subheader("ì„ íƒ ê¸°ì¤€ ì •ë¦¬(ìš°ì„ ìˆœìœ„ í¬í•¨)")
    crit = data.get("criteria", []) or []
    if not crit:
        st.caption("ì„ íƒ ê¸°ì¤€ì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")
        return []
    rows = []
    names: List[str] = []
    for c in crit:
        nm = str(c.get("name", "") or "").strip()
        if nm:
            names.append(nm)
        rows.append({"ê¸°ì¤€": nm, "ìš°ì„ ìˆœìœ„(1~5)": c.get("priority", ""), "ì™œ ì¤‘ìš”í•œê°€": c.get("why", "")})
    st.dataframe(rows, use_container_width=True, hide_index=True)
    return names


def render_action_visualization(data: Dict[str, Any]) -> None:
    st.subheader("ê³„íš ì •ë¦¬(ë…„ â†’ ë‹¬ â†’ ì£¼) â€” ì‚¬ìš©ì ë‹µë³€ ê¸°ë°˜")
    pv = data.get("plan_visualization", {}) or {}
    c1, c2, c3 = st.columns(3)
    c1.metric("ë…„", pv.get("year", "") or "-")
    c2.metric("ë‹¬", pv.get("month", "") or "-")
    c3.metric("ì£¼(í•µì‹¬ 3ê°œ)", " ")

    week = pv.get("week", []) or []
    if week:
        for x in week:
            st.write(f"- {x}")
    else:
        st.caption("ì‚¬ìš©ì ë‹µë³€ì—ì„œ ì£¼ ë‹¨ìœ„ ê³„íšì´ ì¶©ë¶„íˆ ë“œëŸ¬ë‚˜ì§€ ì•Šì•˜ì–´ìš”.")

    st.subheader("ì£¼ê°„ í…Œì´ë¸”(ì •ë¦¬ìš©)")
    cal = data.get("weekly_table", {}) or {}
    days = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
    table = [{"Day": d, "Tasks": "\n".join(cal.get(d, []) or [])} for d in days]
    st.dataframe(table, use_container_width=True, hide_index=True)


def render_key_points_logic(data: Dict[str, Any]) -> None:
    kp = data.get("key_points", {}) or {}
    st.subheader("ì •ë¦¬ í¬ì¸íŠ¸")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„(ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•œ ê²ƒ)**")
        for x in kp.get("uncertainties", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**íŠ¸ë ˆì´ë“œì˜¤í”„(ì–»ëŠ” ê²ƒ vs ìƒëŠ” ê²ƒ)**")
        for x in kp.get("tradeoffs", []) or []:
            st.write(f"- {x}")


def render_emotions_values(data: Dict[str, Any]) -> None:
    ev = data.get("emotions_values", {}) or {}
    st.subheader("ê°ì •/ê°€ì¹˜ ì •ë¦¬")
    c1, c2 = st.columns(2)
    with c1:
        st.write("**ê°ì •**")
        for x in ev.get("emotions", []) or []:
            st.write(f"- {x}")
    with c2:
        st.write("**ê°€ì¹˜ Top3**")
        for x in ev.get("top_values", []) or []:
            st.write(f"- {x}")


def render_coaching_message(data: Dict[str, Any]) -> None:
    st.subheader("ì½”ì¹­ ë©”ì‹œì§€(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    msgs = data.get("coaching_message", []) or []
    for m in msgs:
        st.write(f"- {m}")


def render_next_question(data: Dict[str, Any]) -> None:
    st.subheader("ë‹¤ìŒì— ìŠ¤ìŠ¤ë¡œì—ê²Œ ë˜ì§ˆ ì§ˆë¬¸(1ê°œ)")
    st.write(f"**{data.get('next_self_question','')}**")


# =========================
# Mirroring ë¶„ì„(í‚¤ì›Œë“œ/ê°ì •ì–´)
# =========================
STOPWORDS = {
    "ê·¸ëƒ¥",
    "ë„ˆë¬´",
    "ì§„ì§œ",
    "ê·¼ë°",
    "ê·¸ë¦¬ê³ ",
    "ê·¸ë˜ì„œ",
    "í•˜ì§€ë§Œ",
    "ì œê°€",
    "ì €ëŠ”",
    "ë‚˜ëŠ”",
    "ë‚´ê°€",
    "ì´ê²Œ",
    "ê·¸ê²Œ",
    "ì €",
    "ê²ƒ",
    "ìˆ˜",
    "ì¢€",
    "ì•½ê°„",
    "ë•Œë¬¸",
    "ë•Œë¬¸ì—",
    "ê°™ì•„ìš”",
    "ê°™ì€",
    "í•˜ëŠ”",
    "í•´ì•¼",
    "í•˜ê³ ",
    "ìˆëŠ”",
    "ìˆë‹¤",
    "ì—†ë‹¤",
    "ì—†ì–´ìš”",
    "ëª¨ë¥´ê² ",
    "ëª¨ë¥´ê² ì–´ìš”",
}

EMOTION_WORDS = [
    "ë¶ˆì•ˆ",
    "ë‘ë ¤ì›€",
    "ê±±ì •",
    "ê¸´ì¥",
    "ë‹µë‹µ",
    "í›„íšŒ",
    "ì£„ì±…ê°",
    "ë¶€ë‹´",
    "ìŠ¤íŠ¸ë ˆìŠ¤",
    "ìš°ìš¸",
    "ì§œì¦",
    "í™”",
    "ë¶„ë…¸",
    "ì„¤ë ˜",
    "ê¸°ëŒ€",
    "ì•ˆë„",
    "í¸ì•ˆ",
    "í–‰ë³µ",
    "ì˜ìš•",
    "ì§€ì¹¨",
    "ë²ˆì•„ì›ƒ",
]


def analyze_mirroring_from_answers() -> Tuple[pd.DataFrame, pd.DataFrame]:
    text = " ".join([str(x.get("a", "")) for x in st.session_state.answers if x.get("a")])
    clean = re.sub(r"[^\wê°€-í£ ]", " ", text)
    clean = re.sub(r"\s+", " ", clean).strip().lower()

    toks = [t for t in clean.split(" ") if len(t) >= 2 and t not in STOPWORDS]
    # í‚¤ì›Œë“œ ë¹ˆë„
    freq: Dict[str, int] = {}
    for t in toks:
        freq[t] = freq.get(t, 0) + 1
    kw = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:10]
    kw_df = pd.DataFrame(kw, columns=["í‚¤ì›Œë“œ", "ë¹ˆë„"])

    # ê°ì •ì–´ ë¹ˆë„(ë¶€ë¶„ í¬í•¨)
    emo_freq: Dict[str, int] = {}
    for ew in EMOTION_WORDS:
        c = len(re.findall(re.escape(ew), text))
        if c > 0:
            emo_freq[ew] = c
    emo = sorted(emo_freq.items(), key=lambda x: x[1], reverse=True)[:10]
    emo_df = pd.DataFrame(emo, columns=["ê°ì •ì–´", "ë¹ˆë„"])
    return kw_df, emo_df


def render_mirroring_visual() -> None:
    st.subheader("ë‚´ë©´ì˜ ëª©ì†Œë¦¬(Mirroring) â€” ë‹µë³€ì—ì„œ ë§ì´ ë“±ì¥í•œ í‘œí˜„")
    kw_df, emo_df = analyze_mirroring_from_answers()

    c1, c2 = st.columns(2)
    with c1:
        st.write("**ìì£¼ ë“±ì¥í•œ í‚¤ì›Œë“œ(Top 10)**")
        if len(kw_df) == 0:
            st.caption("í‚¤ì›Œë“œê°€ ì¶©ë¶„íˆ ì¡íˆì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(kw_df, use_container_width=True, hide_index=True)
            st.bar_chart(kw_df.set_index("í‚¤ì›Œë“œ")["ë¹ˆë„"])
    with c2:
        st.write("**ê°ì •ì–´(Top 10)**")
        if len(emo_df) == 0:
            st.caption("ëšœë ·í•œ ê°ì •ì–´ê°€ ë§ì´ ë“±ì¥í•˜ì§€ ì•Šì•˜ì–´ìš”.")
        else:
            st.dataframe(emo_df, use_container_width=True, hide_index=True)
            st.bar_chart(emo_df.set_index("ê°ì •ì–´")["ë¹ˆë„"])

    st.caption("ì´ ê²°ê³¼ëŠ” â€˜ì •ë‹µâ€™ì´ ì•„ë‹ˆë¼, ë‹¹ì‹ ì˜ ë‹µë³€ì— ë‚˜íƒ€ë‚œ ë°˜ë³µ í‘œí˜„ì„ ìš”ì•½í•œ ê±°ìš¸ì…ë‹ˆë‹¤.")


# =========================
# ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤
# =========================
def build_decision_matrix(options: List[str], criteria_names: List[str]) -> pd.DataFrame:
    if not options:
        options = ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]
    if not criteria_names:
        criteria_names = ["ê¸°ì¤€ 1", "ê¸°ì¤€ 2", "ê¸°ì¤€ 3"]

    cols = ["ì˜µì…˜"] + criteria_names + ["ë©”ëª¨"]
    rows = []
    for opt in options:
        r = {"ì˜µì…˜": opt, "ë©”ëª¨": ""}
        for c in criteria_names:
            r[c] = 3
        rows.append(r)
    return pd.DataFrame(rows, columns=cols)


def render_decision_matrix(criteria_names: List[str], data: Dict[str, Any]) -> None:
    st.subheader("ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(ì§ì ‘ ì ìˆ˜ ë§¤ê¸°ê¸°)")
    st.caption("ê° ì˜µì…˜ì´ â€˜ë‚´ ê¸°ì¤€â€™ì—ì„œ ì–´ëŠ ì •ë„ì¸ì§€ 1~5ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”. ì ìˆ˜ ìì²´ëŠ” ê²°ë¡ ì´ ì•„ë‹ˆë¼, ìƒê°ì„ êº¼ë‚´ëŠ” ë„êµ¬ì˜ˆìš”.")

    # ì˜µì…˜ ì†ŒìŠ¤: ì‚¬ìš©ì ì…ë ¥ options â†’ ì—†ìœ¼ë©´ ë¦¬í¬íŠ¸ì˜ options_mentioned â†’ ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê¸°ë³¸
    user_opts = parse_options()
    report_opts = (data.get("summary", {}) or {}).get("options_mentioned", []) or []
    opts = user_opts or [str(x) for x in report_opts if str(x).strip()] or ["ì˜µì…˜ 1", "ì˜µì…˜ 2"]

    if st.session_state.decision_matrix_df is None:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)

    df: pd.DataFrame = st.session_state.decision_matrix_df

    # ì˜µì…˜ ë³€ê²½ì— ëŒ€ì‘(ê°„ë‹¨ ë™ê¸°í™”)
    existing_opts = [str(x) for x in df["ì˜µì…˜"].tolist()] if "ì˜µì…˜" in df.columns else []
    if set(existing_opts) != set(opts):
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    # ê¸°ì¤€ ë³€ê²½ì— ëŒ€ì‘(ê°„ë‹¨ ë™ê¸°í™”)
    desired_cols = ["ì˜µì…˜"] + (criteria_names or []) + ["ë©”ëª¨"]
    if list(df.columns) != desired_cols:
        st.session_state.decision_matrix_df = build_decision_matrix(opts, criteria_names)
        df = st.session_state.decision_matrix_df

    col_cfg: Dict[str, Any] = {}
    for c in criteria_names:
        col_cfg[c] = st.column_config.NumberColumn(c, min_value=1, max_value=5, step=1, format="%d")

    edited = st.data_editor(
        df,
        use_container_width=True,
        hide_index=True,
        column_config=col_cfg,
        num_rows="fixed",
    )
    st.session_state.decision_matrix_df = edited

    # í•©ê³„(ì°¸ê³ ìš©)
    if criteria_names:
        try:
            totals = edited[criteria_names].sum(axis=1)
            show = edited.copy()
            show["ì´ì (ì°¸ê³ )"] = totals
            st.write("**ì´ì (ì°¸ê³ ìš©)**")
            st.dataframe(show[["ì˜µì…˜", "ì´ì (ì°¸ê³ )"]], use_container_width=True, hide_index=True)
            st.caption("ì´ì ì€ â€˜ê²°ë¡ â€™ì´ ì•„ë‹ˆë¼, ì–´ë–¤ ì˜µì…˜ì´ ì–´ë–¤ ê¸°ì¤€ì—ì„œ ê°•/ì•½í•œì§€ ë‹¤ì‹œ ë³´ê²Œ í•˜ëŠ” ì°¸ê³ ì¹˜ì˜ˆìš”.")
        except Exception:
            pass


# =========================
# ê³µìœ /ì €ì¥(í´ë¦½ë³´ë“œ + ë‹¤ìš´ë¡œë“œ)
# =========================
def render_copy_to_clipboard_button(text: str, button_label: str = "í´ë¦½ë³´ë“œì— ë³µì‚¬") -> None:
    # Streamlit ê¸°ë³¸ì— ë³µì‚¬ ê¸°ëŠ¥ì´ ì—†ì–´ JSë¡œ êµ¬í˜„
    # (HTTPS/ë¸Œë¼ìš°ì € ì •ì±…ì— ë”°ë¼ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
    safe = text.replace("\\", "\\\\").replace("`", "\\`").replace("${", "\\${")
    html = f"""
    <div style="display:flex; gap:8px; align-items:center;">
      <button
        onclick="navigator.clipboard.writeText(`{safe}`).then(()=>{{const el=document.getElementById('cpmsg'); el.innerText='ë³µì‚¬ë¨'; setTimeout(()=>el.innerText='',1200);}});"
        style="padding:8px 12px; border-radius:10px; border:1px solid #444; background:#111; color:#fff; cursor:pointer;">
        {button_label}
      </button>
      <span id="cpmsg" style="font-size:12px; opacity:0.8;"></span>
    </div>
    """
    st.components.v1.html(html, height=55)


def build_report_text_for_export(data: Dict[str, Any]) -> str:
    lines: List[str] = []
    lines.append("ğŸª¨ ëŒë©©ì´ AI ê²°ì • ì½”ì¹­ â€” ìµœì¢… ì •ë¦¬(ê±°ìš¸ ë¹„ì¶”ê¸°)")
    lines.append(f"- ìƒì„± ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("[ì„¸ì…˜ ì •ë³´]")
    lines.append(f"- ì¹´í…Œê³ ë¦¬: {st.session_state.category}")
    lines.append(f"- ê²°ì • ìœ í˜•: {st.session_state.decision_type}")
    lines.append(f"- ìƒí™© ì„¤ëª…: {st.session_state.situation}")
    lines.append(f"- ëª©í‘œ: {st.session_state.goal}")
    lines.append(f"- ì˜µì…˜: {st.session_state.options or '(ì—†ìŒ)'}")
    lines.append("")
    lines.append("[ë¦¬í¬íŠ¸ JSON]")
    lines.append(json.dumps(data, ensure_ascii=False, indent=2))
    lines.append("")
    lines.append("[Q/A]")
    for i, qa in enumerate(st.session_state.answers, start=1):
        tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
        lines.append(f"{i}. ({tag}) Q: {qa['q']}")
        lines.append(f"   A: {qa['a']}")
        lines.append(f"   ts: {qa['ts']}")
        lines.append("")
    return "\n".join(lines).strip()


# =========================
# Back ë²„íŠ¼ ë¡œì§
# =========================
def handle_back() -> None:
    """
    ìš”êµ¬ì‚¬í•­:
    - ì§ˆë¬¸ í™”ë©´ì—ì„œ q_indexë¥¼ ì¤„ì´ê³  answersì—ì„œ ë§ˆì§€ë§‰ ë‹µë³€ì„ ì œê±°í•˜ì—¬ ì´ì „ ì§ˆë¬¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°
    - probe ìƒíƒœê°€ ê¼¬ì´ì§€ ì•Šë„ë¡ ì •ë¦¬
    """
    if not st.session_state.answers:
        st.session_state.q_index = max(0, int(st.session_state.q_index) - 1)
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        return

    last = st.session_state.answers.pop()

    # probeëŠ” ê°™ì€ main_indexì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸ì´ë¯€ë¡œ, ë’¤ë¡œ ê°€ê¸° ì‹œ probe ëª¨ë“œ í•´ì œí•˜ê³  í•´ë‹¹ mainìœ¼ë¡œ ìœ ì§€
    if last.get("kind") == "probe":
        st.session_state.probe_active = False
        st.session_state.probe_question = ""
        st.session_state.probe_for_index = None
        # q_indexëŠ” lastì˜ main_indexë¡œ ë§ì¶¤(ëŒ€ê°œ í˜„ì¬)
        st.session_state.q_index = int(last.get("main_index", st.session_state.q_index))
        return

    # main ë‹µë³€ì„ ë˜ëŒë¦¬ë©´, í•´ë‹¹ ì§ˆë¬¸ìœ¼ë¡œ ëŒì•„ê°€ì•¼ í•¨
    mi = int(last.get("main_index", 0))
    st.session_state.probe_active = False
    st.session_state.probe_question = ""
    st.session_state.probe_for_index = None
    st.session_state.q_index = max(0, mi)


# =========================
# Sidebar: ê²°ì • ìœ í˜• í…œí”Œë¦¿ ìë™ ì…ë ¥
# =========================
def on_decision_type_change() -> None:
    new_dt = st.session_state.decision_type
    prev_dt = st.session_state.last_decision_type
    st.session_state.last_decision_type = new_dt

    template = DECISION_TEMPLATES.get(new_dt, "")
    if not template:
        return

    cur = (st.session_state.situation or "").strip()
    # "ìë™ ì…ë ¥"ì´ì§€ë§Œ, ì‚¬ìš©ìê°€ ì´ë¯¸ ì‘ì„±í•œ ë‚´ìš©ì„ ë®ì–´ì“°ì§€ ì•Šë„ë¡:
    # - ë¹„ì–´ìˆê±°ë‚˜
    # - ê¸°ì¡´ì´ [ê°€ì´ë“œ]ë¡œ ì‹œì‘í•˜ë©´(í…œí”Œë¦¿ ìƒíƒœ) ë®ì–´ì“°ê¸°
    if (not cur) or cur.startswith("[ê°€ì´ë“œ]"):
        st.session_state.situation = template


# =========================
# App UI
# =========================
init_state()

with st.sidebar:
    st.header("ì„¤ì •")
    st.text_input("OpenAI API Key (Secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()
    st.subheader("ìƒí™© ì„¤ì •(ì„¸ì…˜ ì‹œì‘)")
    st.selectbox("ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")

    st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type", on_change=on_decision_type_change)

    st.text_area("ìƒí™© ì„¤ëª…", key="situation", height=120, placeholder="ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆê³  ë¬´ì—‡ì„ ê²°ì •í•´ì•¼ í•˜ë‚˜ìš”?")
    st.text_input("ì›í•˜ëŠ” ëª©í‘œ", key="goal", placeholder="ì´ ê²°ì •ì—ì„œ ì–»ê³  ì‹¶ì€ ê²°ê³¼(ê°€ëŠ¥í•˜ë©´ ì¸¡ì • ê°€ëŠ¥í•˜ê²Œ)")
    st.text_input("ì˜µì…˜(ì‰¼í‘œë¡œ êµ¬ë¶„, ì„ íƒ)", key="options", placeholder="ì˜ˆ: A, B, C")

    with st.expander("ê²°ì • ìœ í˜• ê°€ì´ë“œ ë‹¤ì‹œ ë„£ê¸°"):
        st.caption("ìƒí™© ì„¤ëª…ì´ ë¹„ì–´ìˆê±°ë‚˜ [ê°€ì´ë“œ] í…ìŠ¤íŠ¸ë¼ë©´, ê²°ì • ìœ í˜•ì— ë§ì¶˜ í…œí”Œë¦¿ì´ ìë™ìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤.")
        if st.button("ê°€ì´ë“œ ì‚½ì…/ê°±ì‹ ", use_container_width=True):
            tmpl = DECISION_TEMPLATES.get(st.session_state.decision_type, "")
            if tmpl:
                st.session_state.situation = tmpl
                st.rerun()

    st.divider()
    st.subheader("ì½”ì¹˜ ì„ íƒ")
    coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
    cur = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
    picked = st.radio("ì½”ì¹˜", coach_labels, index=cur)
    st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]
    coach = coach_by_id(st.session_state.coach_id)
    with st.expander("ì½”ì¹˜ ì§„í–‰ ë°©ì‹"):
        st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
        for m in coach["method"]:
            st.write(f"- {m}")
        st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.divider()
    st.subheader("ì§ˆë¬¸ ê°œìˆ˜")
    st.session_state.num_questions = st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions))

    st.divider()
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ì²˜ìŒë¶€í„°", use_container_width=True):
            reset_flow("setup")
            st.rerun()
    with c2:
        if st.session_state.page == "setup":
            if st.button("ì§ˆë¬¸ ì‹œì‘", type="primary", use_container_width=True):
                reset_flow("questions")
                st.rerun()
        elif st.session_state.page == "questions":
            done = main_answer_count() >= int(st.session_state.num_questions)
            if st.button("ìµœì¢… ê²°ê³¼ë¡œ", use_container_width=True, disabled=not done):
                st.session_state.page = "report"
                st.session_state.report_just_entered = True
                st.rerun()
        else:
            if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ", use_container_width=True):
                st.session_state.page = "questions"
                st.rerun()

# Progress (ëŒë‹¤ë¦¬ + ì‚¬ëŒ)
nq = int(st.session_state.num_questions)
labels = ["ì„¤ì •"] + [f"Q{i}" for i in range(1, nq + 1)] + ["ìš”ì•½"]

if st.session_state.page == "setup":
    idx = 0
elif st.session_state.page == "questions":
    idx = 1 + int(st.session_state.q_index)
else:
    idx = 1 + nq

render_pebble_bridge(idx, len(labels), labels)

progress = idx / max(1, (len(labels) - 1))
with st.columns([1, 2, 1])[1]:
    render_hero_pebble(progress, f"ì§„í–‰ë„: {int(progress * 100)}%")

st.divider()

coach = coach_by_id(st.session_state.coach_id)

if st.session_state.page == "setup":
    st.title("ğŸª¨ AI ê²°ì • ì½”ì¹­")
    st.caption("ì •ë‹µì„ ì£¼ê¸°ë³´ë‹¤, ì§ˆë¬¸ìœ¼ë¡œ ìƒê°ì„ ì •ë¦¬í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤. í•œ í™”ë©´ì— í•œ ì§ˆë¬¸ì”© ì§„í–‰ë©ë‹ˆë‹¤.")
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ìƒí™©ì„ ì…ë ¥í•˜ê³  â€˜ì§ˆë¬¸ ì‹œì‘â€™ì„ ëˆ„ë¥´ì„¸ìš”.")

    with st.container(border=True):
        st.subheader("í˜„ì¬ ì„¤ì • ë¯¸ë¦¬ë³´ê¸°")
        st.write(f"- ì¹´í…Œê³ ë¦¬: {st.session_state.category}")
        st.write(f"- ê²°ì • ìœ í˜•: {st.session_state.decision_type}")
        st.write(f"- ì½”ì¹˜: {coach['name']}")
        st.write(f"- ì§ˆë¬¸ ê°œìˆ˜: {nq}")
        st.write(f"- ìƒí™© ì„¤ëª…: {st.session_state.situation or '(ë¯¸ì…ë ¥)'}")
        st.write(f"- ëª©í‘œ: {st.session_state.goal or '(ë¯¸ì…ë ¥)'}")
        st.write(f"- ì˜µì…˜: {st.session_state.options or '(ë¯¸ì…ë ¥)'}")

elif st.session_state.page == "questions":
    st.title("ì§ˆë¬¸")
    st.caption("í•œ í™”ë©´ì— í•œ ì§ˆë¬¸. ë‹µë³€ì„ ì €ì¥í•˜ë©´ ë‹¤ìŒìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤. (ë‹µë³€ì´ 10ì ë¯¸ë§Œì´ë©´ 1íšŒ êµ¬ì²´í™” ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤)")

    q_idx = int(st.session_state.q_index)
    q_idx = max(0, min(q_idx, nq - 1))

    # ë©”ì¸ ì§ˆë¬¸ ì¤€ë¹„
    ensure_question(q_idx, nq)
    main_q = st.session_state.questions[q_idx]

    # í˜„ì¬ í‘œì‹œí•  ì§ˆë¬¸: probeê°€ í™œì„±í™”ë©´ probe, ì•„ë‹ˆë©´ main
    if st.session_state.probe_active and st.session_state.probe_for_index == q_idx:
        show_q = st.session_state.probe_question
        kind = "probe"
        badge = "ì¶”ê°€ ì§ˆë¬¸(êµ¬ì²´í™”)"
    else:
        show_q = main_q
        kind = "main"
        badge = "ë©”ì¸ ì§ˆë¬¸"

    # ìƒë‹¨ ì»¨íŠ¸ë¡¤: Back
    top_c1, top_c2, top_c3 = st.columns([1, 2, 1])
    with top_c1:
        if st.button("â¬…ï¸ ì´ì „ìœ¼ë¡œ", use_container_width=True, disabled=(q_idx == 0 and not st.session_state.answers)):
            handle_back()
            st.rerun()
    with top_c3:
        st.caption(f"ë©”ì¸ ë‹µë³€: {main_answer_count()} / {nq}")

    st.subheader(f"Q{q_idx + 1} / {nq}  Â·  {badge}")
    with st.container(border=True):
        st.markdown(f"**{show_q}**")

    with st.form(f"answer_form_{q_idx}_{kind}", clear_on_submit=True):
        hint = ""
        if st.session_state.answers:
            last_a = st.session_state.answers[-1]["a"]
            hint = f"ì´ì „ ë‹µ ìš”ì•½: {last_a[:90]}{'â€¦' if len(last_a) > 90 else ''}"
        ans = st.text_area("ë‹µë³€", placeholder=hint or "ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", height=150)
        submitted = st.form_submit_button("ë‹µë³€ ì €ì¥", use_container_width=True)

    if submitted:
        a = (ans or "").strip()
        if not a:
            st.warning("ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í•œ ì¤„ë§Œ ì…ë ¥í•´ë„ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            add_answer(show_q, a, kind=kind, main_index=q_idx)

            if kind == "probe":
                # probe ì¢…ë£Œ â†’ ë‹¤ìŒ mainìœ¼ë¡œ
                st.session_state.probe_active = False
                st.session_state.probe_question = ""
                st.session_state.probe_for_index = None
                st.session_state.q_index = min(q_idx + 1, nq - 1)

            else:
                # main ë‹µë³€ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ probe ìƒì„±(1íšŒ) + ê°™ì€ ë‹¨ê³„ ìœ ì§€
                if is_too_short_answer(a):
                    pq, err, dbg = generate_probe_question(show_q, a)
                    st.session_state.debug_log = dbg
                    st.session_state.probe_active = True
                    st.session_state.probe_question = pq
                    st.session_state.probe_for_index = q_idx
                else:
                    # ì •ìƒ ì§„í–‰
                    if main_answer_count() >= nq:
                        st.session_state.page = "report"
                        st.session_state.report_just_entered = True
                        st.session_state.q_index = nq - 1
                    else:
                        st.session_state.q_index = min(q_idx + 1, nq - 1)

            st.rerun()

    with st.expander("ë‹µë³€ ê¸°ë¡"):
        grouped: Dict[int, List[Dict[str, Any]]] = {}
        for qa in st.session_state.answers:
            grouped.setdefault(int(qa.get("main_index", 0)), []).append(qa)

        for mi in sorted(grouped.keys()):
            st.markdown(f"### Q{mi + 1}")
            for qa in grouped[mi]:
                tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
                st.markdown(f"**({tag}) {qa['q']}**")
                st.write(qa["a"])
                st.caption(qa["ts"])
                st.divider()

    with st.expander("ë””ë²„ê·¸ ë¡œê·¸"):
        st.write(st.session_state.debug_log)

else:
    st.title("ìµœì¢… ì •ë¦¬")
    st.caption("ì¶”ì²œ/ì •ë‹µ ì—†ì´, ê³ ë¯¼ì˜ í•µì‹¬ê³¼ ê¸°ì¤€ì„ â€˜ê±°ìš¸ ë¹„ì¶”ê¸°â€™ ë°©ì‹ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.")

    if st.session_state.report_just_entered:
        st.balloons()
        st.session_state.report_just_entered = False

    if main_answer_count() < nq:
        st.warning("ì•„ì§ ëª¨ë“  ë©”ì¸ ì§ˆë¬¸ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì§ˆë¬¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ ë‹µë³€ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ ì´ë™", type="primary"):
            st.session_state.page = "questions"
            st.rerun()
        st.stop()

    colA, colB = st.columns([1, 1])
    with colA:
        gen = st.button("ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨", type="primary", use_container_width=True)
    with colB:
        if st.button("ìƒˆ ì„¸ì…˜ ì‹œì‘", use_container_width=True):
            reset_flow("setup")
            st.rerun()

    if gen or (st.session_state.final_report_json is None and st.session_state.final_report_raw is None):
        with st.spinner("ìµœì¢… ì •ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            data, err, dbg, raw = generate_final_report_json()
            st.session_state.debug_log = dbg
            if data is not None:
                st.session_state.final_report_json = data
                st.session_state.final_report_raw = raw
            else:
                st.session_state.final_report_json = None
                st.session_state.final_report_raw = raw
                st.error(err or "ì •ë¦¬ ìƒì„± ì‹¤íŒ¨")

    data = st.session_state.final_report_json
    if data:
        st.success("ìµœì¢… ì •ë¦¬ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

        render_summary_block(data)
        criteria_names = render_criteria(data)

        # ì˜ì‚¬ê²°ì • ë§¤íŠ¸ë¦­ìŠ¤(ì˜µì…˜xê¸°ì¤€)
        render_decision_matrix(criteria_names, data)

        # ì½”ì¹˜ë³„ ì„¹ì…˜
        if coach["id"] == "action":
            render_action_visualization(data)
        elif coach["id"] == "logic":
            render_key_points_logic(data)
        else:
            render_emotions_values(data)

        # ë‚´ë©´ì˜ ëª©ì†Œë¦¬(Mirroring ì‹œê°í™”)
        render_mirroring_visual()

        render_coaching_message(data)
        render_next_question(data)

        st.subheader("ê³µìœ /ì €ì¥")
        export_text = build_report_text_for_export(data)
        render_copy_to_clipboard_button(export_text, "ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ ë³µì‚¬")

        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.download_button(
            "ë¦¬í¬íŠ¸ .txt ë‹¤ìš´ë¡œë“œ",
            data=export_text.encode("utf-8"),
            file_name=f"pebble_decision_report_{ts}.txt",
            mime="text/plain",
            use_container_width=True,
        )

        st.subheader("ê³µìœ ìš©(JSON)")
        st.code(json.dumps(data, ensure_ascii=False, indent=2), language="json")

        if contains_forbidden_recommendation(json.dumps(data, ensure_ascii=False)):
            st.warning("ë¦¬í¬íŠ¸ì— ì¶”ì²œ/ì§€ì‹œì²˜ëŸ¼ ë³´ì´ëŠ” í‘œí˜„ì´ ì„ì˜€ì„ ìˆ˜ ìˆì–´ìš”. í•„ìš”í•˜ë©´ â€˜ì •ë¦¬ ìƒì„±/ìƒˆë¡œê³ ì¹¨â€™ì„ ëˆŒëŸ¬ ë³´ì„¸ìš”.")

        # ê²°ì • ìœ íš¨ê¸°ê°„ ë¬¸êµ¬
        valid_until = (datetime.now().date() + timedelta(days=7)).strftime("%Y-%m-%d")
        st.divider()
        st.caption(f"ì´ ì •ë¦¬ëŠ” **{valid_until}**ê¹Œì§€ ìœ íš¨í•©ë‹ˆë‹¤.")

    elif st.session_state.final_report_raw:
        st.warning("JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë¬¸ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
        st.code(st.session_state.final_report_raw, language="text")

    with st.expander("Q/A ì „ì²´ ë³´ê¸°"):
        for i, qa in enumerate(st.session_state.answers, start=1):
            tag = "PROBE" if qa.get("kind") == "probe" else "MAIN"
            st.markdown(f"**{i}. ({tag}) {qa['q']}**")
            st.write(qa["a"])
            st.caption(qa["ts"])
            st.divider()

    with st.expander("ë””ë²„ê·¸ ë¡œê·¸"):
        st.write(st.session_state.debug_log)

st.divider()
with st.expander("ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (Streamlit Cloud)"):
    st.markdown(
        """
- Secrets ì„¤ì •: Settings â†’ Secretsì— `OPENAI_API_KEY = "sk-..."` ì¶”ê°€
- requirements.txt:
  - streamlit
  - openai
  - pandas
"""
    )

