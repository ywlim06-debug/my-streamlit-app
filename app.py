# app.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸª¨ ëŒë©©ì´ ê²°ì • ì½”ì¹˜ (Pebble Decision Coach)
#
# ìš”ì²­ ë°˜ì˜:
# - ì§ˆë¬¸ ê°œìˆ˜ ì„¤ì •(2~10)
# - ì§ˆë¬¸ ì™„ë£Œ í›„ "ë ˆí¬íŠ¸ í˜ì´ì§€"ë¡œ ì´ë™(session_state ë¼ìš°íŒ…)
# - ì§ˆë¬¸ ì¤‘ë³µ ë°©ì§€(ìœ ì‚¬í•˜ë©´ 1íšŒ ì¬ìƒì„± + fallback)
# - ì‹¤í–‰ ì½”ì¹˜ ì§„í–‰ ë°©ì‹ ê°•í™”:
#   1) ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°(ê°€ì¹˜/íš¨ê³¼/ë‚œì´ë„ ê¸°ì¤€)
#   2) ê³„íš ì§ˆë¬¸ ì¶”ê°€: ë…„ â†’ ë‹¬ â†’ ì£¼(ëª©í‘œë¥¼ ìª¼ê°œëŠ” ì§ˆë¬¸)
#   3) If-Then, ì¥ì• ë¬¼ ëŒ€ì‘, 7ì¼ ì‹¤í—˜, ì²´í¬ë¦¬ìŠ¤íŠ¸
# - Streamlit Cloud: st.secrets["OPENAI_API_KEY"] ìš°ì„ 
# - SVGëŠ” base64 HTMLë¡œ ë Œë”ë§(PIL ì˜¤ë¥˜ ë°©ì§€)
#
# í•„ìš” íŒ¨í‚¤ì§€:
#   pip install streamlit openai
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from __future__ import annotations

import base64
import json
import random
import re
import textwrap
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import streamlit as st

try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # type: ignore


# =========================
# Page Config
# =========================
st.set_page_config(page_title="ëŒë©©ì´ ê²°ì • ì½”ì¹˜", page_icon="ğŸª¨", layout="wide")

MODEL_PRIMARY = "gpt-5-mini"
MODEL_FALLBACK = "gpt-4o-mini"

TOPIC_CATEGORIES = [
    ("ğŸ“ í•™ì—…/ì§„ë¡œ", "í•™ì—…, ì „ê³µ ì„ íƒ, ì§„ë¡œ ë°©í–¥, ì·¨ì—…/ì´ì§, ëª©í‘œ ì„¤ì •"),
    ("ğŸ’¼ ì»¤ë¦¬ì–´/ì¼", "ì—…ë¬´ ì„ íƒ, í”„ë¡œì íŠ¸, í˜‘ì—…, ë¦¬ë”ì‹­, ì»¤ë¦¬ì–´ ì„±ì¥"),
    ("ğŸ’– ê´€ê³„", "ì¹œêµ¬/ì—°ì¸/ê°€ì¡±, ê°ˆë“±, ì†Œí†µ, ê±°ë¦¬ë‘ê¸°, ì„ íƒì˜ ê¸°ì¤€"),
    ("ğŸ’° ëˆ/ì†Œë¹„", "ì˜ˆì‚°, ì†Œë¹„ ìŠµê´€, íˆ¬ì/ì €ì¶•, í° êµ¬ë§¤ ê²°ì •"),
    ("ğŸ§  ë§ˆìŒ/ì‚¶", "ë¶ˆì•ˆ/ë²ˆì•„ì›ƒ, ê°€ì¹˜ê´€, ì¸ìƒ ë°©í–¥, ë£¨í‹´/ê· í˜•"),
    ("ğŸ“¦ ê¸°íƒ€", "ì •ë¦¬ë˜ì§€ ì•Šì€ ê³ ë¯¼, ì¼ìƒ ì„ íƒ, ê¸°íƒ€"),
]

DECISION_TYPES = [
    "A vs B ì„ íƒ(ë‘˜ ì¤‘ í•˜ë‚˜)",
    "ì—¬ëŸ¬ ì˜µì…˜ ì¤‘ ì„ íƒ",
    "í•´ì•¼ í• ì§€ ë§ì§€(Yes/No)",
    "ì–¸ì œ/ì–´ë–»ê²Œ í• ì§€(ì „ëµ/ì‹œì )",
    "ê°ˆë“± í•´ê²°/ëŒ€í™” ë°©í–¥",
]

COACHES = [
    {
        "id": "logic",
        "name": "ğŸ” ë…¼ë¦¬ ì½”ì¹˜",
        "tagline": "ì •ë³´ë¥¼ êµ¬ì¡°í™”í•´ì„œ ê²°ì •ì„ ëª…ë£Œí•˜ê²Œ ë•ìŠµë‹ˆë‹¤",
        "style": "ë…¼ë¦¬ì /ê°„ê²°/í”„ë ˆì„ì›Œí¬ ì¤‘ì‹¬",
        "method": [
            "í•µì‹¬ ìŸì Â·ì œì•½ì¡°ê±´ ì •ì˜",
            "ì˜µì…˜/ê¸°ì¤€/ê°€ì¤‘ì¹˜ ì •ë¦¬",
            "ì¥ë‹¨ì Â·ë¦¬ìŠ¤í¬Â·ê°€ì • ê²€ì¦",
            "ê²°ë¡  + ì„ íƒ ê·¼ê±°",
        ],
        "prompt_hint": "MECE, ê¸°ì¤€í‘œ, ë¦¬ìŠ¤í¬/ê°€ì • ê²€ì¦",
    },
    {
        "id": "value",
        "name": "ğŸ’— ê°€ì¹˜/ê°ì • ì½”ì¹˜",
        "tagline": "ê°ì •ê³¼ ê°€ì¹˜ê´€ì„ ëª…ë£Œí™”í•´ â€˜ë‚˜ë‹¤ìš´ ì„ íƒâ€™ì„ ë•ìŠµë‹ˆë‹¤",
        "style": "ê³µê°/ê°€ì¹˜ê´€/ê°ì • ëª…ë£Œí™”",
        "method": [
            "ê°ì •/ë‘ë ¤ì›€/ê¸°ëŒ€ ë¶„í•´",
            "ì§„ì§œ ì›í•˜ëŠ” ê²ƒ(ê°€ì¹˜) ë°œêµ´",
            "í›„íšŒ ìµœì†Œí™” ê´€ì (ë¯¸ë˜ì˜ ë‚˜) ì§ˆë¬¸",
            "ë‚˜ë‹µê²Œ ì„ íƒí•˜ëŠ” ë¬¸ì¥ ë§Œë“¤ê¸°",
        ],
        "prompt_hint": "ê°ì • ë¼ë²¨ë§, ê°€ì¹˜ ìš°ì„ ìˆœìœ„, í›„íšŒ í…ŒìŠ¤íŠ¸",
    },
    {
        "id": "action",
        "name": "âš”ï¸ ì‹¤í–‰ ì½”ì¹˜",
        "tagline": "ê²°ì •ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ í–‰ë™Â·ê³„íšìœ¼ë¡œ ë°”ê¿‰ë‹ˆë‹¤",
        "style": "êµ¬ì²´ì /ìš°ì„ ìˆœìœ„/ê³„íš(ë…„â†’ë‹¬â†’ì£¼)/ì‘ì€ ì‹¤í—˜",
        "method": [
            "ìš°ì„ ìˆœìœ„ ì •í•˜ê¸°: íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€ìœ¼ë¡œ 1~3ê°œ ì„ ì •",
            "í° ëª©í‘œë¥¼ ê³„íšìœ¼ë¡œ ìª¼ê°œê¸°: ë…„ â†’ ë‹¬ â†’ ì£¼ ë‹¨ìœ„ë¡œ êµ¬ì²´í™”",
            "7ì¼ ì‹¤í—˜ 1~2ê°œ ì„¤ê³„(15~30ë¶„ ë‹¨ìœ„ë¡œ ì‹œì‘)",
            "ì¥ì• ë¬¼/ëŒ€ì‘ê³„íš(If-Then) ì •ë¦¬",
            "ì‹¤í–‰ í›„ ë¦¬ë·° ì§ˆë¬¸(ë¬´ì—‡ì´ ì‘ë™/ë°©í•´í–ˆëŠ”ê°€)",
        ],
        "prompt_hint": "ìš°ì„ ìˆœìœ„, ë¡œë“œë§µ(ë…„â†’ë‹¬â†’ì£¼), 7ì¼ ì‹¤í—˜, If-Then",
    },
]


# =========================
# Pebble UI (SVG -> base64 HTML)
# =========================
def _pebble_svg(fill: str, shine: str, stroke: str = "#3a3a3a") -> str:
    return f"""
<svg width="160" height="120" viewBox="0 0 160 120" xmlns="http://www.w3.org/2000/svg" role="img" aria-label="pebble">
  <defs>
    <radialGradient id="g" cx="35%" cy="25%" r="80%">
      <stop offset="0%" stop-color="{shine}" stop-opacity="0.95"/>
      <stop offset="55%" stop-color="{fill}" stop-opacity="1"/>
      <stop offset="100%" stop-color="{fill}" stop-opacity="1"/>
    </radialGradient>
  </defs>
  <path d="M28 80
           C14 60, 20 30, 50 20
           C66 14, 96 12, 114 24
           C142 44, 150 68, 130 88
           C112 108, 54 110, 28 80 Z"
        fill="url(#g)" stroke="{stroke}" stroke-width="2" />
  <path d="M54 30 C68 22, 82 22, 94 30"
        fill="none" stroke="{shine}" stroke-width="7" stroke-linecap="round" opacity="0.55"/>
</svg>
""".strip()


def pebble_svg_b64(progress_0_to_1: float, inactive: bool = False) -> str:
    p = max(0.0, min(1.0, float(progress_0_to_1)))
    if inactive:
        fill, shine = "#2f3136", "#6b6f7a"
    else:
        fill = "#5f6672" if p < 0.25 else "#707888" if p < 0.5 else "#8892a6" if p < 0.75 else "#a6b2c8"
        shine = "#aab8ff" if p < 0.25 else "#c8d3ff" if p < 0.5 else "#e3e8ff" if p < 0.75 else "#ffffff"
    svg = _pebble_svg(fill=fill, shine=shine)
    return base64.b64encode(svg.encode("utf-8")).decode("ascii")


def render_pebble_row(current_idx: int, total: int, labels: List[str]) -> None:
    cols = st.columns(total)
    for i in range(total):
        active = i <= current_idx
        p = (i + 1) / total
        b64 = pebble_svg_b64(p, inactive=not active)
        html = f"""
        <div style="text-align:center;">
          <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:140px;"/>
          <div style="font-size:12px; margin-top:4px; opacity:{1.0 if active else 0.55};">
            {labels[i]}
          </div>
        </div>
        """
        cols[i].markdown(html, unsafe_allow_html=True)


def render_hero_pebble(progress: float, label: str) -> None:
    b64 = pebble_svg_b64(progress, inactive=False)
    html = f"""
    <div style="text-align:center;">
      <img src="data:image/svg+xml;base64,{b64}" style="width:100%; max-width:240px;"/>
      <div style="margin-top:6px; font-size:14px;">
        {label}
      </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)


# =========================
# OpenAI helpers
# =========================
def get_api_key() -> str:
    try:
        k = st.secrets.get("OPENAI_API_KEY", "")  # type: ignore
        if k:
            return str(k).strip()
    except Exception:
        pass
    return str(st.session_state.get("openai_api_key_input", "")).strip()


def get_client(api_key: str) -> "OpenAI":
    if OpenAI is None:
        raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. `pip install openai`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    return OpenAI(api_key=api_key)


def call_openai_text(system: str, user: str, temperature: float = 0.7) -> Tuple[Optional[str], Optional[str], List[str]]:
    debug: List[str] = []
    api_key = get_api_key()
    if not api_key:
        return None, "OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. Secretsì— OPENAI_API_KEYë¥¼ ë„£ê±°ë‚˜ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ì„¸ìš”.", debug

    try:
        client = get_client(api_key)
    except Exception as e:
        return None, str(e), debug

    if hasattr(client, "responses"):
        for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
            try:
                debug.append(f"Responses API / model={model}")
                resp = client.responses.create(
                    model=model,
                    input=[
                        {"role": "system", "content": [{"type": "text", "text": system}]},
                        {"role": "user", "content": [{"type": "text", "text": user}]},
                    ],
                    temperature=temperature,
                )
                if getattr(resp, "output_text", None):
                    return str(resp.output_text).strip(), None, debug

                out_texts: List[str] = []
                for item in getattr(resp, "output", []) or []:
                    for c in getattr(item, "content", []) or []:
                        if getattr(c, "type", None) == "output_text":
                            out_texts.append(getattr(c, "text", ""))
                text = "\n".join([t for t in out_texts if t]).strip()
                if text:
                    return text, None, debug
                raise RuntimeError("ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                debug.append(f"Responses failed: {type(e).__name__}: {e}")

    for model in [MODEL_PRIMARY, MODEL_FALLBACK]:
        try:
            debug.append(f"Chat Completions / model={model}")
            cc = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": system}, {"role": "user", "content": user}],
                temperature=temperature,
            )
            text = ""
            if cc.choices:
                text = (cc.choices[0].message.content or "").strip()
            if text:
                return text, None, debug
            raise RuntimeError("ë¹ˆ ì‘ë‹µ")
        except Exception as e:
            debug.append(f"Chat failed: {type(e).__name__}: {e}")

    return None, "OpenAI í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë””ë²„ê·¸ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.", debug


# =========================
# State + routing
# =========================
def init_state() -> None:
    if "page" not in st.session_state:
        st.session_state.page = "setup"  # setup | questions | report

    if "category" not in st.session_state:
        st.session_state.category = TOPIC_CATEGORIES[0][0]
    if "decision_type" not in st.session_state:
        st.session_state.decision_type = DECISION_TYPES[0]
    if "coach_id" not in st.session_state:
        st.session_state.coach_id = COACHES[0]["id"]

    if "num_questions" not in st.session_state:
        st.session_state.num_questions = 5
    if "q_index" not in st.session_state:
        st.session_state.q_index = 0

    if "questions" not in st.session_state:
        st.session_state.questions = []
    if "answers" not in st.session_state:
        st.session_state.answers = []

    if "final_report" not in st.session_state:
        st.session_state.final_report = None

    if "debug_log" not in st.session_state:
        st.session_state.debug_log = []
    if "openai_api_key_input" not in st.session_state:
        st.session_state.openai_api_key_input = ""


def coach_by_id(coach_id: str) -> Dict[str, Any]:
    for c in COACHES:
        if c["id"] == coach_id:
            return c
    return COACHES[0]


def reset_flow(to_page: str = "setup") -> None:
    st.session_state.page = to_page
    st.session_state.q_index = 0
    st.session_state.questions = []
    st.session_state.answers = []
    st.session_state.final_report = None
    st.session_state.debug_log = []


def add_answer(q: str, a: str) -> None:
    st.session_state.answers.append({"q": q, "a": a, "ts": datetime.now().isoformat(timespec="seconds")})


# =========================
# Similarity + Question generation
# =========================
def system_prompt_for(coach: Dict[str, Any]) -> str:
    if coach["id"] == "logic":
        return (
            "ë‹¹ì‹ ì€ 'ë…¼ë¦¬ ì½”ì¹˜'ì…ë‹ˆë‹¤. ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ê³ ë¯¼ì„ ì˜ì‚¬ê²°ì • ë¬¸ì œë¡œ êµ¬ì¡°í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n"
            "- ìŸì /ì˜µì…˜/ê¸°ì¤€/ì œì•½/ê°€ì •/ë¦¬ìŠ¤í¬ë¥¼ ë¶„ë¦¬í•´ì„œ ë‹¤ë£¨ì„¸ìš”.\n"
            "- ì§ˆë¬¸ì€ ì§§ê³ , ë‹µë³€ì„ í‘œ/ëª©ë¡ìœ¼ë¡œ ë§Œë“¤ê¸° ì‰¬ìš´ í˜•íƒœë¡œ êµ¬ì„±í•˜ì„¸ìš”.\n"
        )
    if coach["id"] == "value":
        return (
            "ë‹¹ì‹ ì€ 'ê°€ì¹˜/ê°ì • ì½”ì¹˜'ì…ë‹ˆë‹¤. ëª©í‘œëŠ” ê°ì •ê³¼ ê°€ì¹˜ê´€ì„ ëª…ë£Œí™”í•´ ì‚¬ìš©ìê°€ 'ë‚˜ë‹¤ìš´ ì„ íƒ'ì„ í•˜ë„ë¡ ë•ëŠ” ê²ƒì…ë‹ˆë‹¤.\n"
            "- ê°ì • ë¼ë²¨ë§ + ê·¸ ê°ì •ì˜ ê·¼ì›(ìš•êµ¬/ë‘ë ¤ì›€)ì„ íƒìƒ‰í•˜ì„¸ìš”.\n"
            "- ê°€ì¹˜(ì¤‘ìš”í•œ ê²ƒ)ë¥¼ 3ê°œë¡œ ì¢íˆê³ , í›„íšŒ ìµœì†Œí™” ê´€ì  ì§ˆë¬¸ì„ í¬í•¨í•˜ì„¸ìš”.\n"
        )
    return (
        "ë‹¹ì‹ ì€ 'ì‹¤í–‰ ì½”ì¹˜'ì…ë‹ˆë‹¤. ëª©í‘œëŠ” ê²°ì •ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íšê³¼ í–‰ë™ìœ¼ë¡œ ë°”ê¾¸ëŠ” ê²ƒì…ë‹ˆë‹¤.\n"
        "- ë°˜ë“œì‹œ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ê²Œ í•˜ì„¸ìš”(íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ ê¸°ì¤€).\n"
        "- í° ëª©í‘œë¥¼ ë…„â†’ë‹¬â†’ì£¼ ë‹¨ìœ„ë¡œ ìª¼ê°œ êµ¬ì²´í™”í•˜ê²Œ í•˜ì„¸ìš”.\n"
        "- 7ì¼ ì‹¤í—˜ 1~2ê°œì™€ If-Then(ì¥ì• ë¬¼ ëŒ€ì‘)ì„ í¬í•¨í•˜ì„¸ìš”.\n"
        "- ì§ˆë¬¸ì€ ì§§ê³ , ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ë‹µì„ ëŒì–´ë‚´ëŠ” í˜•íƒœë¡œ êµ¬ì„±í•˜ì„¸ìš”.\n"
    )


def build_context_block() -> str:
    cat = st.session_state.category
    dtype = st.session_state.decision_type
    hist = ""
    for i, qa in enumerate(st.session_state.answers[-6:], start=1):
        hist += f"{i}) Q: {qa['q']}\n   A: {qa['a']}\n"
    return textwrap.dedent(f"""
    [ê³ ë¯¼ ì¹´í…Œê³ ë¦¬]
    {cat}

    [ê²°ì • ìœ í˜•]
    {dtype}

    [ì§€ê¸ˆê¹Œì§€ì˜ Q/A (ìµœê·¼ 6ê°œ)]
    {hist if hist.strip() else "(ì•„ì§ ì—†ìŒ)"}
    """).strip()


def normalize(s: str) -> str:
    s = (s or "").strip()
    s = re.sub(r"\s+", " ", s)
    return s


def token_overlap(a: str, b: str) -> float:
    def toks(s: str) -> set:
        s = re.sub(r"[^\wê°€-í£ ]", " ", s)
        s = re.sub(r"\s+", " ", s).strip().lower()
        return set([t for t in s.split(" ") if len(t) >= 2])

    ta, tb = toks(a), toks(b)
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    denom = max(1, min(len(ta), len(tb)))
    return inter / denom


def is_similar(a: str, b: str) -> bool:
    a0, b0 = normalize(a), normalize(b)
    if not a0 or not b0:
        return False
    if a0 == b0:
        return True
    if a0 in b0 or b0 in a0:
        return True
    return token_overlap(a0, b0) >= 0.75


def instruction_for_question(i: int, n: int, coach_id: str) -> str:
    """
    ì§ˆë¬¸ì„ nê°œë¡œ ëŠ˜ë ¤ë„ ê° ì§ˆë¬¸ì´ ì—­í• ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì„¤ê³„.
    ì‹¤í–‰ ì½”ì¹˜ëŠ” ìš°ì„ ìˆœìœ„ + ë…„â†’ë‹¬â†’ì£¼ ê³„íš ì§ˆë¬¸ì´ ì¤‘ê°„ì— ë°˜ë“œì‹œ ë‚˜ì˜¤ë„ë¡ êµ¬ì„±.
    """
    # ê³µí†µ ì‹œì‘ 2ê°œ
    if i == 0:
        return "ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ íŒŒì•…í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
    if i == 1:
        return "ì›í•˜ëŠ” ê²°ê³¼ì™€ í”¼í•˜ê³  ì‹¶ì€ ê²°ê³¼ë¥¼ ë¶„ë¦¬í•´ ë“œëŸ¬ë‚´ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."

    # ì‹¤í–‰ ì½”ì¹˜ ì „ìš©: ìš°ì„ ìˆœìœ„/ë¡œë“œë§µ ì§ˆë¬¸ì„ ê°•ì œ ë°°ì¹˜
    if coach_id == "action":
        # i=2: ìš°ì„ ìˆœìœ„
        if i == 2:
            return "í•´ì•¼ í•  ê²ƒ(ë˜ëŠ” ì˜µì…˜)ë“¤ì„ 3~6ê°œë¡œ ë‚˜ì—´í•˜ê³ , íš¨ê³¼/ì¤‘ìš”ë„/ë‚œì´ë„ë¡œ ìš°ì„ ìˆœìœ„ 1~3ê°œë¥¼ ê³ ë¥´ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
        # i=3: ë…„â†’ë‹¬â†’ì£¼ ë¡œë“œë§µ
        if i == 3 and n >= 5:
            return "ìš°ì„ ìˆœìœ„ 1ê°œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª©í‘œë¥¼ ë…„â†’ë‹¬â†’ì£¼ë¡œ ìª¼ê°œ ê³„íšì„ ì„¸ìš°ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
        # ì¤‘ë°˜(ë§ˆì§€ë§‰ 2ê°œ ì´ì „): 7ì¼ ì‹¤í—˜/ì²« í–‰ë™
        if i < n - 2:
            return "ì´ë²ˆ ì£¼ì— í•  ìˆ˜ ìˆëŠ” 7ì¼ ì‹¤í—˜(1ê°œ)ê³¼ ì‹œì‘ í–‰ë™(15~30ë¶„)ì„ êµ¬ì²´í™”í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
        # ë§ˆì§€ë§‰ 2ê°œ: ì¥ì• ë¬¼ If-Then, ì‹¤í–‰ ì•½ì†
        if i == n - 2:
            return "ì¥ì• ë¬¼ 3ê°€ì§€ë¥¼ ì˜ˆìƒí•˜ê³  If-Then(ë§Œì•½~ì´ë©´â†’~í•œë‹¤) ëŒ€ì‘ì„ ë§Œë“¤ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
        return "ì‹¤í–‰ ì•½ì†ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ê³ ì •í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œ(ì–¸ì œ/ì–´ë””ì„œ/ëª‡ ë¶„/ë¬´ì—‡ì„) ì‘ì„±í•˜ì„¸ìš”."

    # ë…¼ë¦¬/ê°€ì¹˜ ì½”ì¹˜: ê¸°ì¡´ íë¦„
    if i == 2 and n >= 4:
        return "ì œì•½(ì‹œê°„/ëˆ/ê´€ê³„/ê·œì¹™)ê³¼ ë°”ê¿€ ìˆ˜ ì—†ëŠ” ì¡°ê±´ì„ ëª…í™•íˆ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."

    if i < n - 2:
        if coach_id == "logic":
            return "ì˜µì…˜ì„ ë‚˜ëˆ„ê³  í‰ê°€ ê¸°ì¤€(3~5)ì„ ì„¤ì •í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”. (í‘œë¡œ ì •ë¦¬ ê°€ëŠ¥í•˜ê²Œ)"
        return "ê°€ì¹˜ ìš°ì„ ìˆœìœ„(ìƒìœ„ 3ê°œ)ì™€ ê°ì •/ìš•êµ¬/ë‘ë ¤ì›€ì„ ë“œëŸ¬ë‚´ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."

    if i == n - 2:
        if coach_id == "logic":
            return "ê°€ì •/ë¦¬ìŠ¤í¬ë¥¼ ê²€ì¦í•˜ê³  í”ŒëœBë¥¼ ë– ì˜¬ë¦¬ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
        return "í›„íšŒ ìµœì†Œí™” ê´€ì (1ë…„/5ë…„ í›„)ì„ ì ê²€í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”."

    if coach_id == "logic":
        return "ê²°ì •ì„ ë‚´ë¦¬ê¸° ìœ„í•œ ìµœì¢… í™•ì¸ ì§ˆë¬¸ 1ê°œ(ê°€ì •/ë¦¬ìŠ¤í¬/ëŒ€ì•ˆ ì¤‘ í•˜ë‚˜ì— ì´ˆì )ë¥¼ ì‘ì„±í•˜ì„¸ìš”."
    return "ê²°ì • ë¬¸ì¥ì„ í•œ ì¤„ë¡œ ì™„ì„±í•˜ê²Œ í•˜ëŠ” ì§ˆë¬¸ 1ê°œë¥¼ ì‘ì„±í•˜ì„¸ìš”. (ë‚˜ëŠ” ___ë¥¼ ìœ„í•´ ___ì„ ì„ íƒí•œë‹¤)"


def fallback_question(coach_id: str, i: int, n: int) -> str:
    if i == 0:
        return "ì§€ê¸ˆ ê³ ë¯¼ ìƒí™©ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. (ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆê³ , ë¬´ì—‡ì„ ê²°ì •í•´ì•¼ í•˜ë‚˜ìš”?)"
    if i == 1:
        return "ì´ ê²°ì •ì—ì„œ ì–»ê³  ì‹¶ì€ ìµœì„ ì˜ ê²°ê³¼ 1ê°€ì§€ì™€ í”¼í•˜ê³  ì‹¶ì€ ìµœì•…ì˜ ê²°ê³¼ 1ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"

    if coach_id == "action":
        if i == 2:
            return "í•´ì•¼ í•  ì¼(ë˜ëŠ” ì˜µì…˜)ì„ 3~6ê°œ ì ê³ , ê·¸ì¤‘ ê°€ì¥ íš¨ê³¼ê°€ í° 1~3ê°œë¥¼ ìš°ì„ ìˆœìœ„ë¡œ ê³ ë¥´ë©´ ë¬´ì—‡ì¸ê°€ìš”?"
        if i == 3 and n >= 5:
            return "ìš°ì„ ìˆœìœ„ 1ê°œë¥¼ â€˜1ë…„ ëª©í‘œ â†’ ì´ë²ˆ ë‹¬ ëª©í‘œ â†’ ì´ë²ˆ ì£¼ í•  ì¼â€™ë¡œ ìª¼ê°œë©´ ê°ê° ë¬´ì—‡ì¸ê°€ìš”?"
        if i == n - 2:
            return "ì´ë²ˆ ì£¼ ì‹¤í–‰ì„ ë°©í•´í•  ì¥ì• ë¬¼ 3ê°€ì§€ë¥¼ ì ê³ , ê°ê°ì— ëŒ€í•´ â€˜ë§Œì•½ ~ì´ë©´ â†’ ~í•œë‹¤â€™ë¡œ ëŒ€ì‘ì„ ë§Œë“¤ì–´ë³´ë©´ìš”?"
        if i == n - 1:
            return "ì´ë²ˆ ì£¼ ì²« í–‰ë™ì„ â€˜ì–¸ì œ/ì–´ë””ì„œ/ëª‡ ë¶„/ë¬´ì—‡ì„â€™ í•œ ë¬¸ì¥ìœ¼ë¡œ ì ì–´ ì£¼ì„¸ìš”."
        return "ì´ë²ˆ ì£¼ì— í•  7ì¼ ì‹¤í—˜ 1ê°œì™€, ì˜¤ëŠ˜ 15~30ë¶„ ì•ˆì— í•  ì‹œì‘ í–‰ë™ì€ ë¬´ì—‡ì¸ê°€ìš”?"

    # logic/value ê³µí†µ fallback
    if i == 2 and n >= 4:
        return "ì‹œê°„/ëˆ/ê´€ê³„/ê·œì¹™ ì¸¡ë©´ì—ì„œ ë°”ê¿€ ìˆ˜ ì—†ëŠ” ì œì•½ 2ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
    if i == n - 1:
        if coach_id == "logic":
            return "ì´ ê²°ì •ì„ ë‚´ë¦¬ê¸° ì „ì— í™•ì¸í•´ì•¼ í•  ê°€ì¥ í° ê°€ì • 1ê°œì™€, ê·¸ ê°€ì •ì´ í‹€ë ¸ì„ ë•Œì˜ ëŒ€ì•ˆ(í”ŒëœB)ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        return "â€˜ë‚˜ëŠ” ___ë¥¼ ìœ„í•´ ___ì„ ì„ íƒí•œë‹¤â€™ ë¬¸ì¥ì„ ì™„ì„±í•˜ë©´, ë¹ˆì¹¸ì— ë¬´ì—‡ì´ ë“¤ì–´ê°€ë‚˜ìš”?"
    if coach_id == "logic":
        return "ì„ íƒ ê¸°ì¤€ 3ê°œë¥¼ ì •í•´ë³´ë©´ ë¬´ì—‡ì¸ê°€ìš”? (ì˜ˆ: ì„±ì¥/ë¹„ìš©/ë¦¬ìŠ¤í¬)"
    return "ì´ ê³ ë¯¼ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê°€ì¹˜ 3ê°œëŠ” ë¬´ì—‡ì¸ê°€ìš”? (ì˜ˆ: ì•ˆì •/ì„±ì¥/ê´€ê³„)"


def generate_question(i: int, n: int) -> Tuple[str, Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for(coach)
    prev_qs = st.session_state.questions[:]

    def prompt(nonce: int) -> str:
        prev_txt = "\n".join([f"- {q}" for q in prev_qs]) if prev_qs else "(ì—†ìŒ)"
        return textwrap.dedent(f"""
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìƒê°ì„ ì •ë¦¬í•˜ê¸° ìœ„í•œ ì§ˆë¬¸ì„ 1ê°œ ìƒì„±í•©ë‹ˆë‹¤.

        ê·œì¹™:
        - ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥ (ì„¤ëª…/ë¨¸ë¦¬ë§/ë²ˆí˜¸ ê¸ˆì§€)
        - í•œêµ­ì–´
        - ì´ì „ ì§ˆë¬¸ê³¼ ë™ì¼í•˜ê±°ë‚˜ ë§¤ìš° ìœ ì‚¬í•œ ì§ˆë¬¸ ê¸ˆì§€
        - ì§ˆë¬¸ì˜ ì´ˆì /ê´€ì ì´ ì´ì „ ì§ˆë¬¸ë“¤ê³¼ ê²¹ì¹˜ì§€ ì•Šê²Œ êµ¬ì„±
        - ì‚¬ìš©ìê°€ ë‹µí•˜ê¸° ì‰½ê²Œ ì˜ˆì‹œ(ê´„í˜¸ 1ì¤„) í—ˆìš©

        [ì´ì „ ì§ˆë¬¸ ëª©ë¡]
        {prev_txt}

        {build_context_block()}

        [ì´ë²ˆ ì§ˆë¬¸ì˜ ëª©ì ]
        {instruction_for_question(i, n, coach["id"])}

        (nonce={nonce})

        ì´ì œ ì§ˆë¬¸ 1ê°œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """).strip()

    q1, err, dbg = call_openai_text(system=system, user=prompt(random.randint(1000, 9999)), temperature=0.75)
    if not q1:
        return fallback_question(coach["id"], i, n), err, dbg

    q1 = normalize(q1)
    if not any(is_similar(q1, pq) for pq in prev_qs):
        return q1, None, dbg

    dbg.append("Similar question detected. Regenerating once.")
    q2, err2, dbg2 = call_openai_text(system=system, user=prompt(random.randint(10000, 99999)), temperature=0.85)
    dbg.extend(dbg2)
    if q2:
        q2 = normalize(q2)
        if not any(is_similar(q2, pq) for pq in prev_qs):
            return q2, None, dbg

    dbg.append("Still similar after retry. Using fallback question.")
    return fallback_question(coach["id"], i, n), None, dbg


def ensure_question(index: int, total: int) -> None:
    while len(st.session_state.questions) <= index:
        i = len(st.session_state.questions)
        q, err, dbg = generate_question(i, total)
        st.session_state.debug_log = dbg
        st.session_state.questions.append(q)


# =========================
# Final report
# =========================
def generate_final_report() -> Tuple[Optional[str], Optional[str], List[str]]:
    coach = coach_by_id(st.session_state.coach_id)
    system = system_prompt_for(coach)

    if coach["id"] == "logic":
        format_spec = """
ì¶œë ¥ í˜•ì‹:
## í•œ ì¤„ ê²°ë¡ 
- ê²°ë¡ : ...

## ì˜ì‚¬ê²°ì • êµ¬ì¡°
- ìŸì :
- ì˜µì…˜(2~4):
- í‰ê°€ ê¸°ì¤€(3~5):
- ì œì•½/ê°€ì •:
- ë¦¬ìŠ¤í¬/ëŒ€ì‘:

## ì¶”ì²œì•ˆ (ê·¼ê±°)
- ì¶”ì²œ: ...
- ì´ìœ (3ì¤„):
- ë³´ì™„ì±…(ë¦¬ìŠ¤í¬ ì¤„ì´ê¸°):

## ë‹¤ìŒ í–‰ë™(24ì‹œê°„ ë‚´)
- ...
"""
    elif coach["id"] == "value":
        format_spec = """
ì¶œë ¥ í˜•ì‹:
## ì§€ê¸ˆì˜ ë§ˆìŒ ìš”ì•½
- ê°ì •(3ê°œ): ...
- ì§„ì§œ ìš•êµ¬/ë‘ë ¤ì›€: ...

## ë‚˜ì˜ ê¸°ì¤€(ê°€ì¹˜)
- ìƒìœ„ 3ê°€ì§€: ...
- ë‚´ë ¤ë†“ì„ ìˆ˜ ìˆëŠ” ê²ƒ 1ê°€ì§€: ...

## ë‚˜ë‹¤ìš´ ì„ íƒ ë¬¸ì¥
- â€œë‚˜ëŠ” ___ë¥¼ ìœ„í•´ ___ì„ ì„ íƒí•œë‹¤.â€

## í›„íšŒ ìµœì†Œí™” ì²´í¬
- 1ë…„ ë’¤ì˜ ë‚˜: ...
- 5ë…„ ë’¤ì˜ ë‚˜: ...

## ë‚´ì¼ì˜ ì‘ì€ ì•½ì†
- ...
"""
    else:
        # ì‹¤í–‰ ì½”ì¹˜ëŠ” ë…„â†’ë‹¬â†’ì£¼ ê³„íšì„ ë ˆí¬íŠ¸ì—ì„œë„ ê°•í•˜ê²Œ
        format_spec = """
ì¶œë ¥ í˜•ì‹:
## ìš°ì„ ìˆœìœ„(Top 1~3)
- 1) ...
- 2) ...
- 3) ...

## ëª©í‘œ ë¡œë“œë§µ(ë…„ â†’ ë‹¬ â†’ ì£¼)
- 1ë…„ ëª©í‘œ(1ê°œ):
- ì´ë²ˆ ë‹¬ ëª©í‘œ(1ê°œ):
- ì´ë²ˆ ì£¼ ê³„íš(3~5ê°œ):

## 7ì¼ ì‹¤í—˜(1~2ê°œ)
- ì‹¤í—˜1: (ì‹œì‘ í–‰ë™ 15~30ë¶„ í¬í•¨)
- ì‹¤í—˜2(ì„ íƒ):

## If-Then ëŒ€ì‘í‘œ
- ë§Œì•½ ___ì´ë©´ â†’ ___í•œë‹¤ (3ê°œ)

## ì˜¤ëŠ˜(24ì‹œê°„ ë‚´) ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ...
- [ ] ...

## ë¦¬ë·° ì§ˆë¬¸
- ...
"""

    qa_text = ""
    for i, qa in enumerate(st.session_state.answers, start=1):
        qa_text += f"{i}) Q: {qa['q']}\n   A: {qa['a']}\n"

    user = textwrap.dedent(f"""
ì•„ë˜ Q/Aë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì½”ì¹˜ ì—­í• ì— ë§ëŠ” 'ìµœì¢… ì •ë¦¬ ë ˆí¬íŠ¸'ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ê·œì¹™:
- í•œêµ­ì–´
- ì„ íƒì„ ê°•ìš”í•˜ì§€ ë§ê³ , ê·¼ê±°ì™€ ë‹¤ìŒ ìŠ¤í…ì„ ëª…í™•íˆ
- ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ 'ì¶”ê°€ í™•ì¸ ì§ˆë¬¸' 1ê°œë¥¼ ë§ˆì§€ë§‰ì— ì œì•ˆ
- ê¸¸ì´: 700~1200ì

[ì„¤ì •]
- ì¹´í…Œê³ ë¦¬: {st.session_state.category}
- ê²°ì • ìœ í˜•: {st.session_state.decision_type}
- ì½”ì¹˜: {coach["name"]}

[Q/A]
{qa_text if qa_text.strip() else "(ì—†ìŒ)"}

{format_spec}

ë§ˆì§€ë§‰ ì¤„:
- ì¶”ê°€ í™•ì¸ ì§ˆë¬¸: ...
""").strip()

    return call_openai_text(system=system, user=user, temperature=0.65)


# =========================
# Main UI
# =========================
init_state()

with st.sidebar:
    st.header("ì„¤ì •")
    st.text_input("OpenAI API Key (Secrets ìš°ì„ )", type="password", key="openai_api_key_input")

    st.divider()
    st.subheader("ê³ ë¯¼ ë²”ìœ„")
    st.selectbox("ê³ ë¯¼ ì¹´í…Œê³ ë¦¬", [x[0] for x in TOPIC_CATEGORIES], key="category")
    st.selectbox("ê²°ì • ìœ í˜•", DECISION_TYPES, key="decision_type")

    st.divider()
    st.subheader("ì½”ì¹˜ ì„ íƒ")
    coach_labels = [f"{c['name']} â€” {c['tagline']}" for c in COACHES]
    cur = next((i for i, c in enumerate(COACHES) if c["id"] == st.session_state.coach_id), 0)
    picked = st.radio("ì½”ì¹˜", coach_labels, index=cur)
    st.session_state.coach_id = COACHES[coach_labels.index(picked)]["id"]

    coach = coach_by_id(st.session_state.coach_id)
    with st.expander("ì½”ì¹˜ ì§„í–‰ ë°©ì‹"):
        st.markdown(f"**{coach['name']}**  \n_{coach['style']}_")
        for m in coach["method"]:
            st.write(f"- {m}")
        st.caption(f"íŠ¹ì§•: {coach['prompt_hint']}")

    st.divider()
    st.subheader("ì§ˆë¬¸ ê°œìˆ˜")
    st.session_state.num_questions = st.slider("ì§ˆë¬¸ ê°œìˆ˜(2~10)", 2, 10, int(st.session_state.num_questions))

    st.divider()
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ì²˜ìŒë¶€í„°", use_container_width=True):
            reset_flow("setup")
            st.rerun()
    with c2:
        if st.session_state.page == "setup":
            if st.button("ì§ˆë¬¸ ì‹œì‘", type="primary", use_container_width=True):
                reset_flow("questions")
                st.rerun()
        elif st.session_state.page == "questions":
            done = len(st.session_state.answers) >= int(st.session_state.num_questions)
            if st.button("ìµœì¢… ë ˆí¬íŠ¸ë¡œ", use_container_width=True, disabled=not done):
                st.session_state.page = "report"
                st.rerun()
        else:
            if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ", use_container_width=True):
                st.session_state.page = "questions"
                st.rerun()

# Progress bar labels
nq = int(st.session_state.num_questions)
progress_labels = ["ì„¤ì •"] + [f"Q{i}" for i in range(1, nq + 1)] + ["ë ˆí¬íŠ¸"]

if st.session_state.page == "setup":
    current_progress = 0
elif st.session_state.page == "questions":
    current_progress = 1 + int(st.session_state.q_index)
else:
    current_progress = 1 + nq

render_pebble_row(current_progress, len(progress_labels), progress_labels)

progress = current_progress / max(1, (len(progress_labels) - 1))
with st.columns([1, 2, 1])[1]:
    render_hero_pebble(progress, f"ì§„í–‰ë„: {int(progress*100)}%")

st.divider()

# Pages
coach = coach_by_id(st.session_state.coach_id)

if st.session_state.page == "setup":
    st.title("ğŸª¨ ëŒë©©ì´ ê²°ì • ì½”ì¹˜")
    st.caption("ì§ˆë¬¸ ê°œìˆ˜ë¥¼ ì„¤ì •í•˜ê³  ì‹œì‘í•˜ì„¸ìš”. ì§ˆë¬¸ì´ ëë‚˜ë©´ ìë™ìœ¼ë¡œ ë ˆí¬íŠ¸ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")

    cat_desc = next((d for n, d in TOPIC_CATEGORIES if n == st.session_state.category), "")
    st.info(f"**ì¹´í…Œê³ ë¦¬:** {st.session_state.category}\n\n{cat_desc}")
    st.write(f"**ê²°ì • ìœ í˜•:** {st.session_state.decision_type}")
    st.write(f"**ì„ íƒí•œ ì½”ì¹˜:** {coach['name']}")
    st.write(f"**ì§ˆë¬¸ ê°œìˆ˜:** {nq}ê°œ")
    st.success("ì‚¬ì´ë“œë°”ì—ì„œ â€˜ì§ˆë¬¸ ì‹œì‘â€™ì„ ëˆ„ë¥´ë©´ ì§ˆë¬¸ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")

elif st.session_state.page == "questions":
    st.title("ì§ˆë¬¸")
    st.caption("ë‹µë³€ì„ ì €ì¥í•˜ë©´ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.")

    q_idx = int(st.session_state.q_index)
    if q_idx >= nq:
        st.session_state.q_index = nq - 1
        q_idx = nq - 1

    ensure_question(q_idx, nq)
    current_q = st.session_state.questions[q_idx]

    st.subheader(f"Q{q_idx + 1} / {nq}")
    with st.container(border=True):
        st.markdown(f"**{current_q}**")

    with st.form(f"answer_form_{q_idx}", clear_on_submit=True):
        hint = ""
        if st.session_state.answers:
            last_a = st.session_state.answers[-1]["a"]
            hint = f"ì´ì „ ë‹µ ìš”ì•½: {last_a[:90]}{'â€¦' if len(last_a) > 90 else ''}"
        answer = st.text_area("ë‹µë³€", placeholder=hint or "ì—¬ê¸°ì— ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”", height=140)
        submitted = st.form_submit_button("ë‹µë³€ ì €ì¥", use_container_width=True)

    if submitted:
        if not answer.strip():
            st.warning("ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í•œ ì¤„ë§Œ ì…ë ¥í•´ë„ ì§„í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            add_answer(current_q, answer.strip())

            if len(st.session_state.answers) >= nq:
                st.session_state.page = "report"
                st.session_state.q_index = nq - 1
            else:
                st.session_state.q_index += 1
            st.rerun()

    with st.expander("ë‹µë³€ ê¸°ë¡ ë³´ê¸°"):
        if not st.session_state.answers:
            st.caption("ì•„ì§ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for i, qa in enumerate(st.session_state.answers, start=1):
                st.markdown(f"**Q{i}. {qa['q']}**")
                st.write(qa["a"])
                st.caption(qa["ts"])
                st.divider()

    with st.expander("ë””ë²„ê·¸ ë¡œê·¸(ë¬¸ì œ ë°œìƒ ì‹œ í™•ì¸)"):
        st.write(st.session_state.debug_log)

else:
    st.title("ìµœì¢… ì •ë¦¬ ë ˆí¬íŠ¸")
    st.caption("ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì •ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    st.info(
        f"- **ì¹´í…Œê³ ë¦¬:** {st.session_state.category}\n"
        f"- **ê²°ì • ìœ í˜•:** {st.session_state.decision_type}\n"
        f"- **ì½”ì¹˜:** {coach['name']}\n"
        f"- **ì§ˆë¬¸ ê°œìˆ˜:** {nq}ê°œ"
    )

    if len(st.session_state.answers) < nq:
        st.warning("ì•„ì§ ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì§ˆë¬¸ í˜ì´ì§€ë¡œ ëŒì•„ê°€ ë‹µë³€ì„ ì™„ë£Œí•˜ì„¸ìš”.")
        if st.button("ì§ˆë¬¸ í˜ì´ì§€ë¡œ ì´ë™", type="primary"):
            st.session_state.page = "questions"
            st.rerun()
        st.stop()

    colA, colB = st.columns([1, 1])
    with colA:
        gen = st.button("ë ˆí¬íŠ¸ ìƒì„±/ìƒˆë¡œê³ ì¹¨", type="primary", use_container_width=True)
    with colB:
        if st.button("ìƒˆ ê³ ë¯¼ ì‹œì‘", use_container_width=True):
            reset_flow("setup")
            st.rerun()

    if gen or (st.session_state.final_report is None):
        with st.spinner("ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
            report, err, dbg = generate_final_report()
            st.session_state.debug_log = dbg
            if report:
                st.session_state.final_report = report
            else:
                st.session_state.final_report = None
                st.error(err or "ë ˆí¬íŠ¸ ìƒì„± ì‹¤íŒ¨")

    if st.session_state.final_report:
        st.success("ë ˆí¬íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.markdown(st.session_state.final_report)

        st.subheader("ê³µìœ ìš© ìš”ì•½(JSON)")
        share = {
            "category": st.session_state.category,
            "decision_type": st.session_state.decision_type,
            "coach": coach["name"],
            "num_questions": nq,
            "qa": st.session_state.answers,
            "final_report": st.session_state.final_report,
        }
        st.code(json.dumps(share, ensure_ascii=False, indent=2), language="json")

    with st.expander("Q/A ì „ì²´ ë³´ê¸°"):
        for i, qa in enumerate(st.session_state.answers, start=1):
            st.markdown(f"**Q{i}. {qa['q']}**")
            st.write(qa["a"])
            st.caption(qa["ts"])
            st.divider()

    with st.expander("ë””ë²„ê·¸ ë¡œê·¸(ë¬¸ì œ ë°œìƒ ì‹œ í™•ì¸)"):
        st.write(st.session_state.debug_log)

st.divider()
with st.expander("Streamlit Cloud ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸"):
    st.markdown(
        """
- Secrets ì„¤ì •: Settings â†’ Secretsì— `OPENAI_API_KEY = "sk-..."` ì¶”ê°€
- requirements.txt:
  - streamlit
  - openai
- ëª¨ë¸ ê¶Œí•œ ë¬¸ì œê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ gpt-4o-minië¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.
"""
    )
